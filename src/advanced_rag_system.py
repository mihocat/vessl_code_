#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced RAG System with Reranker and Reasoning Chain
ë¦¬ë­ì»¤ì™€ ì¶”ë¡  ì²´ì¸ì„ ê°–ì¶˜ ê³ ê¸‰ RAG ì‹œìŠ¤í…œ
"""

import logging
from typing import Dict, List, Any, Optional, Union
from PIL import Image
import time

# ê¸°ì¡´ ì»´í¬ë„ŒíŠ¸
from enhanced_rag_system import EnhancedVectorDatabase, MultimodalEmbedder
from enhanced_image_analyzer import ChatGPTStyleAnalyzer
from chatgpt_response_generator import ChatGPTResponseGenerator

# ìƒˆë¡œìš´ ì»´í¬ë„ŒíŠ¸
from reranker_system import HybridReranker
from rag_reasoning_chain import ElectricalEngineeringReasoner

logger = logging.getLogger(__name__)


class AdvancedRAGSystem:
    """ê³ ê¸‰ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, vector_db: EnhancedVectorDatabase, llm_client):
        """
        ê³ ê¸‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            vector_db: í–¥ìƒëœ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
            llm_client: LLM í´ë¼ì´ì–¸íŠ¸
        """
        self.vector_db = vector_db
        self.llm_client = llm_client
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.image_analyzer = ChatGPTStyleAnalyzer()
        self.response_generator = ChatGPTResponseGenerator()
        
        # ë¦¬ë­ì»¤ ì´ˆê¸°í™”
        self.reranker = HybridReranker()
        
        # ì¶”ë¡  ì²´ì¸ ì´ˆê¸°í™”
        self.reasoner = ElectricalEngineeringReasoner(
            llm_client=llm_client,
            vector_db=vector_db,
            reranker=self.reranker
        )
        
        # ë²”ìš© OCR íŒŒì´í”„ë¼ì¸
        try:
            from universal_ocr_pipeline import DomainAdaptiveOCR
            self.ocr_pipeline = DomainAdaptiveOCR()
            logger.info("Universal Domain-Adaptive OCR pipeline loaded")
        except:
            logger.warning("Universal OCR pipeline not available, trying Korean OCR")
            try:
                from korean_ocr_pipeline import KoreanElectricalOCR
                self.ocr_pipeline = KoreanElectricalOCR()
                logger.info("Korean Electrical OCR pipeline loaded")
            except:
                logger.warning("Korean OCR pipeline not available, trying multimodal")
                try:
                    from multimodal_ocr import MultimodalOCRPipeline
                    self.ocr_pipeline = MultimodalOCRPipeline()
                    logger.info("Multimodal OCR pipeline loaded")
                except:
                    logger.warning("No OCR pipeline available")
                    self.ocr_pipeline = None
        
        logger.info("Advanced RAG system initialized")
    
    def process_query_advanced(
        self,
        query: str,
        image: Optional[Union[Image.Image, str, bytes]] = None,
        mode: str = 'reasoning',  # 'fast', 'balanced', 'reasoning'
        response_style: str = 'comprehensive'
    ) -> Dict[str, Any]:
        """
        ê³ ê¸‰ ì¿¼ë¦¬ ì²˜ë¦¬
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            image: ì´ë¯¸ì§€ (ì„ íƒì )
            mode: ì²˜ë¦¬ ëª¨ë“œ
            response_style: ì‘ë‹µ ìŠ¤íƒ€ì¼
        """
        start_time = time.time()
        
        try:
            # 1. ì´ë¯¸ì§€ ë¶„ì„ (ìˆëŠ” ê²½ìš°)
            image_analysis = None
            if image:
                image_analysis = self._analyze_image_advanced(image)
                
                # ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¿¼ë¦¬ì— ì¶”ê°€
                if image_analysis.get('ocr_text'):
                    query = f"{query}\n\n[ì´ë¯¸ì§€ ë‚´ìš©: {image_analysis['ocr_text'][:200]}...]"
            
            # 2. ì²˜ë¦¬ ëª¨ë“œë³„ ì‹¤í–‰
            if mode == 'reasoning':
                # ì¶”ë¡  ì²´ì¸ ì‚¬ìš©
                result = self._process_with_reasoning(query, image_analysis)
            elif mode == 'balanced':
                # ë¦¬ë­í‚¹ë§Œ ì‚¬ìš©
                result = self._process_with_reranking(query, image_analysis, response_style)
            else:  # fast
                # ê¸°ë³¸ ê²€ìƒ‰ë§Œ ì‚¬ìš©
                result = self._process_fast(query, image_analysis, response_style)
            
            # 3. ì‘ë‹µ ì‹œê°„ ì¶”ê°€
            result['processing_time'] = time.time() - start_time
            
            return result
            
        except Exception as e:
            logger.error(f"Advanced query processing failed: {e}", exc_info=True)
            return {
                'success': False,
                'error': str(e),
                'processing_time': time.time() - start_time
            }
    
    def _analyze_image_advanced(self, image: Union[Image.Image, str, bytes]) -> Dict[str, Any]:
        """ê³ ê¸‰ ì´ë¯¸ì§€ ë¶„ì„"""
        # ë©€í‹°ëª¨ë‹¬ OCR ìš°ì„  ì‚¬ìš©
        if self.ocr_pipeline:
            try:
                if hasattr(self.ocr_pipeline, 'process_adaptive'):
                    # Universal Domain-Adaptive OCR
                    logger.info("Using Universal Domain-Adaptive OCR pipeline...")
                    ocr_result = self.ocr_pipeline.process_adaptive(image, auto_detect=True)
                elif hasattr(self.ocr_pipeline, 'extract_electrical_data'):
                    # Korean Electrical OCR
                    logger.info("Using Korean Electrical OCR pipeline...")
                    ocr_result = self.ocr_pipeline.extract_electrical_data(image)
                else:
                    # Standard multimodal OCR
                    logger.info("Using multimodal OCR pipeline...")
                    ocr_result = self.ocr_pipeline.process_image(image)
                
                # ê²°ê³¼ í˜•ì‹ ë³€í™˜
                return {
                    'success': True,
                    'ocr_text': ocr_result.get('text_content', ''),
                    'formulas': ocr_result.get('formulas', []),
                    'diagrams': ocr_result.get('diagrams', []),
                    'tables': ocr_result.get('tables', []),
                    'structured_content': ocr_result.get('structured_content', ''),
                    'layout_analysis': ocr_result.get('layout_analysis', {}),
                    'electrical_analysis': ocr_result.get('electrical_analysis', {})
                }
            except Exception as e:
                logger.warning(f"Multimodal OCR failed: {e}, falling back to Florence-2")
        
        # Florence-2 í´ë°±
        return self.image_analyzer.analyze_for_chatgpt_response(image)
    
    def _process_with_reasoning(
        self,
        query: str,
        image_analysis: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ì¶”ë¡  ì²´ì¸ì„ ì‚¬ìš©í•œ ì²˜ë¦¬"""
        logger.info("Processing with reasoning chain...")
        
        # ì¶”ë¡  ìˆ˜í–‰
        reasoning_result = self.reasoner.reason(
            query=query,
            image_analysis=image_analysis,
            max_iterations=2
        )
        
        if reasoning_result['success']:
            return {
                'success': True,
                'query': query,
                'response': reasoning_result['answer'],
                'reasoning_trace': reasoning_result['reasoning_trace'],
                'evidence': self._format_evidence(reasoning_result['evidence']),
                'confidence': reasoning_result.get('context', {}).get('confidence', 0.8),
                'mode': 'reasoning'
            }
        else:
            # í´ë°±: ë¦¬ë­í‚¹ ëª¨ë“œë¡œ
            logger.warning("Reasoning failed, falling back to reranking mode")
            return self._process_with_reranking(query, image_analysis, 'comprehensive')
    
    def _process_with_reranking(
        self,
        query: str,
        image_analysis: Optional[Dict[str, Any]],
        response_style: str
    ) -> Dict[str, Any]:
        """ë¦¬ë­í‚¹ì„ ì‚¬ìš©í•œ ì²˜ë¦¬"""
        logger.info("Processing with reranking...")
        
        # 1. ì´ˆê¸° ê²€ìƒ‰
        search_results = self.vector_db.search_multimodal(
            query=query,
            image_analysis=image_analysis,
            k=20  # ë¦¬ë­í‚¹ì„ ìœ„í•´ ë§ì´ ê²€ìƒ‰
        )
        
        # 2. ì¿¼ë¦¬ ë¶„ì„
        query_analysis = self._analyze_query(query, image_analysis)
        
        # 3. ë¦¬ë­í‚¹
        reranked_results = self.reranker.rerank(
            query=query,
            documents=search_results,
            query_analysis=query_analysis,
            strategy='weighted_fusion',
            top_k=5
        )
        
        # 4. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = self._build_enhanced_context(reranked_results, query_analysis)
        
        # 5. ì‘ë‹µ ìƒì„±
        response = self._generate_enhanced_response(
            query, context, response_style, image_analysis
        )
        
        return {
            'success': True,
            'query': query,
            'response': response,
            'search_results': self._format_search_results(reranked_results),
            'query_analysis': query_analysis,
            'mode': 'reranking'
        }
    
    def _process_fast(
        self,
        query: str,
        image_analysis: Optional[Dict[str, Any]],
        response_style: str
    ) -> Dict[str, Any]:
        """ë¹ ë¥¸ ì²˜ë¦¬ (ê¸°ë³¸ ê²€ìƒ‰ë§Œ)"""
        logger.info("Processing in fast mode...")
        
        # 1. ê²€ìƒ‰
        search_results = self.vector_db.search_multimodal(
            query=query,
            image_analysis=image_analysis,
            k=5
        )
        
        # 2. ê°„ë‹¨í•œ ì»¨í…ìŠ¤íŠ¸
        context = {
            'retrieved_documents': [
                {'content': self._extract_text(doc), 'score': doc.get('hybrid_score', 0)}
                for doc in search_results
            ]
        }
        
        # 3. ë¹ ë¥¸ ì‘ë‹µ ìƒì„±
        prompt = f"""ì§ˆë¬¸: {query}

ì°¸ê³  ìë£Œ:
{self._format_context_for_prompt(context)}

ê°„ë‹¨í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."""
        
        response = self.llm_client.generate(prompt)
        
        return {
            'success': True,
            'query': query,
            'response': response,
            'mode': 'fast'
        }
    
    def _analyze_query(
        self,
        query: str,
        image_analysis: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ì¿¼ë¦¬ ë¶„ì„"""
        analysis = {
            'query_type': self._determine_query_type(query),
            'key_concepts': self._extract_concepts(query),
            'formulas': [],
            'has_image': image_analysis is not None
        }
        
        # ì´ë¯¸ì§€ì—ì„œ ì¶”ê°€ ì •ë³´
        if image_analysis:
            if 'formulas' in image_analysis:
                analysis['formulas'].extend(image_analysis['formulas'])
            if 'key_concepts' in image_analysis:
                analysis['key_concepts'].extend(image_analysis['key_concepts'])
        
        return analysis
    
    def _determine_query_type(self, query: str) -> str:
        """ì¿¼ë¦¬ ìœ í˜• ê²°ì •"""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['ê³„ì‚°', 'êµ¬í•˜', 'ê°’ì€', 'ì–¼ë§ˆ']):
            return 'calculation'
        elif any(word in query_lower for word in ['ì„¤ëª…', 'ë¬´ì—‡', 'ì •ì˜', 'ì˜ë¯¸']):
            return 'explanation'
        elif any(word in query_lower for word in ['ì°¨ì´', 'ë¹„êµ', 'ë‹¤ë¥¸', 'vs']):
            return 'comparison'
        elif any(word in query_lower for word in ['ë°©ë²•', 'ì–´ë–»ê²Œ', 'ì ˆì°¨', 'ê³¼ì •']):
            return 'method'
        elif any(word in query_lower for word in ['ì´ìœ ', 'ì™œ', 'ì›ì¸', 'ë•Œë¬¸']):
            return 'reason'
        else:
            return 'general'
    
    def _extract_concepts(self, query: str) -> List[str]:
        """ê°œë… ì¶”ì¶œ"""
        concepts = []
        ee_keywords = [
            'ì „ì••', 'ì „ë¥˜', 'ì €í•­', 'ì „ë ¥', 'ì„í”¼ë˜ìŠ¤', 'ì—­ë¥ ',
            'ë³€ì••ê¸°', 'ëª¨í„°', 'ì „ë™ê¸°', 'íšŒë¡œ', 'ì½˜ë´ì„œ', 'ì¸ë•í„°',
            '3ìƒ', 'ë‹¨ìƒ', 'RLC', 'PWM', 'ì¸ë²„í„°', 'ì •ë¥˜ê¸°'
        ]
        
        query_lower = query.lower()
        for keyword in ee_keywords:
            if keyword.lower() in query_lower:
                concepts.append(keyword)
        
        return list(set(concepts))
    
    def _build_enhanced_context(
        self,
        reranked_results: List[Dict[str, Any]],
        query_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """í–¥ìƒëœ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        context = {
            'retrieved_documents': [],
            'key_concepts': query_analysis['key_concepts'],
            'formulas': query_analysis['formulas'],
            'query_type': query_analysis['query_type'],
            'evidence_strength': 0.0
        }
        
        # ë¦¬ë­í‚¹ëœ ë¬¸ì„œ ì²˜ë¦¬
        total_score = 0
        for doc in reranked_results:
            doc_info = {
                'content': self._extract_text(doc),
                'score': doc.get('final_rerank_score', doc.get('rerank_score', 0)),
                'score_details': doc.get('score_details', {})
            }
            
            # ë¬¸ì„œì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
            if 'parsed_content' in doc:
                if 'formulas' in doc['parsed_content']:
                    context['formulas'].extend(doc['parsed_content']['formulas'])
            
            context['retrieved_documents'].append(doc_info)
            total_score += doc_info['score']
        
        # ì¦ê±° ê°•ë„ ê³„ì‚°
        if reranked_results:
            context['evidence_strength'] = total_score / len(reranked_results)
        
        return context
    
    def _generate_enhanced_response(
        self,
        query: str,
        context: Dict[str, Any],
        response_style: str,
        image_analysis: Optional[Dict[str, Any]]
    ) -> str:
        """í–¥ìƒëœ ì‘ë‹µ ìƒì„±"""
        # ChatGPT ìŠ¤íƒ€ì¼ ì‘ë‹µ ìƒì„±
        chatgpt_context = context.copy()
        if image_analysis:
            chatgpt_context['image_analysis'] = image_analysis
        
        response = self.response_generator.generate_response(
            question=query,
            context=chatgpt_context,
            response_type=response_style
        )
        
        # ì¦ê±° ê°•ë„ì— ë”°ë¥¸ ì‹ ë¢°ë„ í‘œì‹œ
        confidence_level = self._get_confidence_level(context['evidence_strength'])
        response += f"\n\nğŸ“Š **ì‹ ë¢°ë„**: {confidence_level}"
        
        # ë¦¬ë­í‚¹ ì ìˆ˜ ì •ë³´
        if context['retrieved_documents']:
            response += f"\nğŸ’¡ **ê²€ìƒ‰ í’ˆì§ˆ**: {context['evidence_strength']:.2f}/1.0"
        
        return response
    
    def _get_confidence_level(self, score: float) -> str:
        """ì‹ ë¢°ë„ ë ˆë²¨ ê²°ì •"""
        if score >= 0.8:
            return "ë§¤ìš° ë†’ìŒ â­â­â­â­â­"
        elif score >= 0.6:
            return "ë†’ìŒ â­â­â­â­"
        elif score >= 0.4:
            return "ë³´í†µ â­â­â­"
        elif score >= 0.2:
            return "ë‚®ìŒ â­â­"
        else:
            return "ë§¤ìš° ë‚®ìŒ â­"
    
    def _format_evidence(self, evidence_list) -> List[Dict[str, Any]]:
        """ì¦ê±° í¬ë§·íŒ…"""
        formatted = []
        for evidence in evidence_list[:5]:  # ìƒìœ„ 5ê°œ
            formatted.append({
                'content': evidence.content[:200] + "...",
                'type': evidence.evidence_type,
                'relevance': evidence.relevance_score
            })
        return formatted
    
    def _format_search_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…"""
        formatted = []
        for result in results:
            formatted.append({
                'content': self._extract_text(result)[:200] + "...",
                'score': result.get('final_rerank_score', result.get('rerank_score', 0)),
                'score_details': result.get('score_details', {})
            })
        return formatted
    
    def _extract_text(self, doc: Dict[str, Any]) -> str:
        """ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if 'documents' in doc and doc['documents']:
            return doc['documents'][0]
        elif 'content' in doc:
            return doc['content']
        elif 'text' in doc:
            return doc['text']
        else:
            return str(doc)
    
    def _format_context_for_prompt(self, context: Dict[str, Any]) -> str:
        """í”„ë¡¬í”„íŠ¸ìš© ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…"""
        formatted = ""
        for i, doc in enumerate(context.get('retrieved_documents', [])[:3]):
            formatted += f"\n[ë¬¸ì„œ {i+1}] (ì ìˆ˜: {doc.get('score', 0):.3f})\n"
            formatted += f"{doc['content'][:300]}...\n"
        return formatted


def create_advanced_rag_system(config, llm_client) -> AdvancedRAGSystem:
    """ê³ ê¸‰ RAG ì‹œìŠ¤í…œ ìƒì„±"""
    # í–¥ìƒëœ ë²¡í„° DB
    vector_db = EnhancedVectorDatabase(
        persist_directory=config.rag.persist_directory
    )
    
    # ê³ ê¸‰ RAG ì‹œìŠ¤í…œ
    return AdvancedRAGSystem(
        vector_db=vector_db,
        llm_client=llm_client
    )


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    from config import Config
    from llm_client import LLMClient
    
    config = Config()
    llm_client = LLMClient(config.llm)
    
    # ì‹œìŠ¤í…œ ìƒì„±
    rag_system = create_advanced_rag_system(config, llm_client)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_query = "3ìƒ ì „ë ¥ ì‹œìŠ¤í…œì—ì„œ ì„ ê°„ì „ì••ì´ 380Vì´ê³  ì—­ë¥ ì´ 0.8ì¼ ë•Œ ì „ë ¥ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì€?"
    
    # ì¶”ë¡  ëª¨ë“œë¡œ ì²˜ë¦¬
    result = rag_system.process_query_advanced(
        query=test_query,
        mode='reasoning'
    )
    
    if result['success']:
        print(f"ì‘ë‹µ:\n{result['response']}")
        print(f"\nì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
        print(f"ì²˜ë¦¬ ëª¨ë“œ: {result['mode']}")