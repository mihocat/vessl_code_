#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê³ ê¸‰ í†µí•© ì• í”Œë¦¬ì¼€ì´ì…˜
ê±°ì‹œì  ì‹œìŠ¤í…œì„ í™œìš©í•œ ì „ê¸°ê³µí•™ AI íŠœí„°
"""

import gradio as gr
import asyncio
import logging
from typing import Dict, Any, List, Optional, Tuple
from PIL import Image
import json
import pandas as pd
from datetime import datetime
import os

# ë¡œì»¬ ëª¨ë“ˆ
from integrated_ai_system import IntegratedAISystem, AutoEvaluator
from config import Config
from llm_client import LLMClient

logger = logging.getLogger(__name__)


class ElectricalAITutor:
    """ì „ê¸°ê³µí•™ AI íŠœí„°"""
    
    def __init__(self):
        self.ai_system = None
        self.evaluator = None
        self.history = []
        self.initialized = False
        
    async def initialize(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            logger.info("Initializing Electrical AI Tutor...")
            
            # ì„¤ì • ë¡œë“œ
            config = Config()
            llm_client = LLMClient(config.llm)
            
            # AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self.ai_system = IntegratedAISystem()
            await self.ai_system.initialize({
                'rag': config.rag,
                'dataset': config.dataset,
                'llm_client': llm_client
            })
            
            # í‰ê°€ê¸° ì´ˆê¸°í™”
            self.evaluator = AutoEvaluator(self.ai_system)
            
            self.initialized = True
            logger.info("Electrical AI Tutor initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize: {e}")
            raise
    
    async def solve_problem(
        self,
        text: str,
        image: Optional[np.ndarray] = None,
        show_steps: bool = True,
        explain_detail: bool = True
    ) -> Tuple[str, str, Dict[str, Any]]:
        """ë¬¸ì œ í•´ê²°"""
        
        if not self.initialized:
            await self.initialize()
        
        try:
            # PIL Imageë¡œ ë³€í™˜
            pil_image = None
            if image is not None:
                pil_image = Image.fromarray(image)
            
            # ë¬¸ì œ í•´ê²°
            solution = await self.ai_system.solve_problem(
                image=pil_image,
                text=text
            )
            
            # ê²°ê³¼ í¬ë§·íŒ…
            main_answer = self._format_main_answer(solution)
            detailed_solution = self._format_detailed_solution(
                solution, show_steps, explain_detail
            )
            
            # íˆìŠ¤í† ë¦¬ ì €ì¥
            self.history.append({
                'timestamp': datetime.now().isoformat(),
                'problem': text,
                'solution': solution,
                'has_image': image is not None
            })
            
            # ë¶„ì„ ë°ì´í„°
            analysis = {
                'problem_type': solution.problem_id,
                'confidence': solution.confidence,
                'formulas_used': solution.formulas_used,
                'verification': solution.verification
            }
            
            return main_answer, detailed_solution, analysis
            
        except Exception as e:
            logger.error(f"Problem solving failed: {e}")
            error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            return error_msg, error_msg, {}
    
    def _format_main_answer(self, solution) -> str:
        """ì£¼ìš” ë‹µë³€ í¬ë§·íŒ…"""
        answer = "## ìµœì¢… ë‹µ\n\n"
        
        if solution.final_answer and 'primary_answer' in solution.final_answer:
            pa = solution.final_answer['primary_answer']
            answer += f"**{pa['variable']} = {pa['value']:.3f} {pa['unit']}**\n\n"
        
        # ëª¨ë“  ê³„ì‚°ëœ ê°’
        if solution.final_answer and 'values' in solution.final_answer:
            answer += "### ê³„ì‚°ëœ ê°’ë“¤:\n"
            for var, val in solution.final_answer['values'].items():
                unit = self.ai_system.formula_solver._infer_unit(var)
                answer += f"- {var} = {val:.3f} {unit}\n"
        
        # ì‹ ë¢°ë„
        answer += f"\nì‹ ë¢°ë„: {solution.confidence:.0%}"
        
        return answer
    
    def _format_detailed_solution(
        self, 
        solution,
        show_steps: bool,
        explain_detail: bool
    ) -> str:
        """ìƒì„¸ í•´ê²° ê³¼ì • í¬ë§·íŒ…"""
        detailed = "## ìƒì„¸ í’€ì´ ê³¼ì •\n\n"
        
        # ì‚¬ìš©ëœ ê³µì‹
        if solution.formulas_used:
            detailed += "### ì‚¬ìš©ëœ ê³µì‹\n"
            for formula in solution.formulas_used:
                detailed += f"- {formula}\n"
            detailed += "\n"
        
        # ë‹¨ê³„ë³„ í’€ì´
        if show_steps and solution.steps:
            detailed += "### ë‹¨ê³„ë³„ ê³„ì‚°\n"
            for i, step in enumerate(solution.steps, 1):
                detailed += f"\n**Step {i}: {step['variable']} ê³„ì‚°**\n"
                detailed += f"- ê³µì‹: {step['formula']}\n"
                detailed += f"- ê³„ì‚°: {step['calculation']}\n"
                
                # ì‚¬ìš©ëœ ê°’ë“¤
                if 'used_values' in step:
                    detailed += "- ì‚¬ìš©ëœ ê°’: "
                    for var, val in step['used_values'].items():
                        detailed += f"{var}={val:.3f}, "
                    detailed = detailed.rstrip(", ") + "\n"
                
                detailed += f"- **ê²°ê³¼: {step['result']:.3f}**\n"
        
        # ìƒì„¸ ì„¤ëª…
        if explain_detail and solution.explanation:
            detailed += f"\n### ì„¤ëª…\n{solution.explanation}\n"
        
        # ê²€ì¦ ê²°ê³¼
        if solution.verification:
            detailed += "\n### ê²€ì¦\n"
            for check, passed in solution.verification.items():
                status = "âœ…" if passed else "âŒ"
                detailed += f"- {check}: {status}\n"
        
        return detailed
    
    async def batch_evaluate(self, test_file: str) -> Tuple[str, pd.DataFrame]:
        """ì¼ê´„ í‰ê°€"""
        if not self.initialized:
            await self.initialize()
        
        try:
            # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë¡œë“œ
            self.evaluator.load_test_cases(test_file)
            
            # í‰ê°€ ìˆ˜í–‰
            results = await self.evaluator.evaluate()
            
            # ë³´ê³ ì„œ
            report = results['report']
            
            # ìƒì„¸ ê²°ê³¼ DataFrame
            data = []
            for r in results['results']:
                data.append({
                    'Test ID': r['test_id'],
                    'Problem Type': r['problem_type'],
                    'Correct': 'âœ…' if r['correct'] else 'âŒ',
                    'Confidence': f"{r['solution'].confidence:.2f}",
                    'Score': f"{r['score']:.2f}"
                })
            
            df = pd.DataFrame(data)
            
            return report, df
            
        except Exception as e:
            logger.error(f"Batch evaluation failed: {e}")
            return f"í‰ê°€ ì‹¤íŒ¨: {str(e)}", pd.DataFrame()
    
    def get_history(self) -> pd.DataFrame:
        """íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        if not self.history:
            return pd.DataFrame()
        
        data = []
        for h in self.history:
            data.append({
                'Time': h['timestamp'],
                'Problem': h['problem'][:50] + '...' if len(h['problem']) > 50 else h['problem'],
                'Type': h['solution'].problem_id,
                'Confidence': f"{h['solution'].confidence:.0%}",
                'Image': 'ğŸ“·' if h['has_image'] else ''
            })
        
        return pd.DataFrame(data)
    
    def export_history(self, format: str = 'json') -> str:
        """íˆìŠ¤í† ë¦¬ ë‚´ë³´ë‚´ê¸°"""
        if format == 'json':
            # JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
            export_data = []
            for h in self.history:
                export_data.append({
                    'timestamp': h['timestamp'],
                    'problem': h['problem'],
                    'solution': {
                        'answer': h['solution'].final_answer,
                        'steps': h['solution'].steps,
                        'confidence': h['solution'].confidence
                    }
                })
            
            filename = f"history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            return filename
        
        return ""


def create_advanced_interface():
    """ê³ ê¸‰ Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    tutor = ElectricalAITutor()
    
    # ë¹„ë™ê¸° ë˜í¼
    async def solve_wrapper(text, image, show_steps, explain_detail):
        return await tutor.solve_problem(text, image, show_steps, explain_detail)
    
    def solve_sync(text, image, show_steps, explain_detail):
        return asyncio.run(solve_wrapper(text, image, show_steps, explain_detail))
    
    async def evaluate_wrapper(file):
        if file is None:
            return "íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", pd.DataFrame()
        return await tutor.batch_evaluate(file.name)
    
    def evaluate_sync(file):
        return asyncio.run(evaluate_wrapper(file))
    
    def get_history_sync():
        return tutor.get_history()
    
    def export_history_sync(format):
        filename = tutor.export_history(format)
        return f"ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {filename}"
    
    # Gradio ì¸í„°í˜ì´ìŠ¤
    with gr.Blocks(title="ì „ê¸°ê³µí•™ AI íŠœí„°", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸ“ ì „ê¸°ê³µí•™ AI íŠœí„°
        
        ê³ ê¸‰ í†µí•© AI ì‹œìŠ¤í…œì„ í™œìš©í•œ ì „ê¸°ê³µí•™ ë¬¸ì œ í•´ê²° ë„ìš°ë¯¸
        
        ## ì£¼ìš” ê¸°ëŠ¥
        - ğŸ“¸ ì´ë¯¸ì§€ì—ì„œ ìˆ˜ì‹ê³¼ ë¬¸ì œ ìë™ ì¸ì‹ (OCR)
        - ğŸ§® ì „ê¸°ê³µí•™ ê³µì‹ ê¸°ë°˜ ìë™ ê³„ì‚°
        - ğŸ“š RAG ì‹œìŠ¤í…œì„ í†µí•œ ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰
        - ğŸ¤– LLMì„ í™œìš©í•œ ìƒì„¸ ì„¤ëª… ìƒì„±
        - âœ… ìë™ ê²€ì¦ ë° í‰ê°€
        """)
        
        with gr.Tab("ë¬¸ì œ í•´ê²°"):
            with gr.Row():
                with gr.Column(scale=1):
                    text_input = gr.Textbox(
                        label="ë¬¸ì œ ì„¤ëª…",
                        placeholder="ë¬¸ì œë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”...",
                        lines=5
                    )
                    image_input = gr.Image(
                        label="ë¬¸ì œ ì´ë¯¸ì§€ (ì„ íƒ)",
                        type="numpy"
                    )
                    
                    with gr.Row():
                        show_steps = gr.Checkbox(
                            label="ë‹¨ê³„ë³„ í’€ì´ í‘œì‹œ",
                            value=True
                        )
                        explain_detail = gr.Checkbox(
                            label="ìƒì„¸ ì„¤ëª… í¬í•¨",
                            value=True
                        )
                    
                    solve_btn = gr.Button(
                        "ğŸ” ë¬¸ì œ í•´ê²°",
                        variant="primary",
                        size="lg"
                    )
                    
                    # ì˜ˆì œ
                    gr.Examples(
                        examples=[
                            ["ìœ íš¨ì „ë ¥ 320kW, ë¬´íš¨ì „ë ¥ 140kVarì¼ ë•Œ ì—­ë¥ ì€?", None],
                            ["3ìƒ ë¶€í•˜ì˜ í”¼ìƒì „ë ¥ì´ 500kVAì´ê³  ì—­ë¥ ì´ 0.8ì¼ ë•Œ, ìœ íš¨ì „ë ¥ê³¼ ë¬´íš¨ì „ë ¥ì„ êµ¬í•˜ì‹œì˜¤.", None],
                            ["100Î©ì˜ ì €í•­ê³¼ 50Î©ì˜ ë¦¬ì•¡í„´ìŠ¤ê°€ ì§ë ¬ ì—°ê²°ë˜ì–´ ìˆì„ ë•Œ ì„í”¼ë˜ìŠ¤ëŠ”?", None]
                        ],
                        inputs=[text_input, image_input]
                    )
                
                with gr.Column(scale=1):
                    main_answer = gr.Markdown(
                        label="ìµœì¢… ë‹µ",
                        value="ì—¬ê¸°ì— ë‹µì´ í‘œì‹œë©ë‹ˆë‹¤."
                    )
                    
                    detailed_solution = gr.Markdown(
                        label="ìƒì„¸ í’€ì´",
                        value="ìƒì„¸í•œ í’€ì´ ê³¼ì •ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤."
                    )
                    
                    with gr.Accordion("ë¶„ì„ ì •ë³´", open=False):
                        analysis_json = gr.JSON(
                            label="ìƒì„¸ ë¶„ì„"
                        )
            
            solve_btn.click(
                fn=solve_sync,
                inputs=[text_input, image_input, show_steps, explain_detail],
                outputs=[main_answer, detailed_solution, analysis_json]
            )
        
        with gr.Tab("ì¼ê´„ í‰ê°€"):
            gr.Markdown("""
            ### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¼ê´„ í‰ê°€
            
            JSON í˜•ì‹ì˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì—¬ëŸ¬ ë¬¸ì œë¥¼ í•œë²ˆì— í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            """)
            
            test_file = gr.File(
                label="í…ŒìŠ¤íŠ¸ íŒŒì¼ (JSON)",
                file_types=[".json"]
            )
            
            evaluate_btn = gr.Button("ğŸ“Š í‰ê°€ ì‹œì‘", variant="primary")
            
            eval_report = gr.Markdown(label="í‰ê°€ ë³´ê³ ì„œ")
            eval_results = gr.DataFrame(label="ìƒì„¸ ê²°ê³¼")
            
            evaluate_btn.click(
                fn=evaluate_sync,
                inputs=test_file,
                outputs=[eval_report, eval_results]
            )
        
        with gr.Tab("íˆìŠ¤í† ë¦¬"):
            gr.Markdown("### ë¬¸ì œ í•´ê²° íˆìŠ¤í† ë¦¬")
            
            with gr.Row():
                refresh_btn = gr.Button("ğŸ”„ ìƒˆë¡œê³ ì¹¨")
                export_format = gr.Dropdown(
                    choices=["json"],
                    value="json",
                    label="ë‚´ë³´ë‚´ê¸° í˜•ì‹"
                )
                export_btn = gr.Button("ğŸ’¾ ë‚´ë³´ë‚´ê¸°")
            
            history_table = gr.DataFrame(
                label="íˆìŠ¤í† ë¦¬",
                interactive=False
            )
            
            export_status = gr.Textbox(
                label="ë‚´ë³´ë‚´ê¸° ìƒíƒœ",
                interactive=False
            )
            
            refresh_btn.click(
                fn=get_history_sync,
                outputs=history_table
            )
            
            export_btn.click(
                fn=export_history_sync,
                inputs=export_format,
                outputs=export_status
            )
            
            # ì´ˆê¸° íˆìŠ¤í† ë¦¬ ë¡œë“œ
            demo.load(fn=get_history_sync, outputs=history_table)
        
        with gr.Tab("ë„ì›€ë§"):
            gr.Markdown("""
            ## ì‚¬ìš© ë°©ë²•
            
            ### 1. ë¬¸ì œ ì…ë ¥
            - í…ìŠ¤íŠ¸ë¡œ ë¬¸ì œë¥¼ ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜
            - ë¬¸ì œê°€ í¬í•¨ëœ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”
            - ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤
            
            ### 2. ì§€ì›ë˜ëŠ” ë¬¸ì œ ìœ í˜•
            - **ì—­ë¥  ê³„ì‚°**: ìœ íš¨ì „ë ¥, ë¬´íš¨ì „ë ¥, í”¼ìƒì „ë ¥, ì—­ë¥ 
            - **íšŒë¡œ í•´ì„**: ì˜´ì˜ ë²•ì¹™, ì „ë ¥ ê³„ì‚°
            - **ì„í”¼ë˜ìŠ¤**: ì§ë ¬/ë³‘ë ¬ ì„í”¼ë˜ìŠ¤, ìœ„ìƒê°
            - **ë³€ì••ê¸°**: ë³€ì••ë¹„, ì „ë ¥ ë³€í™˜
            - **ì „ë™ê¸°**: ì¶œë ¥, íš¨ìœ¨, ì—­ë¥ 
            
            ### 3. ì¶œë ¥ ì„¤ëª…
            - **ìµœì¢… ë‹µ**: êµ¬í•˜ê³ ì í•˜ëŠ” ê°’ì˜ ê³„ì‚° ê²°ê³¼
            - **ìƒì„¸ í’€ì´**: ë‹¨ê³„ë³„ ê³„ì‚° ê³¼ì •ê³¼ ì‚¬ìš©ëœ ê³µì‹
            - **ê²€ì¦**: ë‹µì˜ ë¬¼ë¦¬ì  íƒ€ë‹¹ì„± ê²€ì¦
            
            ### 4. ì¼ê´„ í‰ê°€
            í…ŒìŠ¤íŠ¸ íŒŒì¼ í˜•ì‹:
            ```json
            [
                {
                    "id": "test_001",
                    "type": "power_factor",
                    "text": "ë¬¸ì œ ì„¤ëª…",
                    "expected_answer": {"value": 0.8}
                }
            ]
            ```
            """)
    
    return demo


if __name__ == "__main__":
    demo = create_advanced_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )