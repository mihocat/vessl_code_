#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced RAG System with Multimodal Support
ë©€í‹°ëª¨ë‹¬ ì§€ì›ì„ ìœ„í•œ í–¥ìƒëœ RAG ì‹œìŠ¤í…œ
"""

import logging
from typing import Dict, List, Any, Optional, Union, Tuple
import numpy as np
import torch
from PIL import Image
import json
import re
from datetime import datetime

# ë²¡í„° DB
import chromadb
from chromadb.config import Settings
from chromadb.utils import embedding_functions

# ì„ë² ë”© ëª¨ë¸
from sentence_transformers import SentenceTransformer

# ê¸°ì¡´ RAG ì‹œìŠ¤í…œ
from rag_system import SearchResult, VectorStore

# ë©€í‹°ëª¨ë‹¬ ì»´í¬ë„ŒíŠ¸
from enhanced_image_analyzer import ChatGPTStyleAnalyzer
from chatgpt_response_generator import ChatGPTResponseGenerator

logger = logging.getLogger(__name__)


class MultimodalEmbedder:
    """ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ìƒì„±ê¸°"""
    
    def __init__(self):
        """ë©€í‹°ëª¨ë‹¬ ì„ë² ë” ì´ˆê¸°í™”"""
        # í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸
        self.text_embedder = SentenceTransformer('jinaai/jina-embeddings-v3', trust_remote_code=True)
        
        # ìˆ˜ì‹ ì„ë² ë”©ì„ ìœ„í•œ ì „ì²˜ë¦¬ê¸°
        self.formula_preprocessor = FormulaPreprocessor()
        
        # ì´ë¯¸ì§€ ë¶„ì„ê¸°
        self.image_analyzer = ChatGPTStyleAnalyzer()
        
        logger.info("Multimodal embedder initialized")
    
    def embed_text(self, text: str) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ì„ë² ë”©"""
        return self.text_embedder.encode(text, convert_to_numpy=True)
    
    def embed_formula(self, formula: str) -> np.ndarray:
        """ìˆ˜ì‹ ì„ë² ë”© (LaTeX)"""
        # ìˆ˜ì‹ ì •ê·œí™”
        normalized = self.formula_preprocessor.normalize(formula)
        
        # ìˆ˜ì‹ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        text_repr = self.formula_preprocessor.to_text(normalized)
        
        # ì„ë² ë”©
        return self.text_embedder.encode(text_repr, convert_to_numpy=True)
    
    def embed_multimodal(self, content: Dict[str, Any]) -> np.ndarray:
        """ë©€í‹°ëª¨ë‹¬ ì»¨í…ì¸  í†µí•© ì„ë² ë”©"""
        embeddings = []
        weights = []
        
        # í…ìŠ¤íŠ¸ ì„ë² ë”©
        if content.get('text'):
            text_emb = self.embed_text(content['text'])
            embeddings.append(text_emb)
            weights.append(0.5)  # í…ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜
        
        # ìˆ˜ì‹ ì„ë² ë”©
        if content.get('formulas'):
            formula_embs = [self.embed_formula(f) for f in content['formulas']]
            if formula_embs:
                avg_formula_emb = np.mean(formula_embs, axis=0)
                embeddings.append(avg_formula_emb)
                weights.append(0.3)  # ìˆ˜ì‹ ê°€ì¤‘ì¹˜
        
        # ë‹¤ì´ì–´ê·¸ë¨ ì„¤ëª… ì„ë² ë”©
        if content.get('diagrams'):
            diagram_texts = []
            for diagram in content['diagrams']:
                if isinstance(diagram, dict):
                    components = diagram.get('components', [])
                    diagram_text = ' '.join([c.get('label', '') for c in components])
                    diagram_texts.append(diagram_text)
            
            if diagram_texts:
                diagram_emb = self.embed_text(' '.join(diagram_texts))
                embeddings.append(diagram_emb)
                weights.append(0.2)  # ë‹¤ì´ì–´ê·¸ë¨ ê°€ì¤‘ì¹˜
        
        # ê°€ì¤‘ í‰ê· 
        if embeddings:
            weights = np.array(weights) / np.sum(weights)
            combined = np.sum([emb * w for emb, w in zip(embeddings, weights)], axis=0)
            return combined
        
        # ë¹ˆ ì»¨í…ì¸ ì˜ ê²½ìš°
        return np.zeros(self.text_embedder.get_sentence_embedding_dimension())


class FormulaPreprocessor:
    """ìˆ˜ì‹ ì „ì²˜ë¦¬ê¸°"""
    
    def normalize(self, formula: str) -> str:
        """LaTeX ìˆ˜ì‹ ì •ê·œí™”"""
        # ê³µë°± ì •ë¦¬
        formula = re.sub(r'\s+', ' ', formula.strip())
        
        # ë¶„ìˆ˜ ì •ê·œí™”
        formula = re.sub(r'\\frac\s*\{([^}]+)\}\s*\{([^}]+)\}', r'(\1)/(\2)', formula)
        
        # ì œê³± ì •ê·œí™”
        formula = re.sub(r'\^(\d+)', r'^{\1}', formula)
        formula = re.sub(r'\^\{([^}]+)\}', r'^(\1)', formula)
        
        return formula
    
    def to_text(self, formula: str) -> str:
        """ìˆ˜ì‹ì„ í…ìŠ¤íŠ¸ í‘œí˜„ìœ¼ë¡œ ë³€í™˜"""
        # LaTeX ëª…ë ¹ì–´ë¥¼ í…ìŠ¤íŠ¸ë¡œ
        replacements = {
            r'\\sqrt': 'square root of',
            r'\\times': 'times',
            r'\\div': 'divided by',
            r'\\pm': 'plus minus',
            r'\\sum': 'sum of',
            r'\\int': 'integral of',
            r'\\alpha': 'alpha',
            r'\\beta': 'beta',
            r'\\gamma': 'gamma',
            r'\\theta': 'theta',
            r'\\omega': 'omega',
            r'\\Omega': 'Omega',
            r'\\pi': 'pi',
            r'\\cos': 'cosine',
            r'\\sin': 'sine',
            r'\\tan': 'tangent',
        }
        
        text = formula
        for latex, plain in replacements.items():
            text = text.replace(latex, plain)
        
        # íŠ¹ìˆ˜ ê¸°í˜¸ ì œê±°
        text = re.sub(r'[{}\\]', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()


class HybridSearchEngine:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ (í‚¤ì›Œë“œ + ë²¡í„°)"""
    
    def __init__(self, vector_db: 'EnhancedVectorDatabase'):
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”"""
        self.vector_db = vector_db
        self.keyword_index = {}
        
        # ì „ê¸°ê³µí•™ í‚¤ì›Œë“œ ì‚¬ì „
        self.domain_keywords = {
            'ì „ì••': ['voltage', 'V', 'ë³¼íŠ¸'],
            'ì „ë¥˜': ['current', 'I', 'ì•”í˜ì–´', 'A'],
            'ì €í•­': ['resistance', 'R', 'ì˜´', 'Î©'],
            'ì „ë ¥': ['power', 'P', 'ì™€íŠ¸', 'W'],
            'ì„í”¼ë˜ìŠ¤': ['impedance', 'Z'],
            'ì—­ë¥ ': ['power factor', 'PF', 'cosÎ¸'],
            'ë³€ì••ê¸°': ['transformer', 'ë³€í™˜'],
            'ëª¨í„°': ['motor', 'ì „ë™ê¸°'],
        }
    
    def build_keyword_index(self, documents: List[Dict[str, Any]]):
        """í‚¤ì›Œë“œ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        self.keyword_index = {}
        
        for i, doc in enumerate(documents):
            text = doc.get('text', '').lower()
            
            # ë„ë©”ì¸ í‚¤ì›Œë“œ ì¶”ì¶œ
            for main_term, variations in self.domain_keywords.items():
                for term in [main_term] + variations:
                    if term.lower() in text:
                        if term not in self.keyword_index:
                            self.keyword_index[term] = []
                        self.keyword_index[term].append(i)
    
    def search(
        self, 
        query: str, 
        image_analysis: Optional[Dict[str, Any]] = None,
        k: int = 10,
        alpha: float = 0.7
    ) -> List[Dict[str, Any]]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            image_analysis: ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            alpha: ë²¡í„° ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (1-alphaëŠ” í‚¤ì›Œë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜)
        """
        # 1. ë²¡í„° ê²€ìƒ‰
        vector_results = self.vector_db.search(query, k=k*2)
        
        # 2. í‚¤ì›Œë“œ ê²€ìƒ‰
        keyword_scores = self._keyword_search(query)
        
        # 3. ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ìˆëŠ” ê²½ìš°)
        if image_analysis:
            image_scores = self._image_context_search(image_analysis)
            
            # ì ìˆ˜ ê²°í•©
            for doc_id, score in image_scores.items():
                if doc_id in keyword_scores:
                    keyword_scores[doc_id] += score * 0.3
                else:
                    keyword_scores[doc_id] = score * 0.3
        
        # 4. ì ìˆ˜ ê²°í•©
        combined_scores = {}
        
        # ë²¡í„° ê²€ìƒ‰ ì ìˆ˜
        for result in vector_results:
            doc_id = result['metadata'].get('doc_id', result['id'])
            combined_scores[doc_id] = alpha * (1 - result['distance'])
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ì ìˆ˜
        max_keyword_score = max(keyword_scores.values()) if keyword_scores else 1
        for doc_id, score in keyword_scores.items():
            normalized_score = score / max_keyword_score
            if doc_id in combined_scores:
                combined_scores[doc_id] += (1 - alpha) * normalized_score
            else:
                combined_scores[doc_id] = (1 - alpha) * normalized_score
        
        # 5. ìƒìœ„ kê°œ ì„ íƒ
        sorted_docs = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)
        
        # ê²°ê³¼ êµ¬ì„±
        results = []
        for doc_id, score in sorted_docs[:k]:
            # ì›ë³¸ ë¬¸ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            doc_info = self._get_document_info(doc_id, vector_results)
            if doc_info:
                doc_info['hybrid_score'] = score
                results.append(doc_info)
        
        return results
    
    def _keyword_search(self, query: str) -> Dict[str, float]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰"""
        scores = {}
        query_lower = query.lower()
        
        # ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        for term, doc_ids in self.keyword_index.items():
            if term.lower() in query_lower:
                for doc_id in doc_ids:
                    if doc_id not in scores:
                        scores[doc_id] = 0
                    scores[doc_id] += 1
        
        return scores
    
    def _image_context_search(self, image_analysis: Dict[str, Any]) -> Dict[str, float]:
        """ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰"""
        scores = {}
        
        # ìˆ˜ì‹ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        if image_analysis.get('formulas'):
            for formula in image_analysis['formulas']:
                # ìˆ˜ì‹ì—ì„œ ë³€ìˆ˜/ìƒìˆ˜ ì¶”ì¶œ
                variables = re.findall(r'[A-Za-z]+', formula)
                for var in variables:
                    if var in self.keyword_index:
                        for doc_id in self.keyword_index[var]:
                            if doc_id not in scores:
                                scores[doc_id] = 0
                            scores[doc_id] += 0.5
        
        # ë‹¤ì´ì–´ê·¸ë¨ ì»´í¬ë„ŒíŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        if image_analysis.get('diagrams'):
            for diagram in image_analysis['diagrams']:
                if isinstance(diagram, dict) and 'components' in diagram:
                    for comp in diagram['components']:
                        label = comp.get('label', '')
                        if label in self.keyword_index:
                            for doc_id in self.keyword_index[label]:
                                if doc_id not in scores:
                                    scores[doc_id] = 0
                                scores[doc_id] += 0.3
        
        return scores
    
    def _get_document_info(self, doc_id: str, vector_results: List[Dict]) -> Optional[Dict]:
        """ë¬¸ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        for result in vector_results:
            if result['metadata'].get('doc_id', result['id']) == doc_id:
                return result
        return None


class EnhancedVectorDatabase(VectorStore):
    """í–¥ìƒëœ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤"""
    
    def __init__(self, rag_config=None, embedding_model=None):
        """í–¥ìƒëœ ë²¡í„° DB ì´ˆê¸°í™”"""
        # ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
        if rag_config is None:
            from config import RAGConfig
            rag_config = RAGConfig()
            
        # ì„ë² ë”© ëª¨ë¸ì´ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        if embedding_model is None:
            from sentence_transformers import SentenceTransformer
            embedding_model = SentenceTransformer(rag_config.embedding_model_name, trust_remote_code=True)
        
        # ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        super().__init__(rag_config, embedding_model)
        
        # ë©€í‹°ëª¨ë‹¬ ì„ë² ë”
        self.multimodal_embedder = MultimodalEmbedder()
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„
        self.hybrid_search = HybridSearchEngine(self)
        
        # ë©”íƒ€ë°ì´í„° ì¸ë±ìŠ¤
        self.metadata_index = {
            'formulas': {},
            'concepts': {},
            'difficulty': {}
        }
    
    def add_multimodal_document(
        self,
        content: Dict[str, Any],
        metadata: Optional[Dict[str, Any]] = None
    ) -> str:
        """ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ì¶”ê°€"""
        # ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ìƒì„±
        embedding = self.multimodal_embedder.embed_multimodal(content)
        
        # ë©”íƒ€ë°ì´í„° êµ¬ì„±
        if metadata is None:
            metadata = {}
        
        metadata.update({
            'has_formulas': len(content.get('formulas', [])) > 0,
            'has_diagrams': len(content.get('diagrams', [])) > 0,
            'content_type': 'multimodal',
            'timestamp': datetime.now().isoformat()
        })
        
        # ë¬¸ì„œ ID ìƒì„±
        doc_id = f"multimodal_{datetime.now().timestamp()}"
        
        # ChromaDBì— ì¶”ê°€
        self.collection.add(
            embeddings=[embedding.tolist()],
            documents=[json.dumps(content, ensure_ascii=False)],
            metadatas=[metadata],
            ids=[doc_id]
        )
        
        # ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        self._update_indexes(doc_id, content, metadata)
        
        return doc_id
    
    def _update_indexes(self, doc_id: str, content: Dict[str, Any], metadata: Dict[str, Any]):
        """ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸"""
        # ìˆ˜ì‹ ì¸ë±ìŠ¤
        if content.get('formulas'):
            for formula in content['formulas']:
                formula_key = self._normalize_formula_key(formula)
                if formula_key not in self.metadata_index['formulas']:
                    self.metadata_index['formulas'][formula_key] = []
                self.metadata_index['formulas'][formula_key].append(doc_id)
        
        # ê°œë… ì¸ë±ìŠ¤
        if metadata.get('concepts'):
            for concept in metadata['concepts']:
                if concept not in self.metadata_index['concepts']:
                    self.metadata_index['concepts'][concept] = []
                self.metadata_index['concepts'][concept].append(doc_id)
    
    def _normalize_formula_key(self, formula: str) -> str:
        """ìˆ˜ì‹ í‚¤ ì •ê·œí™”"""
        # ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜
        key = re.sub(r'\s+', '', formula.lower())
        # LaTeX ëª…ë ¹ì–´ ì œê±°
        key = re.sub(r'\\[a-zA-Z]+', '', key)
        return key
    
    def search_multimodal(
        self,
        query: str,
        image_analysis: Optional[Dict[str, Any]] = None,
        k: int = 5,
        filter_metadata: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰"""
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
        results = self.hybrid_search.search(
            query=query,
            image_analysis=image_analysis,
            k=k
        )
        
        # ë©”íƒ€ë°ì´í„° í•„í„°ë§
        if filter_metadata:
            results = [r for r in results if self._match_metadata(r['metadata'], filter_metadata)]
        
        # ê²°ê³¼ í›„ì²˜ë¦¬
        processed_results = []
        for result in results:
            # JSON ë¬¸ì„œ íŒŒì‹±
            if result['documents']:
                try:
                    content = json.loads(result['documents'][0])
                    result['parsed_content'] = content
                except:
                    pass
            
            processed_results.append(result)
        
        return processed_results
    
    def _match_metadata(self, doc_metadata: Dict, filter_metadata: Dict) -> bool:
        """ë©”íƒ€ë°ì´í„° ë§¤ì¹­"""
        for key, value in filter_metadata.items():
            if key not in doc_metadata:
                return False
            if isinstance(value, list):
                if doc_metadata[key] not in value:
                    return False
            elif doc_metadata[key] != value:
                return False
        return True


class EnhancedRAGSystem:
    """í–¥ìƒëœ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, vector_db: EnhancedVectorDatabase, llm_client):
        """í–¥ìƒëœ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.vector_db = vector_db
        self.llm_client = llm_client
        self.response_generator = ChatGPTResponseGenerator()
        self.image_analyzer = ChatGPTStyleAnalyzer()
        
        logger.info("Enhanced RAG system initialized")
    
    def process_query(
        self,
        query: str,
        image: Optional[Union[Image.Image, str, bytes]] = None,
        response_style: str = 'comprehensive'
    ) -> Dict[str, Any]:
        """
        ì¿¼ë¦¬ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€)
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            image: ì´ë¯¸ì§€ (ì„ íƒì )
            response_style: ì‘ë‹µ ìŠ¤íƒ€ì¼
        """
        # 1. ì´ë¯¸ì§€ ë¶„ì„ (ìˆëŠ” ê²½ìš°)
        image_analysis = None
        if image:
            logger.info("Analyzing image for context...")
            
            # ë©€í‹°ëª¨ë‹¬ OCR íŒŒì´í”„ë¼ì¸ ìš°ì„  ì‚¬ìš©
            try:
                from multimodal_ocr import MultimodalOCRPipeline
                ocr_pipeline = MultimodalOCRPipeline()
                ocr_result = ocr_pipeline.process_image(image)
                
                # OCR ê²°ê³¼ë¥¼ image_analysis í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                image_analysis = {
                    'success': True,
                    'ocr_text': ocr_result.get('text_content', ''),
                    'formulas': ocr_result.get('formulas', []),
                    'diagrams': ocr_result.get('diagrams', []),
                    'tables': ocr_result.get('tables', []),
                    'structured_content': ocr_result.get('structured_content', '')
                }
                logger.info(f"Multimodal OCR extracted: {len(image_analysis['ocr_text'])} chars, {len(image_analysis['formulas'])} formulas")
            except Exception as e:
                logger.warning(f"Multimodal OCR failed, falling back to Florence-2: {e}")
                # Florence-2ë¡œ í´ë°±
                image_analysis = self.image_analyzer.analyze_for_chatgpt_response(image)
            
            # ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ì¿¼ë¦¬ì— ì¶”ê°€
            if image_analysis.get('ocr_text'):
                query = f"{query}\n\n[ì´ë¯¸ì§€ ë‚´ìš©: {image_analysis['ocr_text'][:200]}...]"
        
        # 2. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        logger.info("Searching for relevant documents...")
        search_results = self.vector_db.search_multimodal(
            query=query,
            image_analysis=image_analysis,
            k=5
        )
        
        # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = self._build_context(search_results, image_analysis)
        
        # 4. LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._build_prompt(query, context, response_style)
        
        # 5. LLM ì‘ë‹µ ìƒì„±
        logger.info("Generating response...")
        llm_response = self.llm_client.generate(prompt)
        
        # 6. ChatGPT ìŠ¤íƒ€ì¼ í¬ë§·íŒ…
        formatted_response = self.response_generator.generate_response(
            question=query,
            context=context,
            response_type=response_style
        )
        
        # 7. ìµœì¢… ì‘ë‹µ í†µí•©
        final_response = self._integrate_responses(llm_response, formatted_response, context)
        
        return {
            'success': True,
            'query': query,
            'response': final_response,
            'context': context,
            'search_results': search_results,
            'image_analysis': image_analysis
        }
    
    def _build_context(
        self,
        search_results: List[Dict[str, Any]],
        image_analysis: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        context = {
            'retrieved_documents': [],
            'key_concepts': set(),
            'formulas': [],
            'visual_elements': {},
            'solution_steps': []
        }
        
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        for result in search_results:
            doc_content = result.get('parsed_content', {})
            
            # ë¬¸ì„œ ì¶”ê°€
            context['retrieved_documents'].append({
                'content': doc_content.get('text', ''),
                'score': result.get('hybrid_score', 0),
                'metadata': result.get('metadata', {})
            })
            
            # ìˆ˜ì‹ ìˆ˜ì§‘
            if doc_content.get('formulas'):
                context['formulas'].extend(doc_content['formulas'])
            
            # ê°œë… ìˆ˜ì§‘
            if result.get('metadata', {}).get('concepts'):
                context['key_concepts'].update(result['metadata']['concepts'])
        
        # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ í†µí•©
        if image_analysis:
            if image_analysis.get('key_concepts'):
                context['key_concepts'].update(image_analysis['key_concepts'])
            
            if image_analysis.get('solution_steps'):
                context['solution_steps'] = image_analysis['solution_steps']
            
            if image_analysis.get('visual_elements'):
                context['visual_elements'] = image_analysis['visual_elements']
        
        # setì„ listë¡œ ë³€í™˜
        context['key_concepts'] = list(context['key_concepts'])
        
        return context
    
    def _build_prompt(self, query: str, context: Dict[str, Any], style: str) -> str:
        """LLM í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = f"""ë‹¹ì‹ ì€ ì „ê¸°ê³µí•™ ë¶„ì•¼ì˜ ìµœê³  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ChatGPT ìŠ¤íƒ€ì¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {query}

ì°¸ê³  ìë£Œ:
"""
        
        # ê²€ìƒ‰ëœ ë¬¸ì„œ ì¶”ê°€
        for i, doc in enumerate(context['retrieved_documents'][:3]):
            prompt += f"\n[ë¬¸ì„œ {i+1}]:\n{doc['content'][:500]}...\n"
        
        # ìˆ˜ì‹ ì •ë³´ ì¶”ê°€
        if context['formulas']:
            prompt += "\nê´€ë ¨ ìˆ˜ì‹:\n"
            for formula in context['formulas'][:5]:
                prompt += f"- ${formula}$\n"
        
        # ìŠ¤íƒ€ì¼ ì§€ì‹œ
        if style == 'comprehensive':
            prompt += "\nì¢…í•©ì ì´ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
        elif style == 'step_by_step':
            prompt += "\në‹¨ê³„ë³„ë¡œ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        elif style == 'concept':
            prompt += "\nê°œë…ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        
        return prompt
    
    def _integrate_responses(
        self,
        llm_response: str,
        formatted_response: str,
        context: Dict[str, Any]
    ) -> str:
        """LLM ì‘ë‹µê³¼ í¬ë§·ëœ ì‘ë‹µ í†µí•©"""
        # ê¸°ë³¸ì ìœ¼ë¡œ í¬ë§·ëœ ì‘ë‹µ ì‚¬ìš©
        # LLM ì‘ë‹µì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œí•˜ì—¬ ë³´ê°•
        
        # ìˆ˜ì‹ì´ ìˆìœ¼ë©´ LaTeX í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        integrated = formatted_response
        
        # LLM ì‘ë‹µì—ì„œ ëˆ„ë½ëœ ì •ë³´ ì¶”ê°€
        if "ì˜ˆì‹œ" in llm_response and "ì˜ˆì‹œ" not in integrated:
            # ì˜ˆì‹œ ì„¹ì…˜ ì¶”ê°€
            integrated += "\n\nğŸ“ **ì¶”ê°€ ì˜ˆì‹œ:**\n"
            # ì˜ˆì‹œ ì¶”ì¶œ ë¡œì§...
        
        return integrated


# ê¸°ì¡´ RAG ì‹œìŠ¤í…œê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ì–´ëŒ‘í„°
class RAGSystemAdapter:
    """ê¸°ì¡´ RAG ì‹œìŠ¤í…œ ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜"""
    
    def __init__(self, enhanced_rag: EnhancedRAGSystem):
        self.enhanced_rag = enhanced_rag
    
    def query(self, question: str, k: int = 3) -> Dict[str, Any]:
        """ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜"""
        result = self.enhanced_rag.process_query(
            query=question,
            response_style='comprehensive'
        )
        
        # ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        return {
            "answer": result['response'],
            "sources": [doc['content'] for doc in result['context']['retrieved_documents'][:k]],
            "scores": [doc['score'] for doc in result['context']['retrieved_documents'][:k]]
        }


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    logging.basicConfig(level=logging.INFO)
    
    # í–¥ìƒëœ ë²¡í„° DB ì´ˆê¸°í™”
    vector_db = EnhancedVectorDatabase()
    
    # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì¶”ê°€
    test_content = {
        'text': '3ìƒ ì „ë ¥ ì‹œìŠ¤í…œì—ì„œ ì„ ê°„ì „ì••ì´ 380Vì´ê³  ì—­ë¥ ì´ 0.8ì¼ ë•Œì˜ ì „ë ¥ ê³„ì‚°',
        'formulas': [
            'P = \\sqrt{3} \\times V_L \\times I_L \\times \\cos\\theta',
            'S = \\sqrt{3} \\times V_L \\times I_L'
        ],
        'diagrams': [{
            'type': 'circuit',
            'components': [
                {'type': 'voltage', 'label': 'V1'},
                {'type': 'resistor', 'label': 'R1'},
                {'type': 'inductor', 'label': 'L1'}
            ]
        }]
    }
    
    doc_id = vector_db.add_multimodal_document(
        content=test_content,
        metadata={'concepts': ['3ìƒ ì „ë ¥', 'ì—­ë¥ ', 'ì „ë ¥ ê³„ì‚°']}
    )
    
    print(f"Added document: {doc_id}")
    
    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    results = vector_db.search_multimodal(
        query="3ìƒ ì „ë ¥ ê³„ì‚° ë°©ë²•",
        k=3
    )
    
    print(f"\nSearch results: {len(results)} found")
    for i, result in enumerate(results):
        print(f"{i+1}. Score: {result.get('hybrid_score', 0):.3f}")