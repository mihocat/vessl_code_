#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìµœì í™”ëœ OpenAI Vision API ë¶„ì„ê¸°
Optimized OpenAI Vision API Analyzer

í† í° ì‚¬ìš©ëŸ‰ ìµœì í™” ë° ì‘ë‹µ í’ˆì§ˆ ê°œì„ 
"""

import logging
import base64
import time
from typing import Dict, Any, Optional, Union
from PIL import Image
import io
import os
from openai import OpenAI

logger = logging.getLogger(__name__)


class OptimizedOpenAIVisionAnalyzer:
    """í† í° ì‚¬ìš©ëŸ‰ì„ ìµœì í™”í•œ OpenAI Vision API ë¶„ì„ê¸°"""
    
    def __init__(self, config=None):
        """
        ì´ˆê¸°í™”
        
        Args:
            config: Config ê°ì²´ (ì—†ìœ¼ë©´ ê¸°ë³¸ config ì‚¬ìš©)
        """
        if config is None:
            from config import config as default_config
            config = default_config
        
        self.config = config.openai
        
        if not self.config.api_key:
            logger.error("OpenAI API key not found - Vision API disabled")
            self.api_available = False
        elif self.config.api_key.startswith("sk-fallback"):
            logger.warning("OpenAI API key in fallback mode - Vision API disabled")
            self.api_available = False
        else:
            self.api_available = True
            logger.info(f"Optimized OpenAI Vision API enabled with key: {self.config.api_key[:7]}...")
        
        if self.api_available:
            self.client = OpenAI(api_key=self.config.api_key)
            self.model = self.config.vision_model
            # ìµœì í™”ëœ ì„¤ì •
            self.max_tokens = 1500  # ê¸°ì¡´ 1000 â†’ 1500ìœ¼ë¡œ ì¦ê°€ (ë” ìƒì„¸í•œ ì‘ë‹µ)
            self.temperature = 0.1   # ê¸°ì¡´ 0.2 â†’ 0.1ë¡œ ê°ì†Œ (ë” ì¼ê´€ëœ ì‘ë‹µ)
            
            # ì´ë¯¸ì§€ ìµœì í™” ì„¤ì •
            self.max_image_size = (800, 600)  # ê¸°ì¡´ 1024x576 â†’ 800x600ìœ¼ë¡œ ê°ì†Œ
            self.image_quality = 85  # JPEG í’ˆì§ˆ 85% (ì••ì¶•ë¥  ì¦ê°€)
            
            logger.info(f"Optimized OpenAI Vision Analyzer initialized - Model: {self.model}, Max tokens: {self.max_tokens}")
        else:
            self.client = None
            self.model = None
            self.max_tokens = 1500
            self.temperature = 0.1
            logger.info("Optimized OpenAI Vision Analyzer initialized in fallback mode")
    
    def _optimize_image(self, image: Union[Image.Image, str]) -> Image.Image:
        """ì´ë¯¸ì§€ ìµœì í™” (í¬ê¸° ì¶•ì†Œ ë° ì••ì¶•)"""
        if isinstance(image, str):
            # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
            pil_image = Image.open(image)
        else:
            pil_image = image
        
        # RGB ëª¨ë“œë¡œ ë³€í™˜ (RGBA â†’ RGB)
        if pil_image.mode in ['RGBA', 'LA']:
            # íˆ¬ëª… ë°°ê²½ì„ í°ìƒ‰ìœ¼ë¡œ ë³€í™˜
            background = Image.new('RGB', pil_image.size, (255, 255, 255))
            if pil_image.mode == 'RGBA':
                background.paste(pil_image, mask=pil_image.split()[-1])
            else:
                background.paste(pil_image)
            pil_image = background
        elif pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # í¬ê¸° ìµœì í™”
        original_size = pil_image.size
        pil_image.thumbnail(self.max_image_size, Image.Resampling.LANCZOS)
        optimized_size = pil_image.size
        
        logger.info(f"Image optimized: {original_size} â†’ {optimized_size}")
        return pil_image
    
    def _encode_image_optimized(self, image: Union[Image.Image, str]) -> str:
        """ìµœì í™”ëœ ì´ë¯¸ì§€ base64 ì¸ì½”ë”©"""
        # ì´ë¯¸ì§€ ìµœì í™”
        optimized_image = self._optimize_image(image)
        
        # JPEGë¡œ ì••ì¶•í•˜ì—¬ ì¸ì½”ë”© (PNG ëŒ€ì‹  JPEG ì‚¬ìš©ìœ¼ë¡œ í† í° ì ˆì•½)
        buffered = io.BytesIO()
        optimized_image.save(buffered, format="JPEG", quality=self.image_quality, optimize=True)
        
        encoded_size = len(buffered.getvalue())
        logger.info(f"Image encoded size: {encoded_size / 1024:.1f} KB")
        
        return base64.b64encode(buffered.getvalue()).decode('utf-8')
    
    def _create_optimized_prompt(
        self, 
        question: Optional[str] = None,
        extract_text: bool = True,
        detect_formulas: bool = True
    ) -> tuple[str, str]:
        """ì§ˆì˜ ì¤‘ì‹¬ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ê°„ê²°í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = "ì§ˆì˜ ì¤‘ì‹¬ ì´ë¯¸ì§€ ë¶„ì„. í•œêµ­ì–´+ìˆ˜ì‹ í˜¼ì¬ ì²˜ë¦¬ ì „ë¬¸."
        
        # ì§ˆì˜ ì¤‘ì‹¬ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
        if question:
            user_prompt = f"""ì§ˆë¬¸: "{question}"

ìœ„ ì§ˆë¬¸ ë‹µë³€ì— í•„ìš”í•œ ë¶€ë¶„ë§Œ ë¶„ì„:
1. ì§ˆë¬¸ ê´€ë ¨ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
2. ê´€ë ¨ ìˆ˜ì‹ë§Œ LaTeX í˜•ì‹ ($$ìˆ˜ì‹$$)
3. ë¶ˆí•„ìš”í•œ ë‚´ìš© ìƒëµ

ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""
        else:
            # ì§ˆë¬¸ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë¶„ì„
            tasks = []
            if extract_text:
                tasks.append("ì¤‘ìš”í•œ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë§Œ")
            if detect_formulas:
                tasks.append("í•µì‹¬ ìˆ˜ì‹ë§Œ LaTeXë¡œ")
            
            task_str = ", ".join(tasks) if tasks else "ì£¼ìš” ë‚´ìš©ë§Œ"
            user_prompt = f"{task_str} ì¶”ì¶œí•˜ì—¬ ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”."
        
        return system_prompt, user_prompt
    
    def analyze_image_optimized(
        self, 
        image: Union[Image.Image, str],
        question: Optional[str] = None,
        extract_text: bool = True,
        detect_formulas: bool = True
    ) -> Dict[str, Any]:
        """
        ìµœì í™”ëœ OpenAI Vision API ì´ë¯¸ì§€ ë¶„ì„
        
        Args:
            image: ë¶„ì„í•  ì´ë¯¸ì§€
            question: ì‚¬ìš©ì ì§ˆë¬¸
            extract_text: í…ìŠ¤íŠ¸ ì¶”ì¶œ ì—¬ë¶€
            detect_formulas: ìˆ˜ì‹ ê°ì§€ ì—¬ë¶€
            
        Returns:
            ë¶„ì„ ê²°ê³¼
        """
        # API ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ì¦‰ì‹œ ì‹¤íŒ¨ ë°˜í™˜
        if not self.api_available:
            logger.warning("OpenAI Vision API not available - API key not configured")
            return {
                "success": False,
                "error": "OpenAI API key not configured - using OCR fallback",
                "raw_response": "",
                "token_usage": {"total_tokens": 0}
            }
        
        start_time = time.time()
        
        try:
            # ìµœì í™”ëœ ì´ë¯¸ì§€ ì¸ì½”ë”©
            base64_image = self._encode_image_optimized(image)
            
            # ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt, user_prompt = self._create_optimized_prompt(
                question, extract_text, detect_formulas
            )
            
            # ìš”ì²­ ì •ë³´ ë¡œê¹…
            request_info = {
                "model": self.model,
                "max_tokens": self.max_tokens,
                "temperature": self.temperature,
                "system_prompt_length": len(system_prompt),
                "user_prompt_length": len(user_prompt),
                "image_size_kb": len(base64_image) * 3 / 4 / 1024,
                "detail_level": "low",
                "question": question[:100] + "..." if question and len(question) > 100 else question
            }
            logger.info(f"ğŸš€ ìµœì í™”ëœ OpenAI Vision API ìš”ì²­: {request_info}")
            
            # API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": user_prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}",
                                    "detail": "low"  # 'low' ì‚¬ìš©ìœ¼ë¡œ í† í° ì ˆì•½ (ê¸°ì¡´ auto/high)
                                }
                            }
                        ]
                    }
                ],
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            
            processing_time = time.time() - start_time
            
            # ì‘ë‹µ íŒŒì‹±
            content = response.choices[0].message.content
            
            # í† í° ì‚¬ìš©ëŸ‰ ë¶„ì„
            token_usage = {
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens,
                "estimated_cost_usd": self._calculate_cost(response.usage)
            }
            
            # ì‘ë‹µ ì •ë³´ ë¡œê¹…
            response_info = {
                "success": True,
                "processing_time": processing_time,
                "prompt_tokens": token_usage["prompt_tokens"],
                "completion_tokens": token_usage["completion_tokens"],
                "total_tokens": token_usage["total_tokens"],
                "estimated_cost_usd": token_usage["estimated_cost_usd"],
                "response_length": len(content),
                "optimization_applied": True
            }
            logger.info(f"âœ… ìµœì í™”ëœ OpenAI Vision API ì‘ë‹µ ì™„ë£Œ: {response_info}")
            
            # ì‘ë‹µ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° ë¡œê¹…
            content_preview = content[:200] + "..." if len(content) > 200 else content
            logger.info(f"ğŸ“ ìµœì í™”ëœ ì‘ë‹µ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {content_preview}")
            
            # ìˆ˜ì‹ ê°ì§€ ê°œì„ 
            formulas = []
            if detect_formulas:
                formulas = self._extract_formulas(content)
            
            result = {
                "success": True,
                "raw_response": content,
                "text_content": content,
                "description": content,
                "formulas": formulas,
                "has_formula": len(formulas) > 0,
                "model": self.model,
                "token_usage": token_usage,
                "processing_time": processing_time,
                "optimization_applied": True
            }
            
            logger.info(f"Optimized Vision analysis completed - Tokens: {token_usage['total_tokens']} "
                       f"(Input: {token_usage['prompt_tokens']}, Output: {token_usage['completion_tokens']}), "
                       f"Cost: ${token_usage['estimated_cost_usd']:.4f}, Time: {processing_time:.2f}s")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_str = str(e)
            logger.error(f"Optimized OpenAI Vision API failed: {error_str}")
            
            return {
                "success": False,
                "error": error_str,
                "raw_response": "",
                "token_usage": {"total_tokens": 0},
                "processing_time": processing_time,
                "optimization_applied": True
            }
    
    def _calculate_cost(self, usage) -> float:
        """í† í° ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ë¹„ìš© ê³„ì‚° (gpt-4.1 ê¸°ì¤€)"""
        # gpt-4.1 ê°€ê²©: Input $2.0/1M tokens, Output $8.0/1M tokens
        input_cost = (usage.prompt_tokens / 1_000_000) * 2.0
        output_cost = (usage.completion_tokens / 1_000_000) * 8.0
        return input_cost + output_cost
    
    def _extract_formulas(self, content: str) -> list:
        """ìˆ˜ì‹ ì¶”ì¶œ ê°œì„ """
        import re
        formulas = []
        
        # ë‹¤ì–‘í•œ ìˆ˜ì‹ íŒ¨í„´ ê°ì§€
        patterns = [
            r'\$\$(.+?)\$\$',  # $$...$$
            r'\\\((.+?)\\\)',  # \(...\)
            r'\\\[(.+?)\\\]',  # \[...\]
            r'([A-Z]\s*=\s*[^ê°€-í£\n]{2,20})',  # ê³µì‹ íŒ¨í„´ (ì˜ˆ: F = ma)
            r'(\w+\s*[+\-*/=]\s*\w+)',  # ê¸°ë³¸ ìˆ˜ì‹
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, content, re.DOTALL)
            for match in matches:
                if isinstance(match, tuple):
                    match = match[0] if match[0] else match[1]
                
                formula_text = match.strip()
                if len(formula_text) > 1:  # ì˜ë¯¸ìˆëŠ” ìˆ˜ì‹ë§Œ
                    formulas.append({
                        "latex": formula_text,
                        "confidence": 0.8,
                        "type": "mathematical_expression"
                    })
        
        return formulas
    
    def get_optimization_stats(self) -> Dict[str, Any]:
        """ìµœì í™” í†µê³„ ì¡°íšŒ"""
        return {
            "max_image_size": self.max_image_size,
            "image_quality": self.image_quality,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "model": self.model,
            "optimizations": [
                "ì´ë¯¸ì§€ í¬ê¸° ì¶•ì†Œ (800x600)",
                "JPEG ì••ì¶• (85% í’ˆì§ˆ)",
                "ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸",
                "detail='low' ì„¤ì •",
                "RGB ëª¨ë“œ ë³€í™˜"
            ]
        }


# ê¸°ì¡´ í´ë˜ìŠ¤ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼
class OpenAIVisionAnalyzer(OptimizedOpenAIVisionAnalyzer):
    """ê¸°ì¡´ ì½”ë“œì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í´ë˜ìŠ¤"""
    
    def analyze_image(self, *args, **kwargs):
        """ê¸°ì¡´ ë©”ì„œë“œëª… í˜¸í™˜ì„±"""
        return self.analyze_image_optimized(*args, **kwargs)


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    from config import config
    
    if not config.openai.api_key:
        print("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        exit(1)
    
    analyzer = OptimizedOpenAIVisionAnalyzer(config)
    
    print("=== ìµœì í™”ëœ OpenAI Vision Analyzer ===")
    print(f"ìµœì í™” ì„¤ì •: {analyzer.get_optimization_stats()}")
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¶„ì„
    if os.path.exists("test_image.jpg"):
        result = analyzer.analyze_image_optimized(
            "test_image.jpg",
            question="ì´ ì´ë¯¸ì§€ì˜ ìˆ˜ì‹ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"
        )
        
        print(f"\n=== ë¶„ì„ ê²°ê³¼ ===")
        print(f"ì„±ê³µ: {result.get('success')}")
        print(f"ëª¨ë¸: {result.get('model')}")
        print(f"í† í° ì‚¬ìš©ëŸ‰: {result.get('token_usage', {}).get('total_tokens')}")
        print(f"ì˜ˆìƒ ë¹„ìš©: ${result.get('token_usage', {}).get('estimated_cost_usd', 0):.4f}")
        print(f"ì²˜ë¦¬ ì‹œê°„: {result.get('processing_time', 0):.2f}ì´ˆ")
        print(f"ìˆ˜ì‹ ë°œê²¬: {len(result.get('formulas', []))}ê°œ")
        print(f"\nì‘ë‹µ ë‚´ìš©:\n{result.get('raw_response', '')[:200]}...")
    else:
        print("test_image.jpg íŒŒì¼ì´ ì—†ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")