#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í†µí•© ë¶„ì„ í”„ë¡œì„¸ì„œ
OpenAI GPT-4.1 ë‹¨ì¼ í˜¸ì¶œë¡œ ì´ë¯¸ì§€+í…ìŠ¤íŠ¸ ë¶„ì„ë§Œ ìˆ˜í–‰í•˜ê³ ,
ìµœì¢… ë‹µë³€ì€ RAG + íŒŒì¸íŠœë‹ LLMë§Œ ë‹´ë‹¹
"""

import os
import base64
import logging
import time
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass
from datetime import datetime
from PIL import Image
import io

try:
    from openai import OpenAI
except ImportError as e:
    logging.error("OpenAI library not found. Install with: pip install openai")
    raise e

logger = logging.getLogger(__name__)

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼"""
    success: bool
    extracted_text: Optional[str] = None
    formulas: Optional[List[str]] = None
    key_concepts: Optional[List[str]] = None
    question_intent: Optional[str] = None
    processing_time: Optional[float] = None
    token_usage: Optional[Dict[str, int]] = None
    cost: Optional[float] = None
    error_message: Optional[str] = None


class UnifiedAnalysisProcessor:
    """í†µí•© ë¶„ì„ í”„ë¡œì„¸ì„œ - OpenAI 1íšŒ í˜¸ì¶œ ì œí•œ"""
    
    def __init__(self, config: Optional[Dict] = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.config = config or {}
        self.api_key = self._load_api_key()
        
        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        self.client = OpenAI(api_key=self.api_key)
        self.model = self.config.get('unified_model', 'gpt-4.1')
        self.max_tokens = self.config.get('max_tokens', 300)  # ë¶„ì„ë§Œ ìˆ˜í–‰í•˜ë¯€ë¡œ ì œí•œ
        self.temperature = self.config.get('temperature', 0.1)
        
        # 1íšŒ í˜¸ì¶œ ì œí•œ ì¶”ì 
        self._call_count = 0
        self._max_calls_per_query = 1  # ë¬´ì¡°ê±´ 1íšŒë§Œ í˜¸ì¶œ
        self._session_calls = 0  # ì„¸ì…˜ ì „ì²´ í˜¸ì¶œ ì¶”ì 
        
        logger.info(f"Unified Analysis Processor initialized - Model: {self.model}, Max tokens: {self.max_tokens}")
    
    def _load_api_key(self) -> Optional[str]:
        """API í‚¤ ë¡œë“œ"""
        # 1. ì„¤ì •ì—ì„œ ì§ì ‘ ë¡œë“œ
        if 'api_key' in self.config and self.config['api_key']:
            return self.config['api_key']
        
        # 2. í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œ
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key:
            return api_key
        
        # 3. VESSL ìŠ¤í† ë¦¬ì§€ì—ì„œ ë¡œë“œ
        vessl_key_paths = [
            '/apikey/openai_api_key.txt',
            '/apikey/OPENAI_API_KEY',
            './apikey/openai_api_key.txt'
        ]
        
        for path in vessl_key_paths:
            try:
                if os.path.exists(path):
                    with open(path, 'r', encoding='utf-8') as f:
                        key = f.read().strip()
                        if key:
                            logger.info(f"API key loaded from: {path}")
                            return key
            except Exception as e:
                logger.warning(f"Failed to read API key from {path}: {e}")
        
        return None
    
    def reset_call_count(self):
        """ì§ˆì˜ë‹¹ í˜¸ì¶œ íšŸìˆ˜ ì´ˆê¸°í™”"""
        self._call_count = 0
    
    def analyze_image_and_text(
        self, 
        question: str,
        image: Optional[Union[Image.Image, str, bytes]] = None
    ) -> AnalysisResult:
        """
        ì´ë¯¸ì§€+í…ìŠ¤íŠ¸ í†µí•© ë¶„ì„ (1íšŒ í˜¸ì¶œ ì œí•œ)
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            image: ì´ë¯¸ì§€ (PIL Image, base64 ë¬¸ìì—´, ë˜ëŠ” ë°”ì´íŠ¸)
            
        Returns:
            AnalysisResult: ë¶„ì„ ê²°ê³¼
        """
        # ì—„ê²©í•œ 1íšŒ í˜¸ì¶œ ì œí•œ
        if self._call_count >= self._max_calls_per_query:
            logger.warning(f"ğŸš« OpenAI API í˜¸ì¶œ ì œí•œ ì´ˆê³¼ (í—ˆìš©: {self._max_calls_per_query}íšŒ, ì‹œë„: {self._call_count + 1}íšŒ)")
            return AnalysisResult(
                success=False,
                error_message=f"OpenAI APIëŠ” ì§ˆì˜ë‹¹ ìµœëŒ€ {self._max_calls_per_query}íšŒë§Œ í˜¸ì¶œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )
        
        start_time = time.time()
        self._call_count += 1
        self._session_calls += 1
        
        logger.info(f"ğŸš€ OpenAI Unified Analysis ìš”ì²­ ì‹œì‘ (Model: {self.model})")
        logger.info(f"ğŸ“Š í˜¸ì¶œ ì¶”ì : ì§ˆì˜ë‚´ {self._call_count}/{self._max_calls_per_query}íšŒ, ì„¸ì…˜ë‚´ {self._session_calls}íšŒ")
        
        try:
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {
                    "role": "system",
                    "content": """ë‹¹ì‹ ì€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•˜ì„¸ìš”:

**ì¶”ì¶œëœ í…ìŠ¤íŠ¸:**
[ì´ë¯¸ì§€ì—ì„œ ì½ì€ ëª¨ë“  í…ìŠ¤íŠ¸]

**ê°ì§€ëœ ìˆ˜ì‹:**
[LaTeX í˜•ì‹ì˜ ìˆ˜ì‹ë“¤]

**í•µì‹¬ ê°œë…:**
[ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í•µì‹¬ ê°œë… 3-5ê°œ]

**ì§ˆë¬¸ ì˜ë„:**
[ì‚¬ìš©ìê°€ ë¬´ì—‡ì„ ë¬»ê³ ì í•˜ëŠ”ì§€ í•œ ë¬¸ì¥ìœ¼ë¡œ]"""
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": f"ì§ˆë¬¸: {question}\n\nìœ„ ì§ˆë¬¸ê³¼ ê´€ë ¨í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”."
                        }
                    ]
                }
            ]
            
            # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if image is not None:
                image_base64 = self._process_image(image)
                messages[1]["content"].append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_base64}",
                        "detail": "low"  # í† í° ì ˆì•½
                    }
                })
            
            logger.info(f"ğŸš€ OpenAI Unified Analysis ìš”ì²­ ì‹œì‘ (Model: {self.model})")
            logger.info(f"ğŸ“ ìš”ì²­ ë©”ì‹œì§€: {len(messages)} ê°œ, ì§ˆë¬¸: {question[:100]}...")
            if image is not None:
                logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ í¬í•¨: ì²˜ë¦¬ë¨")
            
            # API í˜¸ì¶œ - GPT-5ëŠ” max_completion_tokens ì‚¬ìš©
            api_params = {
                "model": self.model,
                "messages": messages,
                "temperature": self.temperature
            }
            
            # GPT-5 ëª¨ë¸ì¸ ê²½ìš° max_completion_tokens ì‚¬ìš©
            if "gpt-5" in self.model.lower():
                api_params["max_completion_tokens"] = self.max_tokens
            else:
                api_params["max_tokens"] = self.max_tokens
            
            response = self.client.chat.completions.create(**api_params)
            
            logger.info(f"ğŸ“¥ OpenAI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
            
            processing_time = time.time() - start_time
            
            if response and response.choices:
                content = response.choices[0].message.content
                
                # í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ê³„ì‚°
                token_usage = None
                cost = 0.0
                if hasattr(response, 'usage'):
                    token_usage = {
                        'prompt_tokens': response.usage.prompt_tokens,
                        'completion_tokens': response.usage.completion_tokens,
                        'total_tokens': response.usage.total_tokens
                    }
                    cost = self._calculate_cost(token_usage)
                
                # OpenAI ì‘ë‹µ ë‚´ìš© ë¡œê¹…
                logger.info(f"ğŸ“‹ OpenAI ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 200ì): {content[:200]}...")
                
                # ë¶„ì„ ê²°ê³¼ íŒŒì‹±
                result = self._parse_analysis_result(content, processing_time, token_usage, cost)
                
                logger.info(f"âœ… OpenAI Unified Analysis ì™„ë£Œ - "
                          f"Tokens: {token_usage['total_tokens'] if token_usage else 0}, "
                          f"Cost: ${cost:.4f}, Time: {processing_time:.2f}s")
                
                # íŒŒì‹±ëœ ê²°ê³¼ ìš”ì•½ ë¡œê¹…
                logger.info(f"ğŸ” ë¶„ì„ ê²°ê³¼ ìš”ì•½: "
                          f"í…ìŠ¤íŠ¸={len(result.extracted_text or '')}, "
                          f"ìˆ˜ì‹={len(result.formulas or [])}, "
                          f"ê°œë…={len(result.key_concepts or [])}, "
                          f"ì˜ë„={'ìˆìŒ' if result.question_intent else 'ì—†ìŒ'}")
                
                return result
            else:
                return AnalysisResult(
                    success=False,
                    error_message="API ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                    processing_time=processing_time
                )
                
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ OpenAI Unified Analysis ì‹¤íŒ¨: {e}")
            logger.error(f"âŒ ì˜¤ë¥˜ ìƒì„¸: {type(e).__name__}: {str(e)}")
            logger.error(f"âŒ í˜¸ì¶œ íšŸìˆ˜: {self._call_count}/{self._max_calls_per_query}")
            return AnalysisResult(
                success=False,
                error_message=str(e),
                processing_time=processing_time
            )
    
    def _process_image(self, image: Union[Image.Image, str, bytes]) -> str:
        """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜"""
        if isinstance(image, str):
            # ì´ë¯¸ base64 ë¬¸ìì—´ì¸ ê²½ìš°
            return image
        elif isinstance(image, bytes):
            # bytesì¸ ê²½ìš°
            return base64.b64encode(image).decode('utf-8')
        elif isinstance(image, Image.Image):
            # PIL Imageì¸ ê²½ìš°
            buffer = io.BytesIO()
            # ì´ë¯¸ì§€ í¬ê¸° ìµœì í™” (í† í° ì ˆì•½)
            if image.size[0] > 1024 or image.size[1] > 1024:
                image.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
            image.save(buffer, format="JPEG", quality=85)
            image_bytes = buffer.getvalue()
            return base64.b64encode(image_bytes).decode('utf-8')
        else:
            raise ValueError(f"Unsupported image type: {type(image)}")
    
    def _parse_analysis_result(
        self, 
        content: str, 
        processing_time: float,
        token_usage: Optional[Dict],
        cost: float
    ) -> AnalysisResult:
        """ë¶„ì„ ê²°ê³¼ íŒŒì‹±"""
        try:
            # ê¸°ë³¸ê°’
            extracted_text = ""
            formulas = []
            key_concepts = []
            question_intent = ""
            
            # ì„¹ì…˜ë³„ íŒŒì‹±
            sections = content.split("**")
            current_section = None
            
            for section in sections:
                section = section.strip()
                if "ì¶”ì¶œëœ í…ìŠ¤íŠ¸" in section:
                    current_section = "text"
                elif "ê°ì§€ëœ ìˆ˜ì‹" in section:
                    current_section = "formula"
                elif "í•µì‹¬ ê°œë…" in section:
                    current_section = "concept"
                elif "ì§ˆë¬¸ ì˜ë„" in section:
                    current_section = "intent"
                elif section and current_section:
                    if current_section == "text":
                        extracted_text = section
                    elif current_section == "formula":
                        formulas = [f.strip() for f in section.split('\n') if f.strip()]
                    elif current_section == "concept":
                        key_concepts = [c.strip() for c in section.split('\n') if c.strip()]
                    elif current_section == "intent":
                        question_intent = section
            
            return AnalysisResult(
                success=True,
                extracted_text=extracted_text if extracted_text else None,
                formulas=formulas if formulas else None,
                key_concepts=key_concepts if key_concepts else None,
                question_intent=question_intent if question_intent else None,
                processing_time=processing_time,
                token_usage=token_usage,
                cost=cost
            )
            
        except Exception as e:
            logger.warning(f"ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return AnalysisResult(
                success=True,
                extracted_text=content,  # ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
                processing_time=processing_time,
                token_usage=token_usage,
                cost=cost
            )
    
    def _calculate_cost(self, token_usage: Dict[str, int]) -> float:
        """ë¹„ìš© ê³„ì‚° (GPT-4.1 ê¸°ì¤€)"""
        # gpt-4.1 ê°€ê²©: $2.0/1M input tokens, $8.0/1M output tokens
        input_cost = token_usage.get('prompt_tokens', 0) * 2.0 / 1_000_000
        output_cost = token_usage.get('completion_tokens', 0) * 8.0 / 1_000_000
        return input_cost + output_cost
    
    def get_call_statistics(self) -> Dict[str, Any]:
        """í˜¸ì¶œ í†µê³„ ë°˜í™˜"""
        return {
            "current_call_count": self._call_count,
            "max_calls_per_query": self._max_calls_per_query,
            "calls_remaining": max(0, self._max_calls_per_query - self._call_count)
        }


def create_unified_processor(config: Optional[Dict] = None) -> UnifiedAnalysisProcessor:
    """í†µí•© ë¶„ì„ í”„ë¡œì„¸ì„œ ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    return UnifiedAnalysisProcessor(config)