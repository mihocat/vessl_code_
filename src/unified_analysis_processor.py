#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í†µí•© ë¶„ì„ í”„ë¡œì„¸ì„œ
OpenAI GPT-4.1 ë‹¨ì¼ í˜¸ì¶œë¡œ ì´ë¯¸ì§€+í…ìŠ¤íŠ¸ ë¶„ì„ë§Œ ìˆ˜í–‰í•˜ê³ ,
ìµœì¢… ë‹µë³€ì€ RAG + íŒŒì¸íŠœë‹ LLMë§Œ ë‹´ë‹¹
"""

import os
import base64
import logging
import time
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass
from datetime import datetime
from PIL import Image
import io

try:
    from openai import OpenAI
except ImportError as e:
    logging.error("OpenAI library not found. Install with: pip install openai")
    raise e

logger = logging.getLogger(__name__)
# ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”
logger.setLevel(logging.DEBUG)

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼"""
    success: bool
    extracted_text: Optional[str] = None
    formulas: Optional[List[str]] = None
    key_concepts: Optional[List[str]] = None
    question_intent: Optional[str] = None
    processing_time: Optional[float] = None
    token_usage: Optional[Dict[str, int]] = None
    cost: Optional[float] = None
    error_message: Optional[str] = None


class UnifiedAnalysisProcessor:
    """í†µí•© ë¶„ì„ í”„ë¡œì„¸ì„œ - OpenAI 1íšŒ í˜¸ì¶œ ì œí•œ"""
    
    def __init__(self, config: Optional[Dict] = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.config = config or {}
        self.api_key = self._load_api_key()
        
        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        self.client = OpenAI(api_key=self.api_key)
        self.model = self.config.get('unified_model', 'gpt-5')
        self.max_tokens = self.config.get('max_tokens', 400)  # output í† í° ì œí•œ
        self.temperature = self.config.get('temperature', 0.2)  # ì¼ê´€ì„± ìˆëŠ” ë¶„ì„
        self.max_input_tokens = self.config.get('max_input_tokens', 1000)  # input ì¶©ë¶„íˆ í—ˆìš©
        self.target_output_tokens = self.config.get('target_output_tokens', 350)
        
        # 1íšŒ í˜¸ì¶œ ì œí•œ ì¶”ì 
        self._call_count = 0
        self._max_calls_per_query = 1  # ë¬´ì¡°ê±´ 1íšŒë§Œ í˜¸ì¶œ
        self._session_calls = 0  # ì„¸ì…˜ ì „ì²´ í˜¸ì¶œ ì¶”ì 
        
        logger.info(f"Unified Analysis Processor initialized - Model: {self.model}, Max tokens: {self.max_tokens}")
    
    def _load_api_key(self) -> Optional[str]:
        """API í‚¤ ë¡œë“œ"""
        # 1. ì„¤ì •ì—ì„œ ì§ì ‘ ë¡œë“œ
        if 'api_key' in self.config and self.config['api_key']:
            return self.config['api_key']
        
        # 2. í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œ
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key:
            return api_key
        
        # 3. VESSL ìŠ¤í† ë¦¬ì§€ì—ì„œ ë¡œë“œ
        vessl_key_paths = [
            '/apikey/openai_api_key.txt',
            '/apikey/OPENAI_API_KEY',
            './apikey/openai_api_key.txt'
        ]
        
        for path in vessl_key_paths:
            try:
                if os.path.exists(path):
                    with open(path, 'r', encoding='utf-8') as f:
                        key = f.read().strip()
                        if key:
                            logger.info(f"API key loaded from: {path}")
                            return key
            except Exception as e:
                logger.warning(f"Failed to read API key from {path}: {e}")
        
        return None
    
    def reset_call_count(self):
        """ì§ˆì˜ë‹¹ í˜¸ì¶œ íšŸìˆ˜ ì´ˆê¸°í™”"""
        self._call_count = 0
    
    def analyze_image_and_text(
        self, 
        question: str,
        image: Optional[Union[Image.Image, str, bytes]] = None
    ) -> AnalysisResult:
        """
        ì´ë¯¸ì§€+í…ìŠ¤íŠ¸ í†µí•© ë¶„ì„ (1íšŒ í˜¸ì¶œ ì œí•œ)
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            image: ì´ë¯¸ì§€ (PIL Image, base64 ë¬¸ìì—´, ë˜ëŠ” ë°”ì´íŠ¸)
            
        Returns:
            AnalysisResult: ë¶„ì„ ê²°ê³¼
        """
        # ì—„ê²©í•œ 1íšŒ í˜¸ì¶œ ì œí•œ
        if self._call_count >= self._max_calls_per_query:
            logger.warning(f"ğŸš« OpenAI API í˜¸ì¶œ ì œí•œ ì´ˆê³¼ (í—ˆìš©: {self._max_calls_per_query}íšŒ, ì‹œë„: {self._call_count + 1}íšŒ)")
            return AnalysisResult(
                success=False,
                error_message=f"OpenAI APIëŠ” ì§ˆì˜ë‹¹ ìµœëŒ€ {self._max_calls_per_query}íšŒë§Œ í˜¸ì¶œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )
        
        start_time = time.time()
        self._call_count += 1
        self._session_calls += 1
        
        logger.info(f"ğŸš€ OpenAI Unified Analysis ìš”ì²­ ì‹œì‘ (Model: {self.model})")
        logger.info(f"ğŸ“Š í˜¸ì¶œ ì¶”ì : ì§ˆì˜ë‚´ {self._call_count}/{self._max_calls_per_query}íšŒ, ì„¸ì…˜ë‚´ {self._session_calls}íšŒ")
        
        try:
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {
                    "role": "system",
                    "content": """ë‹¹ì‹ ì€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•˜ë˜, ê° ì„¹ì…˜ì˜ ë‚´ìš©ì€ ì œí•œëœ í† í° ë‚´ì—ì„œ ìµœëŒ€í•œ ì••ì¶•í•˜ì—¬ í•µì‹¬ë§Œ ì „ë‹¬í•˜ì„¸ìš”:

**ì¶”ì¶œëœ í…ìŠ¤íŠ¸:** [ì´ë¯¸ì§€ì—ì„œ ì½ì€ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ 200ì ì´ë‚´ë¡œ ìš”ì•½]
**ê°ì§€ëœ ìˆ˜ì‹:** [LaTeX í˜•ì‹ì˜ ì£¼ìš” ìˆ˜ì‹ 3-5ê°œ]
**í•µì‹¬ ê°œë…:** [ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í•µì‹¬ ê°œë… 5-8ê°œ]
**ì§ˆë¬¸ ì˜ë„:** [ì‚¬ìš©ìê°€ ë¬»ê³ ì í•˜ëŠ” í•µì‹¬ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ]

ì¤‘ìš”: ì „ì²´ ì‘ë‹µì„ 500í† í° ì´ë‚´ë¡œ ì••ì¶•í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”."""
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": f"""ì§ˆë¬¸: {question}

ì£¼ì˜ì‚¬í•­:
- ì „ì²´ ì‘ë‹µì€ ë°˜ë“œì‹œ {self.target_output_tokens}í† í° ì´ë‚´ë¡œ ì‘ì„±
- í•µì‹¬ ì •ë³´ë§Œ ì••ì¶•í•˜ì—¬ ì „ë‹¬
- ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ ì œì™¸í•˜ê³  ìš”ì²­ëœ í˜•ì‹ë§Œ ì¤€ìˆ˜"""
                        }
                    ]
                }
            ]
            
            # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if image is not None:
                image_base64 = self._process_image(image)
                messages[1]["content"].append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_base64}",
                        "detail": "low"  # í† í° ì ˆì•½
                    }
                })
            
            logger.info(f"ğŸš€ OpenAI Unified Analysis ìš”ì²­ ì‹œì‘ (Model: {self.model})")
            logger.info(f"ğŸ“ ìš”ì²­ ë©”ì‹œì§€: {len(messages)} ê°œ, ì§ˆë¬¸: {question[:100]}...")
            if image is not None:
                logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ í¬í•¨: ì²˜ë¦¬ë¨")
            
            # API í˜¸ì¶œ - GPT-5 íŒŒë¼ë¯¸í„° í˜¸í™˜ì„± ì²˜ë¦¬
            api_params = {
                "model": self.model,
                "messages": messages
            }
            
            # GPT-5 ëª¨ë¸ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
            if "gpt-5" in self.model.lower():
                api_params["max_completion_tokens"] = self.max_tokens
                # GPT-5ëŠ” temperature ê¸°ë³¸ê°’(1)ë§Œ ì§€ì›
                # api_params["temperature"] = 1  # ê¸°ë³¸ê°’ì´ë¯€ë¡œ ìƒëµ
            else:
                api_params["max_tokens"] = self.max_tokens
                api_params["temperature"] = self.temperature
            
            response = self.client.chat.completions.create(**api_params)
            
            logger.info(f"ğŸ“¥ OpenAI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
            
            processing_time = time.time() - start_time
            
            if response and response.choices:
                content = response.choices[0].message.content
                
                # í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ê³„ì‚°
                token_usage = None
                cost = 0.0
                if hasattr(response, 'usage'):
                    token_usage = {
                        'prompt_tokens': response.usage.prompt_tokens,
                        'completion_tokens': response.usage.completion_tokens,
                        'total_tokens': response.usage.total_tokens
                    }
                    cost = self._calculate_cost(token_usage)
                
                # OpenAI ì‘ë‹µ ë‚´ìš© ë¡œê¹…
                if content:
                    logger.info(f"ğŸ“‹ OpenAI ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 500ì): {content[:500] if len(content) > 500 else content}")
                    if len(content) > 500:
                        logger.info(f"ğŸ“‹ OpenAI ì‘ë‹µ ë‚´ìš© (ì „ì²´ {len(content)}ì)")
                else:
                    logger.warning("âš ï¸ OpenAI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
                logger.debug(f"ğŸ“„ OpenAI ì „ì²´ ì‘ë‹µ: {content}")
                
                # ë¶„ì„ ê²°ê³¼ íŒŒì‹±
                result = self._parse_analysis_result(content, processing_time, token_usage, cost)
                
                logger.info(f"âœ… OpenAI Unified Analysis ì™„ë£Œ - "
                          f"Tokens: {token_usage['total_tokens'] if token_usage else 0}, "
                          f"Cost: ${cost:.4f}, Time: {processing_time:.2f}s")
                
                # íŒŒì‹±ëœ ê²°ê³¼ ìš”ì•½ ë¡œê¹…
                logger.info(f"ğŸ” ë¶„ì„ ê²°ê³¼ ìš”ì•½: "
                          f"í…ìŠ¤íŠ¸={len(result.extracted_text or '')}ì, "
                          f"ìˆ˜ì‹={len(result.formulas or [])}ê°œ, "
                          f"ê°œë…={len(result.key_concepts or [])}ê°œ, "
                          f"ì˜ë„={'ìˆìŒ' if result.question_intent else 'ì—†ìŒ'}")
                
                # í† í° íš¨ìœ¨ì„± ì²´í¬
                if token_usage and token_usage.get('completion_tokens', 0) > self.target_output_tokens:
                    logger.warning(f"âš ï¸ Output í† í° ì´ˆê³¼: {token_usage['completion_tokens']} > {self.target_output_tokens}")
                
                return result
            else:
                return AnalysisResult(
                    success=False,
                    error_message="API ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                    processing_time=processing_time
                )
                
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ OpenAI Unified Analysis ì‹¤íŒ¨: {e}")
            logger.error(f"âŒ ì˜¤ë¥˜ ìƒì„¸: {type(e).__name__}: {str(e)}")
            logger.error(f"âŒ í˜¸ì¶œ íšŸìˆ˜: {self._call_count}/{self._max_calls_per_query}")
            return AnalysisResult(
                success=False,
                error_message=str(e),
                processing_time=processing_time
            )
    
    def _process_image(self, image: Union[Image.Image, str, bytes]) -> str:
        """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜"""
        if isinstance(image, str):
            # ì´ë¯¸ base64 ë¬¸ìì—´ì¸ ê²½ìš°
            return image
        elif isinstance(image, bytes):
            # bytesì¸ ê²½ìš°
            return base64.b64encode(image).decode('utf-8')
        elif isinstance(image, Image.Image):
            # PIL Imageì¸ ê²½ìš°
            buffer = io.BytesIO()
            # ì´ë¯¸ì§€ í¬ê¸° ìµœì í™” (í† í° ì ˆì•½)
            if image.size[0] > 1024 or image.size[1] > 1024:
                image.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
            image.save(buffer, format="JPEG", quality=85)
            image_bytes = buffer.getvalue()
            return base64.b64encode(image_bytes).decode('utf-8')
        else:
            raise ValueError(f"Unsupported image type: {type(image)}")
    
    def _parse_analysis_result(
        self, 
        content: str, 
        processing_time: float,
        token_usage: Optional[Dict],
        cost: float
    ) -> AnalysisResult:
        """ë¶„ì„ ê²°ê³¼ íŒŒì‹± - ê°œì„ ëœ ë¡œì§"""
        try:
            # íŒŒì‹± ì „ ë¡œê¹…
            logger.debug(f"íŒŒì‹± ì‹œì‘ - ì»¨í…ì¸  ê¸¸ì´: {len(content)}ì")
            logger.debug(f"íŒŒì‹± ëŒ€ìƒ ì»¨í…ì¸  ì²˜ìŒ 200ì: {content[:200]}...")
            
            # ê¸°ë³¸ê°’
            extracted_text = ""
            formulas = []
            key_concepts = []
            question_intent = ""
            
            # ë” ìœ ì—°í•œ íŒŒì‹± (**: ë˜ëŠ” ##ë¥¼ ì§€ì›)
            lines = content.split('\n')
            current_section = None
            current_content = []
            
            logger.debug(f"ì´ {len(lines)}ê°œ ë¼ì¸ íŒŒì‹± ì‹œì‘")
            
            for i, line in enumerate(lines):
                original_line = line
                line = line.strip()
                
                # ì„¹ì…˜ í—¤ë” ê°ì§€ (ë” ìœ ì—°í•˜ê²Œ)
                if any(marker in line for marker in ["ì¶”ì¶œëœ í…ìŠ¤íŠ¸:", "ì¶”ì¶œëœ í…ìŠ¤íŠ¸ï¼š", "**ì¶”ì¶œëœ í…ìŠ¤íŠ¸**", "ì¶”ì¶œëœ í…ìŠ¤íŠ¸"]):
                    logger.debug(f"ë¼ì¸ {i}: 'ì¶”ì¶œëœ í…ìŠ¤íŠ¸' ì„¹ì…˜ ë°œê²¬")
                    # ì´ì „ ì„¹ì…˜ ì €ì¥
                    if current_section and current_content:
                        self._save_section(current_section, '\n'.join(current_content), 
                                         locals())
                    current_section = "text"
                    current_content = []
                    # í—¤ë”ì™€ ê°™ì€ ì¤„ì— ë‚´ìš©ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
                    remaining = line.replace("**ì¶”ì¶œëœ í…ìŠ¤íŠ¸**", "").replace("ì¶”ì¶œëœ í…ìŠ¤íŠ¸:", "").replace("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ï¼š", "").strip()
                    if remaining:
                        current_content.append(remaining)
                elif any(marker in line for marker in ["ê°ì§€ëœ ìˆ˜ì‹:", "ê°ì§€ëœ ìˆ˜ì‹ï¼š", "**ê°ì§€ëœ ìˆ˜ì‹**", "ê°ì§€ëœ ìˆ˜ì‹"]):
                    logger.debug(f"ë¼ì¸ {i}: 'ê°ì§€ëœ ìˆ˜ì‹' ì„¹ì…˜ ë°œê²¬")
                    if current_section and current_content:
                        self._save_section(current_section, '\n'.join(current_content), 
                                         locals())
                    current_section = "formula"
                    current_content = []
                    remaining = line.replace("**ê°ì§€ëœ ìˆ˜ì‹**", "").replace("ê°ì§€ëœ ìˆ˜ì‹:", "").replace("ê°ì§€ëœ ìˆ˜ì‹ï¼š", "").strip()
                    if remaining:
                        current_content.append(remaining)
                elif any(marker in line for marker in ["í•µì‹¬ ê°œë…:", "í•µì‹¬ ê°œë…ï¼š", "**í•µì‹¬ ê°œë…**", "í•µì‹¬ ê°œë…"]):
                    logger.debug(f"ë¼ì¸ {i}: 'í•µì‹¬ ê°œë…' ì„¹ì…˜ ë°œê²¬")
                    if current_section and current_content:
                        self._save_section(current_section, '\n'.join(current_content), 
                                         locals())
                    current_section = "concept"
                    current_content = []
                    remaining = line.replace("**í•µì‹¬ ê°œë…**", "").replace("í•µì‹¬ ê°œë…:", "").replace("í•µì‹¬ ê°œë…ï¼š", "").strip()
                    if remaining:
                        current_content.append(remaining)
                elif any(marker in line for marker in ["ì§ˆë¬¸ ì˜ë„:", "ì§ˆë¬¸ ì˜ë„ï¼š", "**ì§ˆë¬¸ ì˜ë„**", "ì§ˆë¬¸ ì˜ë„"]):
                    logger.debug(f"ë¼ì¸ {i}: 'ì§ˆë¬¸ ì˜ë„' ì„¹ì…˜ ë°œê²¬")
                    if current_section and current_content:
                        self._save_section(current_section, '\n'.join(current_content), 
                                         locals())
                    current_section = "intent"
                    current_content = []
                    remaining = line.replace("**ì§ˆë¬¸ ì˜ë„**", "").replace("ì§ˆë¬¸ ì˜ë„:", "").replace("ì§ˆë¬¸ ì˜ë„ï¼š", "").strip()
                    if remaining:
                        current_content.append(remaining)
                elif line and current_section:
                    # í˜„ì¬ ì„¹ì…˜ì— ë‚´ìš© ì¶”ê°€
                    current_content.append(line)
                elif line and not current_section:
                    logger.debug(f"ë¼ì¸ {i}: ì„¹ì…˜ ì—†ì´ ë‚´ìš© ë°œê²¬: {line[:50]}...")
            
            # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
            if current_section and current_content:
                logger.debug(f"ë§ˆì§€ë§‰ ì„¹ì…˜ '{current_section}' ì €ì¥, ë‚´ìš© {len(current_content)}ì¤„")
                self._save_section(current_section, '\n'.join(current_content), locals())
            
            # íŒŒì‹± ê²°ê³¼ ë¡œê¹…
            logger.debug(f"íŒŒì‹± ì™„ë£Œ - í…ìŠ¤íŠ¸: {len(extracted_text)}ì, "
                        f"ìˆ˜ì‹: {len(formulas)}ê°œ, ê°œë…: {len(key_concepts)}ê°œ")
            
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            if not any([extracted_text, formulas, key_concepts, question_intent]):
                logger.warning("íŒŒì‹± ì‹¤íŒ¨ - ì›ë³¸ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©")
                extracted_text = content
            
            return AnalysisResult(
                success=True,
                extracted_text=extracted_text if extracted_text else None,
                formulas=formulas if formulas else None,
                key_concepts=key_concepts if key_concepts else None,
                question_intent=question_intent if question_intent else None,
                processing_time=processing_time,
                token_usage=token_usage,
                cost=cost
            )
            
        except Exception as e:
            logger.warning(f"ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return AnalysisResult(
                success=True,
                extracted_text=content,  # ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
                processing_time=processing_time,
                token_usage=token_usage,
                cost=cost
            )
    
    def _save_section(self, section_type: str, content: str, context: dict):
        """ì„¹ì…˜ ë‚´ìš© ì €ì¥ í—¬í¼ í•¨ìˆ˜"""
        content = content.strip()
        logger.debug(f"ì„¹ì…˜ ì €ì¥ - íƒ€ì…: {section_type}, ë‚´ìš© ê¸¸ì´: {len(content)}ì")
        
        if not content:
            logger.debug(f"ì„¹ì…˜ {section_type}ì˜ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ")
            return
            
        if section_type == "text":
            context['extracted_text'] = content
            logger.debug(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì €ì¥: {content[:100]}...")
        elif section_type == "formula":
            context['formulas'] = [f.strip() for f in content.split('\n') if f.strip()]
            logger.debug(f"ìˆ˜ì‹ {len(context['formulas'])}ê°œ ì €ì¥")
        elif section_type == "concept":
            # ì‰¼í‘œ ë˜ëŠ” ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„
            if ',' in content:
                context['key_concepts'] = [c.strip() for c in content.split(',') if c.strip()]
            else:
                context['key_concepts'] = [c.strip() for c in content.split('\n') if c.strip()]
            logger.debug(f"í•µì‹¬ ê°œë… {len(context['key_concepts'])}ê°œ ì €ì¥")
        elif section_type == "intent":
            context['question_intent'] = content
            logger.debug(f"ì§ˆë¬¸ ì˜ë„ ì €ì¥: {content[:100]}...")
    
    def _calculate_cost(self, token_usage: Dict[str, int]) -> float:
        """ë¹„ìš© ê³„ì‚° (GPT-5 ê¸°ì¤€)"""
        # GPT-5 ì˜ˆìƒ ê°€ê²© (GPT-4ë³´ë‹¤ ì•½ê°„ ë†’ê²Œ ì±…ì •)
        # input: $3.0/1M tokens, output: $12.0/1M tokens
        input_cost = token_usage.get('prompt_tokens', 0) * 3.0 / 1_000_000
        output_cost = token_usage.get('completion_tokens', 0) * 12.0 / 1_000_000
        total_cost = input_cost + output_cost
        
        # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
        logger.info(f"ğŸ’° í† í° ì‚¬ìš©: Input={token_usage.get('prompt_tokens', 0)}, "
                   f"Output={token_usage.get('completion_tokens', 0)}, "
                   f"Cost=${total_cost:.4f}")
        
        return total_cost
    
    def get_call_statistics(self) -> Dict[str, Any]:
        """í˜¸ì¶œ í†µê³„ ë°˜í™˜"""
        return {
            "current_call_count": self._call_count,
            "max_calls_per_query": self._max_calls_per_query,
            "calls_remaining": max(0, self._max_calls_per_query - self._call_count)
        }


def create_unified_processor(config: Optional[Dict] = None) -> UnifiedAnalysisProcessor:
    """í†µí•© ë¶„ì„ í”„ë¡œì„¸ì„œ ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    return UnifiedAnalysisProcessor(config)