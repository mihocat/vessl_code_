#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Main Application for RAG System
RAG ì‹œìŠ¤í…œ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import os
import sys
import time
import logging
import gradio as gr
from datetime import datetime

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from rag_system import ConcreteKoreanElectricalRAG
from llm_client import LLMClient

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RAGService:
    """RAG ì„œë¹„ìŠ¤ í†µí•© í´ë˜ìŠ¤"""
    
    def __init__(self):
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.rag_system = ConcreteKoreanElectricalRAG(embedding_model_name="jinaai/jina-embeddings-v3")
        self.llm_client = LLMClient()
        
        # ë°ì´í„° ë¡œë“œ
        self.rag_system.load_documents_from_dataset()
        
        logger.info("RAGService ì´ˆê¸°í™” ì™„ë£Œ")
    
    def process_query(self, question: str, user_id: str = "default") -> str:
        """ì‚¬ìš©ì ì§ˆì˜ ì²˜ë¦¬"""
        if not question.strip():
            return self._get_welcome_message()
        
        start_time = time.time()
        self.rag_system.service_stats["total_queries"] += 1
        
        # ì‚¬ìš©ì ì´ë ¥ í™•ì¸
        user_context = ""
        if user_id in self.rag_system.user_history and self.rag_system.user_history[user_id]:
            recent_history = self.rag_system.user_history[user_id][-3:]
            user_context = "ì´ì „ ëŒ€í™”: " + " | ".join(recent_history)
        
        # í–¥ìƒëœ í†µí•© ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        search_results, search_type = self.rag_system.enhanced_search_pipeline(question)
        
        response_parts = []
        
        # ê²€ìƒ‰ ê²°ê³¼ ìœ í˜•ë³„ ì²˜ë¦¬
        if search_type == "high_confidence_db":
            # ê³ ì‹ ë¢°ë„ DB ê²°ê³¼ - ì§ì ‘ ë‹µë³€ ì œê³µ
            best_result = search_results[0]
            doc_info = best_result["doc_info"]
            
            response_parts.append("**ì „ë¬¸ ì§€ì‹ë² ì´ìŠ¤ ë‹µë³€:**\n")
            response_parts.append(doc_info["answer"])
            response_parts.append(f"\n*[ë¶„ë¥˜: {doc_info['category']} | ì‹ ë¢°ë„: {best_result['final_score']:.2f}]*")
            self.rag_system.service_stats["successful_answers"] += 1
            
        elif search_type == "medium_confidence_db":
            # ì¤‘ê°„ ì‹ ë¢°ë„ DB ê²°ê³¼ - LLMìœ¼ë¡œ ì¬êµ¬ì„±
            context_parts = []
            for result in search_results[:2]:
                doc_info = result["doc_info"]
                context_parts.append(f"ì°¸ê³ ìë£Œ {len(context_parts)+1}: {doc_info['answer']}")
            
            context = "\n---\n".join(context_parts)
            if user_context:
                context = f"ì´ì „ ëŒ€í™”:\n{user_context}\n---\n{context}"
            
            answer = self.llm_client.query(question, context)
            response_parts.append(answer)
            response_parts.append(f"\n*[ì°¸ê³ : ì§€ì‹ë² ì´ìŠ¤ {len(search_results)}ê±´ ì¢…í•©]*")
            self.rag_system.service_stats["successful_answers"] += 1
            
        elif search_type == "hybrid_search":
            # DB + ì›¹ ê²€ìƒ‰ í•˜ì´ë¸Œë¦¬ë“œ
            db_results, web_results = search_results
            
            # DB ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            db_context = []
            for result in db_results[:2]:
                doc_info = result["doc_info"]
                db_context.append(f"ì „ë¬¸ìë£Œ: {doc_info['answer']}")
            
            # ì›¹ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            web_context = []
            for result in web_results[:2]:
                web_context.append(f"ì›¹ìë£Œ: {result['title']} - {result['snippet'][:150]}")
            
            # í†µí•© ì»¨í…ìŠ¤íŠ¸
            full_context = "\n".join(db_context + web_context)
            if user_context:
                full_context = f"ì´ì „ ëŒ€í™”: {user_context}\n---\n{full_context}"
            
            answer = self.llm_client.query(question, full_context)
            response_parts.append(answer)
            response_parts.append(f"\n*[í†µí•©ê²€ìƒ‰: DB {len(db_results)}ê±´ + ì›¹ {len(web_results)}ê±´]*")
            self.rag_system.service_stats["successful_answers"] += 1
            
        elif search_type == "web_only":
            # ì›¹ ê²€ìƒ‰ë§Œ ì‚¬ìš©
            web_context = []
            for result in search_results[:2]:
                web_context.append(f"{result['title']}: {result['snippet']}")
            
            context = "\n---\n".join(web_context)
            if user_context:
                context = f"ì´ì „ ëŒ€í™”: {user_context}\n---\n{context}"
            
            answer = self.llm_client.query(question, context)
            response_parts.append(answer)
            response_parts.append(f"\n*[ì›¹ê²€ìƒ‰ ê¸°ë°˜: {len(search_results)}ê±´ ì°¸ì¡°]*")
            self.rag_system.service_stats["successful_answers"] += 1
            
        elif search_type == "low_confidence_db":
            # ì €í’ˆì§ˆ DB ê²°ê³¼ë¼ë„ ì‹œë„
            if search_results:
                context_parts = [result["doc_info"]["answer"] for result in search_results[:2]]
                context = " | ".join(context_parts)
                
                answer = self.llm_client.query(question, context)
                response_parts.append(answer)
                response_parts.append("\n*[ì°¸ê³ : ë¶€ë¶„ì  ì¼ì¹˜ ì •ë³´ í™œìš©]*")
            else:
                response_parts.append(self._handle_non_electrical_query(question))
                
        else:
            # ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
            response_parts.append(self._handle_non_electrical_query(question))
        
        # ì¶”ê°€ ì •ë³´
        response_parts.append("\n\n---")
        response_parts.append(f"ì‘ë‹µì‹œê°„: {round(time.time() - start_time, 2)}ì´ˆ")
        
        # ìŠ¤ë§ˆíŠ¸ ê´€ë ¨ ì§ˆë¬¸ ì¶”ì²œ
        if search_type in ["high_confidence_db", "medium_confidence_db", "hybrid_search"]:
            db_results = search_results if search_type != "hybrid_search" else search_results[0]
            response_parts.append("\n**ê´€ë ¨ ì§ˆë¬¸ ì¶”ì²œ:**")
            categories = set()
            for result in db_results[:3]:
                if result["doc_info"] and result["doc_info"]["category"] not in categories:
                    categories.add(result["doc_info"]["category"])
                    response_parts.append(f"â€¢ {result['doc_info']['category']} ë¶„ì•¼ ì‹¬í™” í•™ìŠµ")
        
        response_parts.append("\nì–¸ì œë“ ì§€ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")
        
        # ì‚¬ìš©ì ì´ë ¥ ì €ì¥
        full_response = "\n".join(response_parts)
        self.rag_system.user_history[user_id].append(question[:50])
        if len(self.rag_system.user_history[user_id]) > 10:
            self.rag_system.user_history[user_id].pop(0)
        
        return full_response
    
    def _get_welcome_message(self) -> str:
        """í™˜ì˜ ë©”ì‹œì§€"""
        return """ğŸ”Œ **ì „ê¸°ê³µí•™ ì „ë¬¸ AI ìƒë‹´ì‚¬**ì…ë‹ˆë‹¤.

**ì£¼ìš” ì„œë¹„ìŠ¤:**
â€¢ ì „ê¸°ê³µí•™ ì´ë¡  ë° ì‹¤ë¬´ ìƒë‹´
â€¢ ì „ê¸°ê¸°ì‚¬/ì‚°ì—…ê¸°ì‚¬ ì‹œí—˜ ì§€ë„  
â€¢ íšŒë¡œ í•´ì„ ë° ì„¤ê³„ ì¡°ì–¸
â€¢ ì „ë ¥ì‹œìŠ¤í…œ ê´€ë ¨ ë¬¸ì˜

ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ì •í™•í•œ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."""
    
    def _handle_non_electrical_query(self, query: str) -> str:
        """ì „ê¸°ê³µí•™ ì™¸ ì§ˆë¬¸ ì§€ëŠ¥í˜• ì²˜ë¦¬"""
        # ì¼ë°˜ ì¸ì‚¬ë§ì´ë‚˜ ê°„ë‹¨í•œ ì§ˆë¬¸
        greetings = ["ì•ˆë…•", "ë°˜ê°€ì›Œ", "ê³ ë§ˆì›Œ", "ê°ì‚¬"]
        if any(greeting in query for greeting in greetings):
            return "ì•ˆë…•í•˜ì„¸ìš”! ì „ê¸°ê³µí•™ ê´€ë ¨ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë„ì›€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
        
        # ë„ì›€ë§ ìš”ì²­
        if any(word in query for word in ["ë„ì›€", "ì‚¬ìš©ë²•", "ì–´ë–»ê²Œ"]):
            return """ì „ê¸°ê³µí•™ ì „ë¬¸ ìƒë‹´ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

**ì§ˆë¬¸ ì˜ˆì‹œ:**
â€¢ ì˜´ì˜ ë²•ì¹™ì´ ë¬´ì—‡ì¸ê°€ìš”?
â€¢ ë³€ì••ê¸°ì˜ ë™ì‘ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”
â€¢ ì „ê¸°ê¸°ì‚¬ ì‹œí—˜ ì¤€ë¹„ ë°©ë²•ì€?
â€¢ ACì™€ DCì˜ ì°¨ì´ì ì€?

**/í†µê³„** ëª…ë ¹ìœ¼ë¡œ ì„œë¹„ìŠ¤ í˜„í™©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."""
        
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì „ê¸°ê³µí•™ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì „ê¸°, ì „ë ¥, íšŒë¡œ, ìê²©ì¦ ë“±ì— ëŒ€í•´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."


def create_gradio_interface(service: RAGService):
    """Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    
    def handle_query(message, history):
        """ì§ˆì˜ ì²˜ë¦¬"""
        if message.startswith("/í†µê³„"):
            return service.rag_system.get_service_statistics()
        elif message.startswith("/ë„ì›€") or message.startswith("/help"):
            return service._get_welcome_message()
        else:
            user_id = f"user_{len(history) % 100}"
            return service.process_query(message, user_id)
    
    demo = gr.ChatInterface(
        fn=handle_query,
        title="âš¡ ì „ê¸°ê³µí•™ ì „ë¬¸ AI ìƒë‹´ì‚¬",
        description="**ì „ê¸°ê³µí•™ ì´ë¡ ë¶€í„° ì‹¤ë¬´ê¹Œì§€, ì •í™•í•œ ì „ë¬¸ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤**\n\nâ€¢ ì „ê¸°ê¸°ì‚¬/ì‚°ì—…ê¸°ì‚¬ ì‹œí—˜ ëŒ€ë¹„ â€¢ íšŒë¡œ í•´ì„ ë° ì„¤ê³„ â€¢ ì „ë ¥ì‹œìŠ¤í…œ ìƒë‹´ â€¢ ì „ê¸°ê¸°ê¸° ì›ë¦¬ ì„¤ëª…",
        theme=gr.themes.Soft(primary_hue="blue", secondary_hue="sky"),
        chatbot=gr.Chatbot(
            height=600, 
            show_copy_button=True, 
            type="messages",
            avatar_images=(None, "âš¡")
        ),
        textbox=gr.Textbox(
            placeholder="ì „ê¸°ê³µí•™ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”... (ì˜ˆ: ì˜´ì˜ ë²•ì¹™, ë³€ì••ê¸° ì›ë¦¬, ì „ê¸°ê¸°ì‚¬ ì‹œí—˜)", 
            container=False, 
            scale=7
        ),
        type="messages",
        examples=[
            "ì˜´ì˜ ë²•ì¹™ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "ë³€ì••ê¸°ì˜ ë™ì‘ ì›ë¦¬ê°€ ê¶ê¸ˆí•©ë‹ˆë‹¤", 
            "ì „ê¸°ê¸°ì‚¬ ì‹œí—˜ ì¤€ë¹„ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "ACì™€ DCì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "í‚¤ë¥´íˆí˜¸í”„ ë²•ì¹™ì„ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”"
        ]
    )
    
    return demo


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("=== RAG Service ì‹œì‘ ===")
    
    try:
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        service = RAGService()
        logger.info("RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # vLLM ì„œë²„ ì—°ê²° í•„ìˆ˜ í™•ì¸
        logger.info("vLLM ì„œë²„ ì—°ê²° ëŒ€ê¸° ì¤‘...")
        if not service.llm_client.check_health():
            # ì„œë²„ ëŒ€ê¸° ë¡œì§ (wait_for_server ë©”ì„œë“œê°€ ì—†ìœ¼ë¯€ë¡œ ì§ì ‘ êµ¬í˜„)
            import time
            max_attempts = 30
            for i in range(max_attempts):
                if service.llm_client.check_health():
                    logger.info("vLLM ì„œë²„ ì—°ê²° ì„±ê³µ")
                    break
                time.sleep(3)
                if i % 5 == 4:
                    logger.info(f"vLLM ì„œë²„ ëŒ€ê¸° ì¤‘... ({i+1}/{max_attempts})")
            else:
                logger.error("vLLM ì„œë²„ ì—°ê²° ì‹¤íŒ¨ - ì„œë¹„ìŠ¤ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                raise RuntimeError("vLLM ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        else:
            logger.info("vLLM ì„œë²„ ì—°ê²° ì„±ê³µ")
        
        # Gradio ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
        app = create_gradio_interface(service)
        logger.info("Gradio ì¸í„°í˜ì´ìŠ¤ ì‹œì‘...")
        
        port = int(os.environ.get("GRADIO_SERVER_PORT", "7860"))
        logger.info(f"ì„œë²„ í¬íŠ¸: {port}")
        logger.info("=== ì „ê¸°ê³µí•™ ì „ë¬¸ RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ ===")
        
        app.launch(
            server_name="0.0.0.0", 
            server_port=port, 
            share=False,
            show_error=True,
            quiet=False,
            inbrowser=False,
            prevent_thread_lock=False,
            favicon_path=None,
            ssl_verify=False,
            allowed_paths=[],
            app_kwargs={"docs_url": None, "redoc_url": None}
        )
        
    except Exception as e:
        logger.error(f"ì„œë¹„ìŠ¤ ì‹œì‘ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise


if __name__ == "__main__":
    main()