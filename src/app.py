#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gradio UI Application for RAG System
RAG ì‹œìŠ¤í…œ Gradio UI ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import sys
import time
import logging
from typing import List, Tuple, Optional

import gradio as gr

from config import Config
from llm_client import LLMClient
from rag_system import RAGSystem, SearchResult
from services import WebSearchService, ResponseGenerator

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ChatService:
    """í†µí•© ì±—ë´‡ ì„œë¹„ìŠ¤"""
    
    def __init__(self, config: Config, llm_client: LLMClient):
        """
        ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            config: ì „ì²´ ì„¤ì • ê°ì²´
            llm_client: LLM í´ë¼ì´ì–¸íŠ¸
        """
        self.config = config
        self.llm_client = llm_client
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.rag_system = RAGSystem(
            rag_config=config.rag,
            dataset_config=config.dataset,
            llm_client=llm_client
        )
        self.web_search = WebSearchService(config.web_search)
        self.response_generator = ResponseGenerator(config.web_search)
        
        # ëŒ€í™” ì´ë ¥
        self.conversation_history = []
        
    def process_query(self, question: str, history: List[Tuple[str, str]]) -> str:
        """
        ì‚¬ìš©ì ì§ˆì˜ ì²˜ë¦¬
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            history: ëŒ€í™” ì´ë ¥
            
        Returns:
            ìƒì„±ëœ ì‘ë‹µ
        """
        start_time = time.time()
        
        # ë¹ˆ ì§ˆë¬¸ ì²˜ë¦¬
        if not question or not question.strip():
            return "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
        
        try:
            # RAG ê²€ìƒ‰ ìˆ˜í–‰
            results, max_score = self.rag_system.search(question)
            
            # ì‘ë‹µ ìƒì„±
            response = self._generate_response(question, results, max_score)
            
            # ì‘ë‹µ ì‹œê°„ ì¶”ê°€
            elapsed_time = time.time() - start_time
            response += f"\n\n_ì‘ë‹µì‹œê°„: {elapsed_time:.2f}ì´ˆ_"
            
            # ëŒ€í™” ì´ë ¥ ì—…ë°ì´íŠ¸
            self.conversation_history.append((question, response))
            
            return response
            
        except Exception as e:
            logger.error(f"Query processing failed: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    
    def _generate_response(self, question: str, results: List[SearchResult], max_score: float) -> str:
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            results: RAG ê²€ìƒ‰ ê²°ê³¼
            max_score: ìµœê³  ìœ ì‚¬ë„ ì ìˆ˜
            
        Returns:
            ìƒì„±ëœ ì‘ë‹µ
        """
        # response_header = f"### ì§ˆë¬¸: {question}\n\n"
        response_header = "ë‹µë³€: "
        
        # ì‹ ë¢°ë„ ìˆ˜ì¤€ ê²°ì •
        if max_score >= self.config.rag.high_confidence_threshold:
            confidence_level = "high"
        elif max_score >= self.config.rag.medium_confidence_threshold:
            confidence_level = "medium"
        else:
            confidence_level = "low"
        
        # ë†’ì€ ì‹ ë¢°ë„ - ì§ì ‘ ë‹µë³€ ì‚¬ìš©
        if confidence_level == "high" and results:
            best_result = results[0]
            response = response_header + best_result.answer
            
            if best_result.category and best_result.category != "general":
                response += f"\n\n_[ì¹´í…Œê³ ë¦¬: {best_result.category}]_"
        
        # ì¤‘ê°„/ë‚®ì€ ì‹ ë¢°ë„ - LLM í™œìš©
        else:
            # ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ (ë‚®ì€ ì‹ ë¢°ë„ì¸ ê²½ìš°)
            web_results = []
            if confidence_level == "low":
                web_results = self.web_search.search(question)
            
            # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            context = self.response_generator.prepare_context(results, web_results)
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.response_generator.generate_prompt(
                question, context, confidence_level
            )
            
            # LLM ì‘ë‹µ ìƒì„±
            try:
                if prompt:  # í”„ë¡¬í”„íŠ¸ê°€ ìˆëŠ” ê²½ìš°ë§Œ LLM í˜¸ì¶œ
                    llm_response = self.llm_client.query(prompt, "")
                    response = response_header + llm_response
                else:
                    response = response_header + "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            except Exception as e:
                logger.error(f"LLM response generation failed: {e}")
                response = response_header + "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        
        # ê´€ë ¨ ì§ˆë¬¸ ì¶”ì²œ
        related_questions = self._get_related_questions(question, results)
        if related_questions:
            response += "\n\n**ğŸ’¡ ê´€ë ¨ ì§ˆë¬¸:**"
            for q in related_questions:
                response += f"\n- {q}"
        
        # ë””ë²„ê·¸ ì •ë³´ (ê°œë°œ ëª¨ë“œì—ì„œë§Œ)
        # if logger.isEnabledFor(logging.DEBUG):
            response += f"\n\n_[ì ìˆ˜: {max_score:.3f}, ì‹ ë¢°ë„: {confidence_level}]_"
        
        return response
    
    def _get_related_questions(
        self, 
        question: str, 
        results: List[SearchResult]
    ) -> List[str]:
        """
        ê´€ë ¨ ì§ˆë¬¸ ì¶”ì¶œ
        
        Args:
            question: ì›ë³¸ ì§ˆë¬¸
            results: ê²€ìƒ‰ ê²°ê³¼
            
        Returns:
            ê´€ë ¨ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        if not results or len(results) < 2:
            return []
        
        related = []
        seen_questions = {question.lower()}
        
        for result in results[1:]:  # ì²« ë²ˆì§¸ ê²°ê³¼ëŠ” ì œì™¸
            if result.score >= 0.6:
                q_lower = result.question.lower()
                if q_lower not in seen_questions:
                    related.append(result.question)
                    seen_questions.add(q_lower)
                    
                    if len(related) >= 3:
                        break
        
        return related


def create_gradio_app(config: Optional[Config] = None) -> gr.Blocks:
    """
    Gradio ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
    
    Args:
        config: ì„¤ì • ê°ì²´ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        
    Returns:
        Gradio Blocks ì¸ìŠ¤í„´ìŠ¤
    """
    # ì„¤ì • ì´ˆê¸°í™”
    if config is None:
        config = Config()
    
    # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    llm_client = LLMClient(config.llm)
    
    # ì„œë²„ ëŒ€ê¸°
    logger.info("Waiting for LLM server...")
    if not llm_client.wait_for_server():
        logger.error("Failed to connect to LLM server")
        raise RuntimeError("LLM server connection failed")
    
    # ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    chat_service = ChatService(config, llm_client)
    
    # Gradio ì¸í„°í˜ì´ìŠ¤
    with gr.Blocks(title=config.app.title, theme=gr.themes.Soft()) as app:
        gr.Markdown(config.app.description)
        
        # ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
        with gr.Row():
            with gr.Column(scale=8):
                # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
                chatbot = gr.Chatbot(
                    label="ëŒ€í™”",
                    height=500,
                    bubble_full_width=False,
                    show_label=True
                )
                
                # ì…ë ¥ ì˜ì—­
                with gr.Row():
                    msg = gr.Textbox(
                        label="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
                        placeholder="ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”...",
                        lines=2,
                        scale=4
                    )
                    with gr.Column(scale=1):
                        submit = gr.Button("ì „ì†¡", variant="primary")
                        clear = gr.Button("ì´ˆê¸°í™”")
            
            # ì‚¬ì´ë“œë°”
            with gr.Column(scale=2):
                # ì˜ˆì œ ì§ˆë¬¸
                gr.Markdown("### ğŸ’¡ ì˜ˆì œ ì§ˆë¬¸")
                examples = gr.Examples(
                    examples=config.app.example_questions,
                    inputs=msg,
                    label="í´ë¦­í•˜ì—¬ ì‚¬ìš©"
                )
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        def respond(message: str, chat_history: List[Tuple[str, str]]):
            """ë©”ì‹œì§€ ì‘ë‹µ ì²˜ë¦¬"""
            if not message.strip():
                return "", chat_history
            
            response = chat_service.process_query(message, chat_history)
            chat_history.append((message, response))
            return "", chat_history
        
        def clear_chat():
            """ëŒ€í™” ì´ˆê¸°í™”"""
            chat_service.conversation_history.clear()
            return None, ""
        
        # ì´ë²¤íŠ¸ ë°”ì¸ë”©
        submit.click(respond, [msg, chatbot], [msg, chatbot])
        msg.submit(respond, [msg, chatbot], [msg, chatbot])
        clear.click(clear_chat, None, [chatbot, msg])
        
        # í†µê³„ í‘œì‹œ
        with gr.Accordion("ğŸ“Š ì„œë¹„ìŠ¤ í†µê³„", open=False):
            with gr.Row():
                stats_display = gr.Textbox(
                    label="í†µê³„",
                    interactive=False,
                    lines=6
                )
                
                def update_stats():
                    """í†µê³„ ì—…ë°ì´íŠ¸"""
                    stats = chat_service.rag_system.get_stats()
                    total = stats['total_queries']
                    
                    if total > 0:
                        high_pct = (stats['high_confidence_hits'] / total) * 100
                        medium_pct = (stats['medium_confidence_hits'] / total) * 100
                        low_pct = (stats['low_confidence_hits'] / total) * 100
                    else:
                        high_pct = medium_pct = low_pct = 0
                    
                    return (
                        f"ì´ ì¿¼ë¦¬ ìˆ˜: {total}\n"
                        f"ë†’ì€ ì‹ ë¢°ë„: {stats['high_confidence_hits']} ({high_pct:.1f}%)\n"
                        f"ì¤‘ê°„ ì‹ ë¢°ë„: {stats['medium_confidence_hits']} ({medium_pct:.1f}%)\n"
                        f"ë‚®ì€ ì‹ ë¢°ë„: {stats['low_confidence_hits']} ({low_pct:.1f}%)\n"
                        f"í‰ê·  ì‘ë‹µì‹œê°„: {stats['avg_response_time']:.2f}ì´ˆ"
                    )
                
                refresh_stats = gr.Button("ìƒˆë¡œê³ ì¹¨", size="sm")
                refresh_stats.click(update_stats, None, stats_display)
                
                # ì´ˆê¸° í†µê³„ í‘œì‹œ
                app.load(update_stats, None, stats_display)
    
    return app


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="RAG System Gradio UI")
    parser.add_argument(
        "--config", 
        type=str, 
        help="Path to config file (JSON format)"
    )
    parser.add_argument(
        "--server-port", 
        type=int, 
        default=7860,
        help="Server port (default: 7860)"
    )
    parser.add_argument(
        "--share", 
        action="store_true",
        help="Create public Gradio link"
    )
    
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    config = Config()
    
    # ëª…ë ¹ì¤„ ì¸ìë¡œ ì˜¤ë²„ë¼ì´ë“œ
    if args.server_port:
        config.app.server_port = args.server_port
    if args.share:
        config.app.share = args.share
    
    # ì•± ìƒì„± ë° ì‹¤í–‰
    try:
        app = create_gradio_app(config)
        app.launch(
            server_name=config.app.server_name,
            server_port=config.app.server_port,
            share=config.app.share
        )
    except Exception as e:
        logger.error(f"Failed to launch app: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()