#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê°œì„ ëœ Gradio UI ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import gradio as gr
import time
import logging
from typing import List, Tuple, Optional, Dict
from llm_client import LLMClient
from rag_system import ImprovedRAGSystem
from ddgs import DDGS

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ImprovedRAGService:
    def __init__(self, llm_client: LLMClient):
        """ê°œì„ ëœ RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.llm_client = llm_client
        self.rag_system = ImprovedRAGSystem(
            embedding_model_name="jinaai/jina-embeddings-v3",
            llm_client=llm_client
        )
        self.conversation_history = []
        
    def process_query(self, question: str, history: List[Tuple[str, str]]) -> str:
        """ì‚¬ìš©ì ì§ˆì˜ ì²˜ë¦¬"""
        start_time = time.time()
        
        # ë¹ˆ ì§ˆë¬¸ ì²˜ë¦¬
        if not question or not question.strip():
            return "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
        
        # ì „ê¸°ê³µí•™ ê´€ë ¨ì„± í™•ì¸
        is_electrical = self._is_electrical_query(question)
        
        if not is_electrical:
            # ì „ê¸°ê³µí•™ ì™¸ ì§ˆë¬¸ ì²˜ë¦¬
            return self._handle_non_electrical_query(question)
        
        # RAG ê²€ìƒ‰
        results, max_score = self.rag_system.search(question, k=5)
        
        # ì‘ë‹µ ìƒì„±
        response = self._generate_response(question, results, max_score)
        
        # ì‘ë‹µ ì‹œê°„ ì¶”ê°€
        elapsed_time = time.time() - start_time
        response += f"\n\nì‘ë‹µì‹œê°„: {elapsed_time:.2f}ì´ˆ"
        
        # ëŒ€í™” ì´ë ¥ ì—…ë°ì´íŠ¸
        self.conversation_history.append((question, response))
        
        return response
    
    def _is_electrical_query(self, query: str) -> bool:
        """ì „ê¸°ê³µí•™ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸"""
        query_lower = query.lower()
        
        # ì „ê¸°ê³µí•™ í‚¤ì›Œë“œ
        electrical_keywords = [
            # ê¸°ë³¸ ìš©ì–´
            "ì „ê¸°", "ì „ì••", "ì „ë¥˜", "ì €í•­", "íšŒë¡œ", "ì„í”¼ë˜ìŠ¤", "ì „ë ¥", "ì—ë„ˆì§€",
            # ìê²©ì¦
            "ì „ê¸°ê¸°ì‚¬", "ì‚°ì—…ê¸°ì‚¬", "ê¸°ëŠ¥ì‚¬", "ì „ê¸°ê³µì‚¬",
            # ê¸°ê¸°
            "ë³€ì••ê¸°", "ë°œì „ê¸°", "ì „ë™ê¸°", "ëª¨í„°", "ì°¨ë‹¨ê¸°", "ê³„ì „ê¸°",
            # ì´ë¡ 
            "ì˜´ì˜ë²•ì¹™", "í‚¤ë¥´íˆí˜¸í”„", "í˜ì´ì €", "ì—­ë¥ ", "ë¬´íš¨ì „ë ¥",
            # ì‹œì„¤
            "ë°°ì „", "ì†¡ì „", "ìˆ˜ì „", "ë³€ì „ì†Œ", "ì „ê¸°ì„¤ë¹„",
            # ì•ˆì „
            "ì ‘ì§€", "ëˆ„ì „", "ê°ì „", "ì ˆì—°",
            # íŠ¹ìˆ˜ í‚¤ì›Œë“œ
            "ë‹¤ì‚°ì—ë“€", "ë¯¸í˜¸"
        ]
        
        # í‚¤ì›Œë“œ ë§¤ì¹­
        for keyword in electrical_keywords:
            if keyword in query_lower:
                return True
        
        return False
    
    def _generate_response(self, question: str, results: List[Dict], max_score: float) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„±"""
        
        # ì ìˆ˜ ê¸°ë°˜ ì‘ë‹µ ì „ëµ
        if max_score >= 0.8:
            # ë§¤ìš° ë†’ì€ ì‹ ë¢°ë„ - ì§ì ‘ ë‹µë³€
            best_result = results[0]
            response = f"ì•ˆë…•í•˜ì„¸ìš”! ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.\n\n"
            response += f"**ì§ˆë¬¸**: {question}\n\n"
            response += f"**ë‹µë³€**:\n{best_result['answer']}\n"
            
            if best_result.get('category'):
                response += f"\n*[ë¶„ë¥˜: {best_result['category']}]*"
            
        elif max_score >= 0.5:
            # ì¤‘ê°„ ì‹ ë¢°ë„ - DB ë‹µë³€ + LLM ë³´ê°•
            context_parts = []
            for i, result in enumerate(results[:3]):
                if result['score'] >= 0.4:
                    context_parts.append(f"ì°¸ê³ ìë£Œ {i+1}: {result['answer']}")
            
            context = "\n\n".join(context_parts)
            
            # LLMìœ¼ë¡œ ì¬êµ¬ì„±
            llm_response = self.llm_client.query(question, context)
            response = llm_response
            
        elif max_score >= 0.3:
            # ë‚®ì€ ì‹ ë¢°ë„ - ì›¹ ê²€ìƒ‰ ì¶”ê°€
            # DB ê²°ê³¼
            db_context = []
            for result in results[:2]:
                if result['score'] >= 0.3:
                    db_context.append(result['answer'])
            
            # ì›¹ ê²€ìƒ‰
            web_results = self._search_web(question)
            web_context = []
            for web in web_results[:2]:
                web_context.append(f"{web['title']}: {web['snippet']}")
            
            # í†µí•© ì»¨í…ìŠ¤íŠ¸
            all_context = "\n".join(db_context + web_context)
            
            # LLM ì‘ë‹µ
            llm_response = self.llm_client.query(question, all_context)
            response = llm_response
            
        else:
            # ë§¤ìš° ë‚®ì€ ì‹ ë¢°ë„ - LLM ì§ì ‘ ì‘ë‹µ
            response = self._handle_low_confidence_query(question)
        
        # ê´€ë ¨ ì§ˆë¬¸ ì¶”ì²œ (ë†’ì€ ì‹ ë¢°ë„ì¼ ë•Œë§Œ)
        if max_score >= 0.5 and len(results) > 1:
            response += "\n\n**ê´€ë ¨ ì§ˆë¬¸ë“¤:**"
            seen_questions = {question.lower()}
            for result in results[1:4]:
                if result['question'].lower() not in seen_questions:
                    response += f"\n- {result['question']}"
                    seen_questions.add(result['question'].lower())
        
        response += "\n\nì–¸ì œë“ ì§€ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
        
        return response
    
    def _search_web(self, query: str) -> List[Dict]:
        """ì›¹ ê²€ìƒ‰"""
        try:
            with DDGS() as ddgs:
                results = []
                search_query = f"ì „ê¸°ê³µí•™ {query}"
                
                for r in ddgs.text(search_query, max_results=3):
                    results.append({
                        "title": r.get("title", ""),
                        "snippet": r.get("body", "")[:200],
                        "url": r.get("href", "")
                    })
                
                return results
        except Exception as e:
            logger.error(f"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _handle_non_electrical_query(self, question: str) -> str:
        """ì „ê¸°ê³µí•™ ì™¸ ì§ˆë¬¸ ì²˜ë¦¬"""
        # LLMìœ¼ë¡œ ì¼ë°˜ ë‹µë³€ ìƒì„±
        response = self.llm_client.query(
            question,
            "ì´ ì§ˆë¬¸ì€ ì „ê¸°ê³µí•™ê³¼ ê´€ë ¨ì´ ì—†ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ë˜, ê°„ë‹¨íˆ ë‹µë³€í•˜ì„¸ìš”."
        )
        
        response += "\n\n*ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.*"
        
        return response
    
    def _handle_low_confidence_query(self, question: str) -> str:
        """ë‚®ì€ ì‹ ë¢°ë„ ì§ˆë¬¸ ì²˜ë¦¬"""
        # LLM ì§ì ‘ ì‘ë‹µ
        response = self.llm_client.query(
            question,
            "ì „ê¸°ê³µí•™ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´ ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."
        )
        
        response += "\n\n*ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.*"
        
        return response


def create_gradio_app(llm_url: str = "http://localhost:8000") -> gr.Blocks:
    """Gradio ì•± ìƒì„±"""
    # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    llm_client = LLMClient(base_url=llm_url)
    
    # RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    rag_service = ImprovedRAGService(llm_client)
    
    # Gradio ì¸í„°í˜ì´ìŠ¤
    with gr.Blocks(title="ì „ê¸°ê³µí•™ AI ì±—ë´‡ (ê°œì„ íŒ)") as app:
        gr.Markdown(
            """
            # ğŸ”Œ ì „ê¸°ê³µí•™ AI ì±—ë´‡ (ê°œì„ íŒ)
            
            ì „ê¸°ê³µí•™ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.
            - ì „ê¸°ê¸°ì‚¬/ì‚°ì—…ê¸°ì‚¬/ê¸°ëŠ¥ì‚¬ ì‹œí—˜ ë¬¸ì œ
            - ì „ê¸° ì´ë¡  ë° ì‹¤ë¬´
            - ì „ê¸° ì„¤ë¹„ ë° ì•ˆì „
            
            **ê°œì„ ì‚¬í•­:**
            - jinaai/jina-embeddings-v3 ì„ë² ë”© ëª¨ë¸
            - í–¥ìƒëœ ê²€ìƒ‰ ì •í™•ë„
            - íŠ¹ìˆ˜ í‚¤ì›Œë“œ ì²˜ë¦¬
            """
        )
        
        # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
        chatbot = gr.Chatbot(
            label="ëŒ€í™”",
            height=500,
            bubble_full_width=False
        )
        
        # ì…ë ¥ì°½
        msg = gr.Textbox(
            label="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: ë‹¤ì‚°ì—ë“€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            lines=2
        )
        
        # ë²„íŠ¼ë“¤
        with gr.Row():
            submit = gr.Button("ì „ì†¡", variant="primary")
            clear = gr.Button("ëŒ€í™” ì´ˆê¸°í™”")
        
        # ì˜ˆì œ ì§ˆë¬¸ë“¤
        gr.Examples(
            examples=[
                "ë‹¤ì‚°ì—ë“€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "R-CíšŒë¡œ í•©ì„± ì„í”¼ë˜ìŠ¤ì—ì„œ -jë¥¼ ë¶™ì´ëŠ” ì´ìœ ëŠ”?",
                "ê³¼ë„í˜„ìƒê³¼ ì¸ë•í„´ìŠ¤ Lì˜ ê´€ê³„ëŠ”?",
                "ëŒ ë¶€ì†ì„¤ë¹„ ì¤‘ ìˆ˜ë¡œì™€ ì—¬ìˆ˜ë¡œì˜ ì°¨ì´ëŠ”?",
                "ì„œë³´ëª¨í„°ì˜ ë™ì‘ ì›ë¦¬ëŠ”?"
            ],
            inputs=msg,
            label="ì˜ˆì œ ì§ˆë¬¸"
        )
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        def respond(message, chat_history):
            response = rag_service.process_query(message, chat_history)
            chat_history.append((message, response))
            return "", chat_history
        
        # ì´ë²¤íŠ¸ ë°”ì¸ë”©
        submit.click(respond, [msg, chatbot], [msg, chatbot])
        msg.submit(respond, [msg, chatbot], [msg, chatbot])
        clear.click(lambda: (None, ""), None, [chatbot, msg])
        
        # í†µê³„ í‘œì‹œ
        with gr.Accordion("ì„œë¹„ìŠ¤ í†µê³„", open=False):
            stats_display = gr.Textbox(
                label="í†µê³„",
                interactive=False,
                lines=5
            )
            
            def update_stats():
                stats = rag_service.rag_system.service_stats
                return (
                    f"ì´ ì¿¼ë¦¬: {stats['total_queries']}\n"
                    f"DB íˆíŠ¸: {stats['db_hits']}\n"
                    f"ì›¹ ê²€ìƒ‰: {stats['web_searches']}\n"
                    f"LLM ì‘ë‹µ: {stats['llm_responses']}\n"
                    f"í‰ê·  ì‘ë‹µì‹œê°„: {stats['avg_response_time']:.2f}ì´ˆ"
                )
            
            refresh_stats = gr.Button("í†µê³„ ìƒˆë¡œê³ ì¹¨")
            refresh_stats.click(update_stats, None, stats_display)
    
    return app


if __name__ == "__main__":
    app = create_gradio_app()
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )