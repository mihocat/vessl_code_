#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì°¨ì„¸ëŒ€ AI í†µí•© ì‹œìŠ¤í…œ
Advanced AI Integration System with Latest Trends

ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ + ì¶”ë¡  ì—”ì§„ + ë©”ëª¨ë¦¬ ê´€ë¦¬ + ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬
Agent System + Reasoning Engine + Memory Management + Multimodal Processing
"""

import os
import json
import time
import asyncio
import logging
from typing import Dict, List, Optional, Any, Union, Tuple, Callable
from dataclasses import dataclass, asdict, field
from datetime import datetime, timedelta
from enum import Enum
from abc import ABC, abstractmethod
import uuid

# ê¸°ì¡´ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì„í¬íŠ¸
from multimodal_pipeline import MultimodalPipeline, ProcessingResult, PipelineConfig
from query_intent_analyzer import QueryIntentAnalyzer, QueryType, ComplexityLevel
from enhanced_rag_system import EnhancedRAGSystem, SearchStrategy
from enhanced_llm_system import EnhancedLLMSystem, ModelDomain

logger = logging.getLogger(__name__)


class AgentType(Enum):
    """ì—ì´ì „íŠ¸ íƒ€ì…"""
    COORDINATOR = "coordinator"          # ì¡°ì •ì - ì „ì²´ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬
    ANALYZER = "analyzer"                # ë¶„ì„ê°€ - ì§ˆì˜ ë° ë°ì´í„° ë¶„ì„
    RESEARCHER = "researcher"            # ì—°êµ¬ì› - ì •ë³´ ê²€ìƒ‰ ë° ì¡°ì‚¬
    REASONER = "reasoner"               # ì¶”ë¡ ê°€ - ë…¼ë¦¬ì  ì¶”ë¡  ë° ë¬¸ì œ í•´ê²°
    SPECIALIST = "specialist"            # ì „ë¬¸ê°€ - ë„ë©”ì¸ íŠ¹í™” ì²˜ë¦¬
    VALIDATOR = "validator"              # ê²€ì¦ì - ê²°ê³¼ ê²€ì¦ ë° í’ˆì§ˆ ê´€ë¦¬
    SYNTHESIZER = "synthesizer"         # ì¢…í•©ì - ìµœì¢… ë‹µë³€ ìƒì„±


class ReasoningType(Enum):
    """ì¶”ë¡  íƒ€ì…"""
    DEDUCTIVE = "deductive"              # ì—°ì—­ì  ì¶”ë¡ 
    INDUCTIVE = "inductive"              # ê·€ë‚©ì  ì¶”ë¡ 
    ABDUCTIVE = "abductive"              # ê°€ì„¤ì  ì¶”ë¡ 
    ANALOGICAL = "analogical"            # ìœ ì¶”ì  ì¶”ë¡ 
    CAUSAL = "causal"                    # ì¸ê³¼ì  ì¶”ë¡ 
    PROBABILISTIC = "probabilistic"      # í™•ë¥ ì  ì¶”ë¡ 
    CHAIN_OF_THOUGHT = "chain_of_thought" # ì‚¬ê³  ì—°ì‡„


class MemoryType(Enum):
    """ë©”ëª¨ë¦¬ íƒ€ì…"""
    WORKING = "working"                  # ì‘ì—… ë©”ëª¨ë¦¬ (ë‹¨ê¸°)
    EPISODIC = "episodic"               # ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬ (ê²½í—˜)
    SEMANTIC = "semantic"                # ì˜ë¯¸ ë©”ëª¨ë¦¬ (ì§€ì‹)
    PROCEDURAL = "procedural"            # ì ˆì°¨ ë©”ëª¨ë¦¬ (ë°©ë²•)
    LONG_TERM = "long_term"             # ì¥ê¸° ë©”ëª¨ë¦¬


@dataclass
class AgentCapability:
    """ì—ì´ì „íŠ¸ ëŠ¥ë ¥"""
    name: str
    description: str
    input_types: List[str]
    output_types: List[str]
    confidence_level: float
    processing_time_estimate: float
    dependencies: List[str] = field(default_factory=list)


@dataclass
class ReasoningStep:
    """ì¶”ë¡  ë‹¨ê³„"""
    step_id: str
    reasoning_type: ReasoningType
    premise: str
    inference_rule: str
    conclusion: str
    confidence: float
    evidence: List[str] = field(default_factory=list)
    alternatives: List[str] = field(default_factory=list)


@dataclass
class MemoryEntry:
    """ë©”ëª¨ë¦¬ í•­ëª©"""
    memory_id: str
    memory_type: MemoryType
    content: Any
    timestamp: datetime
    access_count: int = 0
    last_accessed: Optional[datetime] = None
    relevance_score: float = 1.0
    tags: List[str] = field(default_factory=list)
    context: Dict[str, Any] = field(default_factory=dict)


@dataclass
class AgentTask:
    """ì—ì´ì „íŠ¸ ì‘ì—…"""
    task_id: str
    agent_type: AgentType
    description: str
    input_data: Dict[str, Any]
    priority: int = 1
    timeout: float = 30.0
    dependencies: List[str] = field(default_factory=list)
    status: str = "pending"  # pending, running, completed, failed
    result: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None


class BaseAgent(ABC):
    """ê¸°ë³¸ ì—ì´ì „íŠ¸ ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self, agent_id: str, agent_type: AgentType, capabilities: List[AgentCapability]):
        self.agent_id = agent_id
        self.agent_type = agent_type
        self.capabilities = capabilities
        self.memory_system = None
        self.reasoning_engine = None
        self.status = "idle"
        self.current_task = None
        
        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            'tasks_completed': 0,
            'tasks_failed': 0,
            'average_processing_time': 0.0,
            'average_confidence': 0.0,
            'total_processing_time': 0.0
        }
    
    @abstractmethod
    async def process_task(self, task: AgentTask) -> Dict[str, Any]:
        """ì‘ì—… ì²˜ë¦¬"""
        pass
    
    @abstractmethod
    def can_handle_task(self, task: AgentTask) -> bool:
        """ì‘ì—… ì²˜ë¦¬ ê°€ëŠ¥ ì—¬ë¶€"""
        pass
    
    def update_stats(self, processing_time: float, confidence: float, success: bool):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        if success:
            self.stats['tasks_completed'] += 1
            
            # í‰ê·  ì²˜ë¦¬ ì‹œê°„
            n = self.stats['tasks_completed']
            prev_avg_time = self.stats['average_processing_time']
            self.stats['average_processing_time'] = (
                (prev_avg_time * (n - 1) + processing_time) / n
            )
            
            # í‰ê·  ì‹ ë¢°ë„
            prev_avg_conf = self.stats['average_confidence']
            self.stats['average_confidence'] = (
                (prev_avg_conf * (n - 1) + confidence) / n
            )
        else:
            self.stats['tasks_failed'] += 1
        
        self.stats['total_processing_time'] += processing_time


class ReasoningEngine:
    """ì¶”ë¡  ì—”ì§„"""
    
    def __init__(self):
        self.reasoning_history = []
        self.knowledge_base = {}
        self.inference_rules = self._load_inference_rules()
    
    def _load_inference_rules(self) -> Dict[str, Callable]:
        """ì¶”ë¡  ê·œì¹™ ë¡œë“œ"""
        return {
            'modus_ponens': self._modus_ponens,
            'modus_tollens': self._modus_tollens,
            'syllogism': self._syllogism,
            'abduction': self._abductive_reasoning,
            'analogy': self._analogical_reasoning,
            'causal_chain': self._causal_reasoning
        }
    
    async def reason(self, 
                    premises: List[str], 
                    reasoning_type: ReasoningType,
                    context: Optional[Dict] = None) -> List[ReasoningStep]:
        """ì¶”ë¡  ìˆ˜í–‰"""
        reasoning_steps = []
        step_id = str(uuid.uuid4())
        
        try:
            if reasoning_type == ReasoningType.CHAIN_OF_THOUGHT:
                reasoning_steps = await self._chain_of_thought_reasoning(premises, context)
            elif reasoning_type == ReasoningType.DEDUCTIVE:
                reasoning_steps = await self._deductive_reasoning(premises, context)
            elif reasoning_type == ReasoningType.INDUCTIVE:
                reasoning_steps = await self._inductive_reasoning(premises, context)
            elif reasoning_type == ReasoningType.ABDUCTIVE:
                reasoning_steps = await self._abductive_reasoning_advanced(premises, context)
            elif reasoning_type == ReasoningType.CAUSAL:
                reasoning_steps = await self._causal_reasoning_advanced(premises, context)
            else:
                # ê¸°ë³¸ ì¶”ë¡ 
                step = ReasoningStep(
                    step_id=step_id,
                    reasoning_type=reasoning_type,
                    premise="; ".join(premises),
                    inference_rule="basic_inference",
                    conclusion="ê¸°ë³¸ ì¶”ë¡  ê²°ê³¼ê°€ ë„ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.",
                    confidence=0.7
                )
                reasoning_steps = [step]
            
            # ì¶”ë¡  íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.reasoning_history.extend(reasoning_steps)
            
            return reasoning_steps
            
        except Exception as e:
            logger.error(f"Reasoning failed: {e}")
            return []
    
    async def _chain_of_thought_reasoning(self, premises: List[str], context: Optional[Dict]) -> List[ReasoningStep]:
        """ì‚¬ê³  ì—°ì‡„ ì¶”ë¡ """
        steps = []
        
        # ê° ì „ì œì— ëŒ€í•´ ë‹¨ê³„ë³„ ë¶„ì„
        for i, premise in enumerate(premises):
            step_id = f"cot_{i+1}"
            
            # ì „ì œ ë¶„ì„
            analysis = await self._analyze_premise(premise)
            
            step = ReasoningStep(
                step_id=step_id,
                reasoning_type=ReasoningType.CHAIN_OF_THOUGHT,
                premise=premise,
                inference_rule="step_by_step_analysis",
                conclusion=analysis.get('conclusion', ''),
                confidence=analysis.get('confidence', 0.7),
                evidence=analysis.get('evidence', [])
            )
            steps.append(step)
        
        # ì¢…í•© ê²°ë¡ 
        if len(steps) > 1:
            final_step = ReasoningStep(
                step_id="cot_final",
                reasoning_type=ReasoningType.CHAIN_OF_THOUGHT,
                premise="ì¢…í•© ë¶„ì„",
                inference_rule="synthesis",
                conclusion=await self._synthesize_conclusions([s.conclusion for s in steps]),
                confidence=sum(s.confidence for s in steps) / len(steps)
            )
            steps.append(final_step)
        
        return steps
    
    async def _analyze_premise(self, premise: str) -> Dict[str, Any]:
        """ì „ì œ ë¶„ì„"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
        keywords = ['ì „ì••', 'ì „ë¥˜', 'ì €í•­', 'ì „ë ¥', 'íšŒë¡œ', 'ë²•ì¹™', 'ê³µì‹']
        evidence = []
        
        for keyword in keywords:
            if keyword in premise:
                evidence.append(f"{keyword} ê´€ë ¨ ë‚´ìš© ë°œê²¬")
        
        confidence = min(1.0, len(evidence) * 0.2 + 0.5)
        
        return {
            'conclusion': f"'{premise}'ì— ëŒ€í•œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            'confidence': confidence,
            'evidence': evidence
        }
    
    async def _synthesize_conclusions(self, conclusions: List[str]) -> str:
        """ê²°ë¡  ì¢…í•©"""
        if not conclusions:
            return "ê²°ë¡ ì„ ë„ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return f"ë‹¨ê³„ë³„ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ë©´: {'; '.join(conclusions[:3])}"
    
    async def _deductive_reasoning(self, premises: List[str], context: Optional[Dict]) -> List[ReasoningStep]:
        """ì—°ì—­ì  ì¶”ë¡ """
        # ê°„ë‹¨í•œ ì—°ì—­ì  ì¶”ë¡  êµ¬í˜„
        step = ReasoningStep(
            step_id="deductive_1",
            reasoning_type=ReasoningType.DEDUCTIVE,
            premise="; ".join(premises),
            inference_rule="deductive_logic",
            conclusion="ì£¼ì–´ì§„ ì „ì œë“¤ë¡œë¶€í„° ë…¼ë¦¬ì  ê²°ë¡ ì„ ë„ì¶œí–ˆìŠµë‹ˆë‹¤.",
            confidence=0.8
        )
        return [step]
    
    async def _inductive_reasoning(self, premises: List[str], context: Optional[Dict]) -> List[ReasoningStep]:
        """ê·€ë‚©ì  ì¶”ë¡ """
        step = ReasoningStep(
            step_id="inductive_1",
            reasoning_type=ReasoningType.INDUCTIVE,
            premise="; ".join(premises),
            inference_rule="pattern_recognition",
            conclusion="ê´€ì°°ëœ íŒ¨í„´ìœ¼ë¡œë¶€í„° ì¼ë°˜ì  ì›ë¦¬ë¥¼ ì¶”ë¡ í–ˆìŠµë‹ˆë‹¤.",
            confidence=0.7
        )
        return [step]
    
    async def _abductive_reasoning_advanced(self, premises: List[str], context: Optional[Dict]) -> List[ReasoningStep]:
        """ê³ ê¸‰ ê°€ì„¤ì  ì¶”ë¡ """
        step = ReasoningStep(
            step_id="abductive_1",
            reasoning_type=ReasoningType.ABDUCTIVE,
            premise="; ".join(premises),
            inference_rule="best_explanation",
            conclusion="ê´€ì°°ëœ í˜„ìƒì„ ê°€ì¥ ì˜ ì„¤ëª…í•˜ëŠ” ê°€ì„¤ì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤.",
            confidence=0.6
        )
        return [step]
    
    async def _causal_reasoning_advanced(self, premises: List[str], context: Optional[Dict]) -> List[ReasoningStep]:
        """ê³ ê¸‰ ì¸ê³¼ì  ì¶”ë¡ """
        step = ReasoningStep(
            step_id="causal_1",
            reasoning_type=ReasoningType.CAUSAL,
            premise="; ".join(premises),
            inference_rule="causal_chain",
            conclusion="ì›ì¸ê³¼ ê²°ê³¼ì˜ ê´€ê³„ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.",
            confidence=0.8
        )
        return [step]
    
    # ê¸°ë³¸ ì¶”ë¡  ê·œì¹™ë“¤
    def _modus_ponens(self, p: str, p_implies_q: str) -> str:
        return f"{p}ì´ê³  {p_implies_q}ì´ë¯€ë¡œ, Qê°€ ì°¸ì…ë‹ˆë‹¤."
    
    def _modus_tollens(self, not_q: str, p_implies_q: str) -> str:
        return f"{not_q}ì´ê³  {p_implies_q}ì´ë¯€ë¡œ, Pê°€ ê±°ì§“ì…ë‹ˆë‹¤."
    
    def _syllogism(self, major: str, minor: str) -> str:
        return f"{major}ì´ê³  {minor}ì´ë¯€ë¡œ, ê²°ë¡ ì´ ë„ì¶œë©ë‹ˆë‹¤."
    
    def _abductive_reasoning(self, observation: str) -> str:
        return f"{observation}ì„ ì„¤ëª…í•˜ëŠ” ê°€ì¥ ì ì ˆí•œ ê°€ì„¤ì„ ì œì‹œí•©ë‹ˆë‹¤."
    
    def _analogical_reasoning(self, source: str, target: str) -> str:
        return f"{source}ì™€ {target} ê°„ì˜ ìœ ì‚¬ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ë¡ í•©ë‹ˆë‹¤."
    
    def _causal_reasoning(self, cause: str, effect: str) -> str:
        return f"{cause}ê°€ {effect}ì˜ ì›ì¸ì„ì„ ì¶”ë¡ í•©ë‹ˆë‹¤."


class MemorySystem:
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, max_working_memory: int = 100, max_long_term_memory: int = 10000):
        self.working_memory: Dict[str, MemoryEntry] = {}
        self.episodic_memory: Dict[str, MemoryEntry] = {}
        self.semantic_memory: Dict[str, MemoryEntry] = {}
        self.procedural_memory: Dict[str, MemoryEntry] = {}
        self.long_term_memory: Dict[str, MemoryEntry] = {}
        
        self.max_working_memory = max_working_memory
        self.max_long_term_memory = max_long_term_memory
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ìœ„í•œ ìŠ¤ì¼€ì¤„ëŸ¬
        self.last_cleanup = datetime.now()
        self.cleanup_interval = timedelta(hours=1)
    
    async def store_memory(self, content: Any, memory_type: MemoryType, 
                          tags: List[str] = None, context: Dict[str, Any] = None) -> str:
        """ë©”ëª¨ë¦¬ ì €ì¥"""
        memory_id = str(uuid.uuid4())
        
        memory_entry = MemoryEntry(
            memory_id=memory_id,
            memory_type=memory_type,
            content=content,
            timestamp=datetime.now(),
            tags=tags or [],
            context=context or {}
        )
        
        # ë©”ëª¨ë¦¬ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ì €ì¥ì†Œì— ì €ì¥
        if memory_type == MemoryType.WORKING:
            self.working_memory[memory_id] = memory_entry
            await self._manage_working_memory_capacity()
        elif memory_type == MemoryType.EPISODIC:
            self.episodic_memory[memory_id] = memory_entry
        elif memory_type == MemoryType.SEMANTIC:
            self.semantic_memory[memory_id] = memory_entry
        elif memory_type == MemoryType.PROCEDURAL:
            self.procedural_memory[memory_id] = memory_entry
        else:
            self.long_term_memory[memory_id] = memory_entry
            await self._manage_long_term_memory_capacity()
        
        logger.info(f"Memory stored: {memory_type.value} - {memory_id}")
        return memory_id
    
    async def retrieve_memory(self, memory_id: str) -> Optional[MemoryEntry]:
        """ë©”ëª¨ë¦¬ ê²€ìƒ‰"""
        # ëª¨ë“  ë©”ëª¨ë¦¬ ì €ì¥ì†Œì—ì„œ ê²€ìƒ‰
        for storage in [self.working_memory, self.episodic_memory, 
                       self.semantic_memory, self.procedural_memory, self.long_term_memory]:
            if memory_id in storage:
                memory = storage[memory_id]
                memory.access_count += 1
                memory.last_accessed = datetime.now()
                return memory
        
        return None
    
    async def search_memory(self, query: str, memory_types: List[MemoryType] = None,
                           tags: List[str] = None, limit: int = 10) -> List[MemoryEntry]:
        """ë©”ëª¨ë¦¬ ê²€ìƒ‰"""
        results = []
        
        # ê²€ìƒ‰ ëŒ€ìƒ ë©”ëª¨ë¦¬ íƒ€ì… ê²°ì •
        search_types = memory_types or list(MemoryType)
        
        for memory_type in search_types:
            storage = self._get_storage_by_type(memory_type)
            
            for memory in storage.values():
                # ë‚´ìš© ê¸°ë°˜ ê²€ìƒ‰
                content_match = query.lower() in str(memory.content).lower()
                
                # íƒœê·¸ ê¸°ë°˜ ê²€ìƒ‰
                tag_match = not tags or any(tag in memory.tags for tag in tags)
                
                if content_match and tag_match:
                    results.append(memory)
        
        # ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
        for memory in results:
            memory.relevance_score = self._calculate_relevance(memory, query, tags)
        
        results.sort(key=lambda x: x.relevance_score, reverse=True)
        return results[:limit]
    
    def _get_storage_by_type(self, memory_type: MemoryType) -> Dict[str, MemoryEntry]:
        """ë©”ëª¨ë¦¬ íƒ€ì…ë³„ ì €ì¥ì†Œ ë°˜í™˜"""
        storage_map = {
            MemoryType.WORKING: self.working_memory,
            MemoryType.EPISODIC: self.episodic_memory,
            MemoryType.SEMANTIC: self.semantic_memory,
            MemoryType.PROCEDURAL: self.procedural_memory,
            MemoryType.LONG_TERM: self.long_term_memory
        }
        return storage_map.get(memory_type, {})
    
    def _calculate_relevance(self, memory: MemoryEntry, query: str, tags: List[str]) -> float:
        """ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # ë‚´ìš© ìœ ì‚¬ë„
        content_str = str(memory.content).lower()
        query_words = query.lower().split()
        matching_words = sum(1 for word in query_words if word in content_str)
        content_score = matching_words / len(query_words) if query_words else 0
        
        # íƒœê·¸ ë§¤ì¹­
        tag_score = 0.0
        if tags and memory.tags:
            matching_tags = len(set(tags) & set(memory.tags))
            tag_score = matching_tags / len(tags)
        
        # ì ‘ê·¼ ë¹ˆë„ (ì¸ê¸°ë„)
        access_score = min(1.0, memory.access_count / 10)
        
        # ì‹œê°„ ê°€ì¤‘ì¹˜ (ìµœê·¼ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
        time_diff = datetime.now() - memory.timestamp
        time_score = max(0.1, 1.0 - (time_diff.days / 30))
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        score = (content_score * 0.4 + tag_score * 0.3 + 
                access_score * 0.2 + time_score * 0.1)
        
        return score
    
    async def _manage_working_memory_capacity(self):
        """ì‘ì—… ë©”ëª¨ë¦¬ ìš©ëŸ‰ ê´€ë¦¬"""
        if len(self.working_memory) > self.max_working_memory:
            # ì˜¤ë˜ë˜ê³  ëœ ì‚¬ìš©ëœ ë©”ëª¨ë¦¬ ì œê±°
            sorted_memories = sorted(
                self.working_memory.items(),
                key=lambda x: (x[1].access_count, x[1].timestamp)
            )
            
            # ê°€ì¥ ì˜¤ë˜ë˜ê³  ëœ ì‚¬ìš©ëœ ë©”ëª¨ë¦¬ë¥¼ ì¥ê¸° ë©”ëª¨ë¦¬ë¡œ ì´ë™
            for memory_id, memory in sorted_memories[:10]:
                self.long_term_memory[memory_id] = memory
                del self.working_memory[memory_id]
    
    async def _manage_long_term_memory_capacity(self):
        """ì¥ê¸° ë©”ëª¨ë¦¬ ìš©ëŸ‰ ê´€ë¦¬"""
        if len(self.long_term_memory) > self.max_long_term_memory:
            # ì˜¤ë˜ë˜ê³  ê´€ë ¨ë„ê°€ ë‚®ì€ ë©”ëª¨ë¦¬ ì œê±°
            sorted_memories = sorted(
                self.long_term_memory.items(),
                key=lambda x: (x[1].relevance_score, x[1].timestamp)
            )
            
            # ê°€ì¥ ê´€ë ¨ë„ê°€ ë‚®ì€ ë©”ëª¨ë¦¬ ì œê±°
            for memory_id, _ in sorted_memories[:100]:
                del self.long_term_memory[memory_id]
    
    async def cleanup_memory(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        if datetime.now() - self.last_cleanup > self.cleanup_interval:
            await self._manage_working_memory_capacity()
            await self._manage_long_term_memory_capacity()
            self.last_cleanup = datetime.now()
            logger.info("Memory cleanup completed")
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ í†µê³„"""
        return {
            'working_memory_count': len(self.working_memory),
            'episodic_memory_count': len(self.episodic_memory),
            'semantic_memory_count': len(self.semantic_memory),
            'procedural_memory_count': len(self.procedural_memory),
            'long_term_memory_count': len(self.long_term_memory),
            'total_memory_count': (len(self.working_memory) + len(self.episodic_memory) + 
                                 len(self.semantic_memory) + len(self.procedural_memory) + 
                                 len(self.long_term_memory)),
            'last_cleanup': self.last_cleanup.isoformat()
        }


class CoordinatorAgent(BaseAgent):
    """ì¡°ì •ì ì—ì´ì „íŠ¸ - ì „ì²´ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬"""
    
    def __init__(self):
        capabilities = [
            AgentCapability(
                name="task_orchestration",
                description="ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‘ì—… ì¡°ì •",
                input_types=["task_list", "agent_pool"],
                output_types=["execution_plan", "coordination_result"],
                confidence_level=0.9,
                processing_time_estimate=2.0
            )
        ]
        super().__init__("coordinator_001", AgentType.COORDINATOR, capabilities)
    
    async def process_task(self, task: AgentTask) -> Dict[str, Any]:
        """ì‘ì—… ì²˜ë¦¬"""
        start_time = time.time()
        
        try:
            # ì‘ì—… ë¶„í•´ ë° ì—ì´ì „íŠ¸ í• ë‹¹
            subtasks = await self._decompose_task(task)
            execution_plan = await self._create_execution_plan(subtasks)
            
            result = {
                'success': True,
                'subtasks': subtasks,
                'execution_plan': execution_plan,
                'coordination_strategy': 'parallel_with_dependencies'
            }
            
            processing_time = time.time() - start_time
            self.update_stats(processing_time, 0.9, True)
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.update_stats(processing_time, 0.0, False)
            
            return {
                'success': False,
                'error': str(e),
                'subtasks': [],
                'execution_plan': {}
            }
    
    def can_handle_task(self, task: AgentTask) -> bool:
        return task.agent_type == AgentType.COORDINATOR
    
    async def _decompose_task(self, task: AgentTask) -> List[AgentTask]:
        """ì‘ì—… ë¶„í•´"""
        subtasks = []
        
        # ì§ˆì˜ ë¶„ì„ ì‘ì—…
        analyze_task = AgentTask(
            task_id=f"{task.task_id}_analyze",
            agent_type=AgentType.ANALYZER,
            description="ì§ˆì˜ ì˜ë„ ë¶„ì„",
            input_data=task.input_data,
            priority=1
        )
        subtasks.append(analyze_task)
        
        # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‘ì—… ì¶”ê°€
        if 'image_data' in task.input_data:
            multimodal_task = AgentTask(
                task_id=f"{task.task_id}_multimodal",
                agent_type=AgentType.SPECIALIST,
                description="ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬",
                input_data=task.input_data,
                dependencies=[analyze_task.task_id],
                priority=2
            )
            subtasks.append(multimodal_task)
        
        # ì—°êµ¬ ì‘ì—…
        research_task = AgentTask(
            task_id=f"{task.task_id}_research",
            agent_type=AgentType.RESEARCHER,
            description="ì •ë³´ ê²€ìƒ‰ ë° ì¡°ì‚¬",
            input_data=task.input_data,
            dependencies=[analyze_task.task_id],
            priority=2
        )
        subtasks.append(research_task)
        
        # ì¶”ë¡  ì‘ì—…
        reasoning_task = AgentTask(
            task_id=f"{task.task_id}_reasoning",
            agent_type=AgentType.REASONER,
            description="ë…¼ë¦¬ì  ì¶”ë¡ ",
            input_data=task.input_data,
            dependencies=[research_task.task_id],
            priority=3
        )
        subtasks.append(reasoning_task)
        
        # ì¢…í•© ì‘ì—…
        synthesis_task = AgentTask(
            task_id=f"{task.task_id}_synthesis",
            agent_type=AgentType.SYNTHESIZER,
            description="ìµœì¢… ë‹µë³€ ìƒì„±",
            input_data=task.input_data,
            dependencies=[reasoning_task.task_id],
            priority=4
        )
        subtasks.append(synthesis_task)
        
        return subtasks
    
    async def _create_execution_plan(self, subtasks: List[AgentTask]) -> Dict[str, Any]:
        """ì‹¤í–‰ ê³„íš ìƒì„±"""
        plan = {
            'total_tasks': len(subtasks),
            'estimated_time': sum(task.timeout for task in subtasks),
            'parallel_groups': [],
            'sequential_dependencies': []
        }
        
        # ì˜ì¡´ì„±ì— ë”°ë¥¸ ê·¸ë£¹í™”
        dependency_map = {}
        for task in subtasks:
            level = 0 if not task.dependencies else max(
                dependency_map.get(dep, 0) for dep in task.dependencies
            ) + 1
            dependency_map[task.task_id] = level
        
        # ë ˆë²¨ë³„ë¡œ ê·¸ë£¹í™” (ê°™ì€ ë ˆë²¨ì€ ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥)
        level_groups = {}
        for task_id, level in dependency_map.items():
            if level not in level_groups:
                level_groups[level] = []
            level_groups[level].append(task_id)
        
        plan['parallel_groups'] = list(level_groups.values())
        
        return plan


class AdvancedAISystem:
    """ì°¨ì„¸ëŒ€ AI í†µí•© ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: Optional[Dict] = None):
        """
        ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            config: ì‹œìŠ¤í…œ ì„¤ì •
        """
        self.config = config or {}
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸
        self.multimodal_pipeline = MultimodalPipeline()
        self.reasoning_engine = ReasoningEngine()
        self.memory_system = MemorySystem()
        
        # ì—ì´ì „íŠ¸ í’€
        self.agents: Dict[str, BaseAgent] = {}
        self.task_queue: List[AgentTask] = []
        self.completed_tasks: Dict[str, AgentTask] = {}
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.system_status = "initializing"
        self.active_sessions: Dict[str, Dict] = {}
        
        # ì´ˆê¸°í™”
        self._initialize_agents()
        self.system_status = "ready"
        
        logger.info("Advanced AI System initialized successfully")
    
    def _initialize_agents(self):
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        # ì¡°ì •ì ì—ì´ì „íŠ¸
        coordinator = CoordinatorAgent()
        coordinator.memory_system = self.memory_system
        coordinator.reasoning_engine = self.reasoning_engine
        self.agents[coordinator.agent_id] = coordinator
        
        logger.info(f"Initialized {len(self.agents)} agents")
    
    async def process_advanced_query(self, 
                                   query: str,
                                   image_data: Optional[Union[str, bytes]] = None,
                                   session_id: Optional[str] = None,
                                   reasoning_type: ReasoningType = ReasoningType.CHAIN_OF_THOUGHT,
                                   memory_context: bool = True) -> Dict[str, Any]:
        """
        ê³ ê¸‰ ì§ˆì˜ ì²˜ë¦¬ (ì—ì´ì „íŠ¸ + ì¶”ë¡  + ë©”ëª¨ë¦¬ í†µí•©)
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            image_data: ì´ë¯¸ì§€ ë°ì´í„° (ì„ íƒì )
            session_id: ì„¸ì…˜ ID (ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ìš©)
            reasoning_type: ì¶”ë¡  íƒ€ì…
            memory_context: ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        start_time = time.time()
        
        # ì„¸ì…˜ ê´€ë¦¬
        if not session_id:
            session_id = str(uuid.uuid4())
        
        if session_id not in self.active_sessions:
            self.active_sessions[session_id] = {
                'created_at': datetime.now(),
                'query_count': 0,
                'context_memory': []
            }
        
        session = self.active_sessions[session_id]
        session['query_count'] += 1
        
        try:
            # 1ë‹¨ê³„: ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
            context_memories = []
            if memory_context:
                context_memories = await self.memory_system.search_memory(
                    query, 
                    memory_types=[MemoryType.EPISODIC, MemoryType.SEMANTIC],
                    limit=5
                )
            
            # 2ë‹¨ê³„: ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬
            pipeline_result = await self.multimodal_pipeline.process_multimodal_query(
                query, image_data
            )
            
            # 3ë‹¨ê³„: ì¶”ë¡  ìˆ˜í–‰
            premises = [query]
            if pipeline_result.success and pipeline_result.final_answer:
                premises.append(pipeline_result.final_answer)
            
            # ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            for memory in context_memories:
                premises.append(str(memory.content))
            
            reasoning_steps = await self.reasoning_engine.reason(
                premises, reasoning_type, {'session_id': session_id}
            )
            
            # 4ë‹¨ê³„: ë©”ëª¨ë¦¬ ì €ì¥
            # ì§ˆì˜ë¥¼ ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬ì— ì €ì¥
            query_memory_id = await self.memory_system.store_memory(
                content={
                    'query': query,
                    'response': pipeline_result.final_answer,
                    'confidence': pipeline_result.confidence_score,
                    'timestamp': datetime.now().isoformat()
                },
                memory_type=MemoryType.EPISODIC,
                tags=['user_query', session_id],
                context={'session_id': session_id}
            )
            
            # ì¶”ë¡  ê²°ê³¼ë¥¼ ì‘ì—… ë©”ëª¨ë¦¬ì— ì €ì¥
            if reasoning_steps:
                await self.memory_system.store_memory(
                    content={
                        'reasoning_steps': [asdict(step) for step in reasoning_steps],
                        'reasoning_type': reasoning_type.value
                    },
                    memory_type=MemoryType.WORKING,
                    tags=['reasoning', session_id]
                )
            
            # 5ë‹¨ê³„: ìµœì¢… ì‘ë‹µ êµ¬ì„±
            final_response = await self._compose_advanced_response(
                pipeline_result, reasoning_steps, context_memories, session
            )
            
            processing_time = time.time() - start_time
            
            # ì„¸ì…˜ ì—…ë°ì´íŠ¸
            session['last_query'] = query
            session['last_response'] = final_response
            session['last_activity'] = datetime.now()
            
            result = {
                'success': True,
                'session_id': session_id,
                'query': query,
                'final_response': final_response,
                'pipeline_result': asdict(pipeline_result) if pipeline_result else None,
                'reasoning_steps': [asdict(step) for step in reasoning_steps],
                'context_memories': len(context_memories),
                'processing_time': processing_time,
                'confidence_score': pipeline_result.confidence_score if pipeline_result else 0.0,
                'memory_id': query_memory_id,
                'metadata': {
                    'reasoning_type': reasoning_type.value,
                    'memory_context_used': memory_context,
                    'session_query_count': session['query_count']
                }
            }
            
            logger.info(f"Advanced query processed successfully in {processing_time:.2f}s")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"Advanced query processing failed: {e}")
            
            return {
                'success': False,
                'session_id': session_id,
                'query': query,
                'final_response': f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                'error_message': str(e),
                'processing_time': processing_time,
                'confidence_score': 0.0
            }
    
    async def _compose_advanced_response(self, 
                                       pipeline_result: ProcessingResult,
                                       reasoning_steps: List[ReasoningStep],
                                       context_memories: List[MemoryEntry],
                                       session: Dict) -> str:
        """ê³ ê¸‰ ì‘ë‹µ êµ¬ì„±"""
        response_parts = []
        
        # ë©”ì¸ ì‘ë‹µ
        if pipeline_result and pipeline_result.success:
            response_parts.append(pipeline_result.final_answer)
        
        # ì¶”ë¡  ê³¼ì • ì¶”ê°€ (ì„ íƒì )
        if reasoning_steps and len(reasoning_steps) > 1:
            response_parts.append("\n\nğŸ§  ì¶”ë¡  ê³¼ì •:")
            for i, step in enumerate(reasoning_steps[-2:], 1):  # ë§ˆì§€ë§‰ 2ë‹¨ê³„ë§Œ
                response_parts.append(f"{i}. {step.conclusion} (ì‹ ë¢°ë„: {step.confidence:.2f})")
        
        # ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ (í•„ìš”ì‹œ)
        if context_memories and session['query_count'] > 1:
            response_parts.append(f"\n\nğŸ’­ ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í–ˆìŠµë‹ˆë‹¤.")
        
        # ì„¸ì…˜ ì •ë³´
        if session['query_count'] > 1:
            response_parts.append(f"\n\nğŸ“Š ì´ë²ˆ ì„¸ì…˜ {session['query_count']}ë²ˆì§¸ ì§ˆë¬¸")
        
        return "\n".join(response_parts)
    
    async def get_session_summary(self, session_id: str) -> Dict[str, Any]:
        """ì„¸ì…˜ ìš”ì•½"""
        if session_id not in self.active_sessions:
            return {'error': 'Session not found'}
        
        session = self.active_sessions[session_id]
        
        # ì„¸ì…˜ ê´€ë ¨ ë©”ëª¨ë¦¬ ê²€ìƒ‰
        session_memories = await self.memory_system.search_memory(
            "", 
            tags=[session_id],
            limit=10
        )
        
        return {
            'session_id': session_id,
            'created_at': session['created_at'].isoformat(),
            'query_count': session['query_count'],
            'last_activity': session.get('last_activity', session['created_at']).isoformat(),
            'memory_count': len(session_memories),
            'last_query': session.get('last_query', ''),
            'status': 'active' if datetime.now() - session.get('last_activity', session['created_at']) < timedelta(hours=1) else 'inactive'
        }
    
    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        return {
            'system_status': self.system_status,
            'active_sessions': len(self.active_sessions),
            'agents_count': len(self.agents),
            'memory_stats': self.memory_system.get_memory_stats(),
            'pipeline_stats': self.multimodal_pipeline.get_pipeline_stats(),
            'reasoning_history_count': len(self.reasoning_engine.reasoning_history),
            'capabilities': [
                'multimodal_processing',
                'advanced_reasoning',
                'memory_management',
                'agent_coordination',
                'session_management'
            ]
        }


# í¸ì˜ í•¨ìˆ˜ë“¤
def create_advanced_ai_system(config: Optional[Dict] = None) -> AdvancedAISystem:
    """ê³ ê¸‰ AI ì‹œìŠ¤í…œ ìƒì„±"""
    return AdvancedAISystem(config)

async def process_with_ai_system(query: str, 
                                image_data: Optional[Union[str, bytes]] = None,
                                reasoning_type: ReasoningType = ReasoningType.CHAIN_OF_THOUGHT) -> Dict[str, Any]:
    """AI ì‹œìŠ¤í…œìœ¼ë¡œ ì¿¼ë¦¬ ì²˜ë¦¬"""
    system = create_advanced_ai_system()
    return await system.process_advanced_query(query, image_data, reasoning_type=reasoning_type)


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_advanced_system():
    """ê³ ê¸‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    system = create_advanced_ai_system()
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ì „ì••ê³¼ ì „ë¥˜ì˜ ê´€ê³„ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ì˜´ì˜ ë²•ì¹™ì„ ì´ìš©í•´ì„œ ì €í•­ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì€?",
        "ì•ì˜ ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ íšŒë¡œì—ì„œì˜ ì‘ìš© ì˜ˆì‹œëŠ”?"
    ]
    
    session_id = None
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n=== í…ŒìŠ¤íŠ¸ {i}: {query} ===")
        
        result = await system.process_advanced_query(
            query, 
            session_id=session_id,
            reasoning_type=ReasoningType.CHAIN_OF_THOUGHT,
            memory_context=True
        )
        
        if not session_id:
            session_id = result['session_id']
        
        print(f"ì‘ë‹µ: {result['final_response']}")
        print(f"ì‹ ë¢°ë„: {result['confidence_score']:.2f}")
        print(f"ì²˜ë¦¬ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
    
    # ì„¸ì…˜ ìš”ì•½
    summary = await system.get_session_summary(session_id)
    print(f"\n=== ì„¸ì…˜ ìš”ì•½ ===")
    print(f"ì´ ì§ˆë¬¸ ìˆ˜: {summary['query_count']}")
    print(f"ë©”ëª¨ë¦¬ í•­ëª© ìˆ˜: {summary['memory_count']}")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ
    status = system.get_system_status()
    print(f"\n=== ì‹œìŠ¤í…œ ìƒíƒœ ===")
    print(f"ìƒíƒœ: {status['system_status']}")
    print(f"ì§€ì› ê¸°ëŠ¥: {', '.join(status['capabilities'])}")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(test_advanced_system())