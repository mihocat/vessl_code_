#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì°¨ì„¸ëŒ€ AI ì„œë¹„ìŠ¤
ìµœì‹  AI íŠ¸ë Œë“œ í†µí•©: ì—ì´ì „íŠ¸, ì¶”ë¡  ì²´ì¸, ë©”ëª¨ë¦¬, ë„êµ¬ ì‚¬ìš©
"""

import logging
import time
import json
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import asyncio
from collections import deque

from intelligent_multimodal_system import IntelligentMultimodalSystem, ProcessingResult
from query_intent_analyzer import QueryIntentAnalyzer, IntentAnalysisResult, QueryType, ComplexityLevel
from enhanced_rag_system import EnhancedRAGSystem, SearchStrategy

logger = logging.getLogger(__name__)


class ConversationMode(Enum):
    """ëŒ€í™” ëª¨ë“œ"""
    STANDARD = "standard"        # ì¼ë°˜ ëª¨ë“œ
    EXPERT = "expert"           # ì „ë¬¸ê°€ ëª¨ë“œ (ìƒì„¸í•œ ê¸°ìˆ  ì •ë³´)
    TUTORIAL = "tutorial"       # íŠœí† ë¦¬ì–¼ ëª¨ë“œ (í•™ìŠµ ì§€ì›)
    RESEARCH = "research"       # ì—°êµ¬ ëª¨ë“œ (ì‹¬ì¸µ ë¶„ì„)
    COLLABORATIVE = "collaborative"  # í˜‘ì—… ëª¨ë“œ (ë‹¤ë‹¨ê³„ ìƒí˜¸ì‘ìš©)


class ResponseStyle(Enum):
    """ì‘ë‹µ ìŠ¤íƒ€ì¼"""
    CONCISE = "concise"         # ê°„ê²°í•œ ë‹µë³€
    DETAILED = "detailed"       # ìƒì„¸í•œ ë‹µë³€
    STEP_BY_STEP = "step_by_step"  # ë‹¨ê³„ë³„ ì„¤ëª…
    VISUAL = "visual"           # ì‹œê°ì  ìš”ì†Œ í¬í•¨
    INTERACTIVE = "interactive"  # ìƒí˜¸ì‘ìš©ì  ë‹µë³€


@dataclass
class UserContext:
    """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸"""
    user_id: str
    session_id: str
    conversation_mode: ConversationMode
    response_style: ResponseStyle
    expertise_level: int  # 1-5 (ì´ˆë³´ì-ì „ë¬¸ê°€)
    
    # ê°œì¸í™” ì •ë³´
    preferred_language: str
    domain_interests: List[str]
    learning_goals: List[str]
    
    # ëŒ€í™” ê¸°ë¡
    conversation_history: List[Dict[str, Any]]
    interaction_count: int
    success_rate: float


@dataclass
class ConversationMemory:
    """ëŒ€í™” ë©”ëª¨ë¦¬"""
    short_term: deque  # ìµœê·¼ 5-10ê°œ ëŒ€í™”
    semantic_memory: Dict[str, Any]  # ì£¼ì œë³„ ê¸°ì–µ
    episodic_memory: List[Dict[str, Any]]  # íŠ¹ì • ìƒí™© ê¸°ì–µ
    procedural_memory: Dict[str, List[str]]  # ì ˆì°¨ì  ì§€ì‹
    
    # ë©”íƒ€ ì •ë³´
    memory_strength: Dict[str, float]  # ê¸°ì–µ ê°•ë„
    access_frequency: Dict[str, int]   # ì ‘ê·¼ ë¹ˆë„
    last_updated: Dict[str, float]     # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸


class ChainOfThoughtReasoner:
    """ì¶”ë¡  ì²´ì¸ ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.reasoning_templates = self._load_reasoning_templates()
    
    def _load_reasoning_templates(self):
        """ì¶”ë¡  í…œí”Œë¦¿ ë¡œë“œ"""
        return {
            'problem_solving': [
                "1. ë¬¸ì œ ì´í•´ ë° ì •ì˜",
                "2. ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘",
                "3. í•´ê²° ë°©ë²• íƒìƒ‰",
                "4. ë‹¨ê³„ë³„ í•´ê²° ê³¼ì •",
                "5. ê²°ê³¼ ê²€ì¦ ë° í•´ì„"
            ],
            'analysis': [
                "1. ì£¼ìš” ìš”ì†Œ ì‹ë³„",
                "2. ê´€ê³„ì„± ë¶„ì„",
                "3. íŒ¨í„´ ë° íŠ¹ì§• íŒŒì•…",
                "4. ì›ì¸ê³¼ ê²°ê³¼ ê´€ê³„",
                "5. ê²°ë¡  ë° ì‹œì‚¬ì "
            ],
            'comparison': [
                "1. ë¹„êµ ëŒ€ìƒ ì •ì˜",
                "2. ë¹„êµ ê¸°ì¤€ ì„¤ì •",
                "3. ê° ìš”ì†Œë³„ ë¶„ì„",
                "4. ìœ ì‚¬ì ê³¼ ì°¨ì´ì ",
                "5. ì¢…í•©ì  í‰ê°€"
            ],
            'explanation': [
                "1. í•µì‹¬ ê°œë… ì •ì˜",
                "2. ê¸°ë³¸ ì›ë¦¬ ì„¤ëª…",
                "3. êµ¬ì²´ì  ì˜ˆì‹œ ì œì‹œ",
                "4. ì‘ìš© ë° í™•ì¥",
                "5. ìš”ì•½ ë° ì •ë¦¬"
            ]
        }
    
    def reason(self, query: str, context: Dict[str, Any], reasoning_type: str = 'problem_solving') -> List[str]:
        """ì¶”ë¡  ì²´ì¸ ìƒì„±"""
        template = self.reasoning_templates.get(reasoning_type, self.reasoning_templates['problem_solving'])
        
        # ì¿¼ë¦¬ì™€ ì»¨í…ìŠ¤íŠ¸ì— ë§ì¶° ì¶”ë¡  ë‹¨ê³„ êµ¬ì²´í™”
        reasoning_steps = []
        
        for step in template:
            # ê° ë‹¨ê³„ë¥¼ ì¿¼ë¦¬ì— ë§ê²Œ êµ¬ì²´í™”
            specific_step = self._contextualize_step(step, query, context)
            reasoning_steps.append(specific_step)
        
        return reasoning_steps
    
    def _contextualize_step(self, step: str, query: str, context: Dict[str, Any]) -> str:
        """ì¶”ë¡  ë‹¨ê³„ë¥¼ ì¿¼ë¦¬ì— ë§ê²Œ êµ¬ì²´í™”"""
        # ê°„ë‹¨í•œ êµ¬í˜„: ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ LLM ê¸°ë°˜ ì²˜ë¦¬
        if "ë¬¸ì œ ì´í•´" in step:
            return f"ë¬¸ì œ ì´í•´: '{query}' ë¶„ì„"
        elif "ì •ë³´ ìˆ˜ì§‘" in step:
            return f"ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘: {query}ì™€ ê´€ë ¨ëœ ë°ì´í„° ë° ì§€ì‹"
        elif "í•´ê²° ë°©ë²•" in step:
            return f"í•´ê²° ë°©ë²• íƒìƒ‰: {query}ì— ëŒ€í•œ ì ‘ê·¼ ë°©ì‹"
        else:
            return step


class ToolAgent:
    """ë„êµ¬ ì‚¬ìš© ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.available_tools = self._load_available_tools()
    
    def _load_available_tools(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ë¡œë“œ"""
        return {
            'calculator': {
                'description': 'ìˆ˜í•™ ê³„ì‚° ìˆ˜í–‰',
                'usage': 'mathematical expressions, equations',
                'examples': ['2+2', 'sqrt(16)', 'sin(30)', 'solve x^2 + 2x - 3 = 0']
            },
            'unit_converter': {
                'description': 'ë‹¨ìœ„ ë³€í™˜',
                'usage': 'unit conversions',
                'examples': ['convert 100 km to miles', '50 celsius to fahrenheit']
            },
            'formula_solver': {
                'description': 'ê³µì‹ ë° ë°©ì •ì‹ í•´ê²°',
                'usage': 'formula evaluation, equation solving',
                'examples': ['ohms law V=IR', 'quadratic formula']
            },
            'web_search': {
                'description': 'ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰',
                'usage': 'current information, recent data',
                'examples': ['latest research on AI', 'current exchange rates']
            },
            'code_executor': {
                'description': 'ì½”ë“œ ì‹¤í–‰',
                'usage': 'programming calculations, simulations',
                'examples': ['python script', 'data analysis']
            }
        }
    
    def select_tools(self, query: str, intent: IntentAnalysisResult) -> List[str]:
        """ì¿¼ë¦¬ì— ì í•©í•œ ë„êµ¬ ì„ íƒ"""
        selected_tools = []
        
        # ìˆ˜í•™ì  ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš°
        if intent.requires_calculation or any(op in query for op in ['+', '-', '*', '/', '=', 'ê³„ì‚°', 'calculate']):
            selected_tools.append('calculator')
            selected_tools.append('formula_solver')
        
        # ë‹¨ìœ„ ë³€í™˜ì´ í•„ìš”í•œ ê²½ìš°
        if any(unit in query.lower() for unit in ['km', 'mile', 'celsius', 'fahrenheit', 'volt', 'ampere']):
            selected_tools.append('unit_converter')
        
        # ìµœì‹  ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°
        if any(term in query.lower() for term in ['ìµœì‹ ', 'í˜„ì¬', 'ìš”ì¦˜', 'latest', 'current', 'recent']):
            selected_tools.append('web_search')
        
        # í”„ë¡œê·¸ë˜ë° ê´€ë ¨ ì§ˆì˜
        if any(term in query.lower() for term in ['ì½”ë“œ', 'code', 'í”„ë¡œê·¸ë˜ë°', 'programming', 'python']):
            selected_tools.append('code_executor')
        
        return selected_tools
    
    async def use_tool(self, tool_name: str, query: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """ë„êµ¬ ì‚¬ìš©"""
        if tool_name not in self.available_tools:
            return {'success': False, 'error': f'Tool {tool_name} not available'}
        
        try:
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ê° ë„êµ¬ë³„ API í˜¸ì¶œ
            # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜
            if tool_name == 'calculator':
                return await self._use_calculator(query, parameters)
            elif tool_name == 'unit_converter':
                return await self._use_unit_converter(query, parameters)
            elif tool_name == 'formula_solver':
                return await self._use_formula_solver(query, parameters)
            elif tool_name == 'web_search':
                return await self._use_web_search(query, parameters)
            elif tool_name == 'code_executor':
                return await self._use_code_executor(query, parameters)
            else:
                return {'success': False, 'error': 'Tool implementation not found'}
                
        except Exception as e:
            logger.error(f"Tool {tool_name} execution failed: {e}")
            return {'success': False, 'error': str(e)}
    
    async def _use_calculator(self, query: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """ê³„ì‚°ê¸° ì‚¬ìš©"""
        # ê°„ë‹¨í•œ ê³„ì‚° êµ¬í˜„
        import re
        
        # ìˆ˜ì‹ ì¶”ì¶œ
        math_expressions = re.findall(r'[\d+\-*/().\s]+', query)
        results = []
        
        for expr in math_expressions:
            try:
                # ì•ˆì „í•œ ê³„ì‚°ì„ ìœ„í•œ eval ëŒ€ì•ˆ ì‚¬ìš© (ì‹¤ì œë¡œëŠ” ast.literal_eval ë“± ì‚¬ìš©)
                if len(expr.strip()) > 3 and all(c in '0123456789+-*/.() ' for c in expr):
                    result = eval(expr.strip())
                    results.append(f"{expr.strip()} = {result}")
            except:
                continue
        
        return {
            'success': True,
            'results': results,
            'tool': 'calculator'
        }
    
    async def _use_unit_converter(self, query: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ìœ„ ë³€í™˜ê¸° ì‚¬ìš©"""
        # ê°„ë‹¨í•œ ë‹¨ìœ„ ë³€í™˜ êµ¬í˜„
        conversions = {
            'km_to_mile': lambda x: x * 0.621371,
            'mile_to_km': lambda x: x * 1.60934,
            'celsius_to_fahrenheit': lambda x: (x * 9/5) + 32,
            'fahrenheit_to_celsius': lambda x: (x - 32) * 5/9
        }
        
        results = []
        if 'km' in query and 'mile' in query:
            # ìˆ«ì ì¶”ì¶œ ë° ë³€í™˜ (ê°„ë‹¨í•œ êµ¬í˜„)
            import re
            numbers = re.findall(r'\d+', query)
            if numbers:
                km = float(numbers[0])
                miles = conversions['km_to_mile'](km)
                results.append(f"{km} km = {miles:.2f} miles")
        
        return {
            'success': True,
            'results': results,
            'tool': 'unit_converter'
        }
    
    async def _use_formula_solver(self, query: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """ê³µì‹ í•´ê²°ê¸° ì‚¬ìš©"""
        # ê¸°ë³¸ì ì¸ ê³¼í•™ ê³µì‹ë“¤
        formulas = {
            'ohms_law': {
                'V=IR': lambda I, R: I * R,
                'I=V/R': lambda V, R: V / R,
                'R=V/I': lambda V, I: V / I
            },
            'power': {
                'P=VI': lambda V, I: V * I,
                'P=VÂ²/R': lambda V, R: (V ** 2) / R,
                'P=IÂ²R': lambda I, R: (I ** 2) * R
            }
        }
        
        results = []
        if any(term in query.lower() for term in ['ì˜´ì˜ë²•ì¹™', 'ohm', 'V=IR', 'I=V/R']):
            results.append("ì˜´ì˜ ë²•ì¹™: V = I Ã— R (ì „ì•• = ì „ë¥˜ Ã— ì €í•­)")
            results.append("ë³€í˜•: I = V / R, R = V / I")
        
        return {
            'success': True,
            'results': results,
            'tool': 'formula_solver'
        }
    
    async def _use_web_search(self, query: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """ì›¹ ê²€ìƒ‰ ì‚¬ìš©"""
        # ì‹¤ì œë¡œëŠ” ì›¹ ê²€ìƒ‰ API í˜¸ì¶œ
        return {
            'success': True,
            'results': [f"ì›¹ ê²€ìƒ‰ ê²°ê³¼: '{query}'ì— ëŒ€í•œ ìµœì‹  ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."],
            'tool': 'web_search'
        }
    
    async def _use_code_executor(self, query: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """ì½”ë“œ ì‹¤í–‰ê¸° ì‚¬ìš©"""
        # ì‹¤ì œë¡œëŠ” ì•ˆì „í•œ ì½”ë“œ ì‹¤í–‰ í™˜ê²½
        return {
            'success': True,
            'results': [f"ì½”ë“œ ì‹¤í–‰ ê²°ê³¼: '{query}' ì²˜ë¦¬ ì™„ë£Œ"],
            'tool': 'code_executor'
        }


class AdaptiveResponseGenerator:
    """ì ì‘í˜• ì‘ë‹µ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.response_templates = self._load_response_templates()
    
    def _load_response_templates(self):
        """ì‘ë‹µ í…œí”Œë¦¿ ë¡œë“œ"""
        return {
            ConversationMode.STANDARD: {
                ResponseStyle.CONCISE: "ê°„ê²°í•˜ê³  ëª…í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.",
                ResponseStyle.DETAILED: "ìƒì„¸í•œ ì„¤ëª…ê³¼ í•¨ê»˜ í¬ê´„ì ì¸ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.",
                ResponseStyle.STEP_BY_STEP: "ë‹¨ê³„ë³„ë¡œ ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            },
            ConversationMode.EXPERT: {
                ResponseStyle.CONCISE: "ì „ë¬¸ì ì¸ ê´€ì ì—ì„œ í•µì‹¬ ë‚´ìš©ì„ ì œì‹œí•©ë‹ˆë‹¤.",
                ResponseStyle.DETAILED: "ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ê³¼ ì´ë¡ ì  ë°°ê²½ì„ í¬í•¨í•˜ì—¬ ì„¤ëª…í•©ë‹ˆë‹¤.",
                ResponseStyle.STEP_BY_STEP: "ê° ë‹¨ê³„ì˜ ì´ë¡ ì  ê·¼ê±°ì™€ í•¨ê»˜ ìƒì„¸íˆ ë¶„ì„í•©ë‹ˆë‹¤."
            },
            ConversationMode.TUTORIAL: {
                ResponseStyle.CONCISE: "í•™ìŠµì— í•„ìš”í•œ í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.",
                ResponseStyle.DETAILED: "ê°œë… ì„¤ëª…, ì˜ˆì‹œ, ì—°ìŠµ ë¬¸ì œë¥¼ í¬í•¨í•œ í•™ìŠµ ìë£Œë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
                ResponseStyle.STEP_BY_STEP: "ë‹¨ê³„ë³„ í•™ìŠµ ê³¼ì •ê³¼ ì´í•´ë„ í™•ì¸ì„ í¬í•¨í•©ë‹ˆë‹¤."
            }
        }
    
    def generate_response(self, processing_result: ProcessingResult, user_context: UserContext,
                         reasoning_steps: List[str] = None, tool_results: List[Dict] = None) -> str:
        """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ì— ë§ëŠ” ì‘ë‹µ ìƒì„±"""
        
        # ê¸°ë³¸ ì‘ë‹µ
        base_response = processing_result.response
        
        # ì‚¬ìš©ì ë ˆë²¨ì— ë§ëŠ” ì¡°ì •
        adjusted_response = self._adjust_for_expertise_level(
            base_response, user_context.expertise_level
        )
        
        # ëŒ€í™” ëª¨ë“œì— ë§ëŠ” ìŠ¤íƒ€ì¼ ì ìš©
        styled_response = self._apply_conversation_style(
            adjusted_response, user_context.conversation_mode, user_context.response_style
        )
        
        # ì¶”ë¡  ê³¼ì • ì¶”ê°€ (í•„ìš”í•œ ê²½ìš°)
        if reasoning_steps and user_context.conversation_mode in [ConversationMode.EXPERT, ConversationMode.TUTORIAL]:
            styled_response = self._add_reasoning_explanation(styled_response, reasoning_steps)
        
        # ë„êµ¬ ì‚¬ìš© ê²°ê³¼ í†µí•©
        if tool_results:
            styled_response = self._integrate_tool_results(styled_response, tool_results)
        
        # ê°œì¸í™” ìš”ì†Œ ì¶”ê°€
        personalized_response = self._add_personalization(styled_response, user_context)
        
        return personalized_response
    
    def _adjust_for_expertise_level(self, response: str, level: int) -> str:
        """ì „ë¬¸ì„± ìˆ˜ì¤€ì— ë§ê²Œ ì‘ë‹µ ì¡°ì •"""
        if level <= 2:  # ì´ˆë³´ì
            return f"ğŸ”° ì´ˆë³´ìë¥¼ ìœ„í•œ ì„¤ëª…:\n{response}\n\nğŸ’¡ ì¶”ê°€ í•™ìŠµ íŒ: ê´€ë ¨ ê¸°ì´ˆ ê°œë…ì„ ë” ê³µë¶€í•´ë³´ì„¸ìš”."
        elif level >= 4:  # ì „ë¬¸ê°€
            return f"ğŸ“ ì „ë¬¸ê°€ ìˆ˜ì¤€ ë¶„ì„:\n{response}\n\nğŸ”¬ ì‹¬í™” ê³ ë ¤ì‚¬í•­: ìµœì‹  ì—°êµ¬ ë™í–¥ê³¼ ê³ ê¸‰ ì‘ìš© ë°©ì•ˆì„ ê²€í† í•´ë³´ì„¸ìš”."
        else:  # ì¤‘ê¸‰ì
            return response
    
    def _apply_conversation_style(self, response: str, mode: ConversationMode, style: ResponseStyle) -> str:
        """ëŒ€í™” ìŠ¤íƒ€ì¼ ì ìš©"""
        style_prefix = ""
        style_suffix = ""
        
        if mode == ConversationMode.TUTORIAL:
            style_prefix = "ğŸ“š í•™ìŠµ ê°€ì´ë“œ:\n"
            style_suffix = "\n\nâœ… ì´í•´ë„ í™•ì¸: í•µì‹¬ ê°œë…ì„ ìì‹ ì˜ ë§ë¡œ ì„¤ëª…í•´ë³´ì„¸ìš”."
        elif mode == ConversationMode.RESEARCH:
            style_prefix = "ğŸ”¬ ì—°êµ¬ ë¶„ì„:\n"
            style_suffix = "\n\nğŸ“Š ì¶”ê°€ ì—°êµ¬ ë°©í–¥: ê´€ë ¨ ë…¼ë¬¸ì´ë‚˜ ìµœì‹  ì—°êµ¬ë¥¼ ì°¸ê³ í•´ë³´ì„¸ìš”."
        elif mode == ConversationMode.COLLABORATIVE:
            style_prefix = "ğŸ¤ í˜‘ì—… ëª¨ë“œ:\n"
            style_suffix = "\n\nğŸ’¬ í”¼ë“œë°± ìš”ì²­: ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ë‹¤ë¥¸ ê´€ì ì´ ìˆìœ¼ì‹ ê°€ìš”?"
        
        if style == ResponseStyle.STEP_BY_STEP:
            # ë‹¨ê³„ë³„ í˜•ì‹ìœ¼ë¡œ ì¬êµ¬ì„±
            lines = response.split('\n')
            numbered_lines = []
            step = 1
            for line in lines:
                if line.strip():
                    numbered_lines.append(f"{step}. {line}")
                    step += 1
                else:
                    numbered_lines.append(line)
            response = '\n'.join(numbered_lines)
        
        return f"{style_prefix}{response}{style_suffix}"
    
    def _add_reasoning_explanation(self, response: str, reasoning_steps: List[str]) -> str:
        """ì¶”ë¡  ê³¼ì • ì„¤ëª… ì¶”ê°€"""
        reasoning_text = "\n\nğŸ§  ì‚¬ê³  ê³¼ì •:\n"
        for i, step in enumerate(reasoning_steps, 1):
            reasoning_text += f"{i}. {step}\n"
        
        return f"{response}{reasoning_text}"
    
    def _integrate_tool_results(self, response: str, tool_results: List[Dict]) -> str:
        """ë„êµ¬ ì‚¬ìš© ê²°ê³¼ í†µí•©"""
        if not tool_results:
            return response
        
        tools_text = "\n\nğŸ› ï¸ ë„êµ¬ ì‚¬ìš© ê²°ê³¼:\n"
        for result in tool_results:
            if result.get('success'):
                tool_name = result.get('tool', 'Unknown')
                results = result.get('results', [])
                tools_text += f"ğŸ“‹ {tool_name}: {', '.join(results)}\n"
        
        return f"{response}{tools_text}"
    
    def _add_personalization(self, response: str, user_context: UserContext) -> str:
        """ê°œì¸í™” ìš”ì†Œ ì¶”ê°€"""
        # ì‚¬ìš©ì ê´€ì‹¬ ë„ë©”ì¸ ë°˜ì˜
        if user_context.domain_interests:
            domain = user_context.domain_interests[0]
            response += f"\n\nğŸ¯ {domain} ê´€ë ¨ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë¬¸ì˜í•´ì£¼ì„¸ìš”."
        
        # ì„±ê³µë¥ ì— ë”°ë¥¸ ê²©ë ¤ ë©”ì‹œì§€
        if user_context.success_rate < 0.7:
            response += f"\n\nğŸ’ª ì§ˆë¬¸ì´ ë” ìˆìœ¼ì‹œë©´ ìì„¸íˆ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤!"
        
        return response


class NextGenAIService:
    """ì°¨ì„¸ëŒ€ AI ì„œë¹„ìŠ¤"""
    
    def __init__(self, config):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.config = config
        
        # í•µì‹¬ ì‹œìŠ¤í…œë“¤
        self.multimodal_system = IntelligentMultimodalSystem(config)
        self.intent_analyzer = QueryIntentAnalyzer()
        self.enhanced_rag = EnhancedRAGSystem(config)
        
        # AI íŠ¸ë Œë“œ ì»´í¬ë„ŒíŠ¸ë“¤
        self.reasoning_engine = ChainOfThoughtReasoner()
        self.tool_agent = ToolAgent()
        self.response_generator = AdaptiveResponseGenerator()
        
        # ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
        self.conversation_memories = {}  # user_id -> ConversationMemory
        
        # ì„œë¹„ìŠ¤ í†µê³„
        self.service_stats = {
            'total_conversations': 0,
            'successful_interactions': 0,
            'average_satisfaction': 0.0,
            'tool_usage_count': 0,
            'memory_efficiency': 0.0
        }
        
        logger.info("Next-Generation AI Service initialized")
    
    async def process_conversation(self, query: str, image_path: str = None, 
                                 user_context: UserContext = None) -> Dict[str, Any]:
        """
        ì°¨ì„¸ëŒ€ ëŒ€í™” ì²˜ë¦¬
        
        Args:
            query: ì‚¬ìš©ì ì§ˆì˜
            image_path: ì´ë¯¸ì§€ ê²½ë¡œ (ì„ íƒì )
            user_context: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            self.service_stats['total_conversations'] += 1
            
            # ê¸°ë³¸ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            if not user_context:
                user_context = self._create_default_user_context()
            
            # ëŒ€í™” ë©”ëª¨ë¦¬ ë¡œë“œ
            memory = self._get_or_create_memory(user_context.user_id)
            
            # 1ë‹¨ê³„: ì˜ë„ ë¶„ì„
            intent_result = self.intent_analyzer.analyze_intent(query, has_image=bool(image_path))
            
            # 2ë‹¨ê³„: ë©”ëª¨ë¦¬ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ í™•ì¥
            enhanced_query = self._enhance_query_with_memory(query, memory, intent_result)
            
            # 3ë‹¨ê³„: ì¶”ë¡  ì²´ì¸ ìƒì„± (ë³µì¡í•œ ë¬¸ì œì˜ ê²½ìš°)
            reasoning_steps = None
            if intent_result.complexity.value >= 3:
                reasoning_type = self._determine_reasoning_type(intent_result)
                reasoning_steps = self.reasoning_engine.reason(
                    enhanced_query, 
                    {'intent': intent_result, 'memory': memory}, 
                    reasoning_type
                )
            
            # 4ë‹¨ê³„: ë„êµ¬ ì„ íƒ ë° ì‚¬ìš©
            tool_results = []
            if intent_result.requires_calculation or intent_result.complexity.value >= 4:
                selected_tools = self.tool_agent.select_tools(enhanced_query, intent_result)
                tool_results = await self._use_tools_parallel(selected_tools, enhanced_query)
            
            # 5ë‹¨ê³„: ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬
            processing_result = self.multimodal_system.process_query(
                enhanced_query, 
                image_path, 
                user_context=asdict(user_context)
            )
            
            # 6ë‹¨ê³„: ì ì‘í˜• ì‘ë‹µ ìƒì„±
            final_response = self.response_generator.generate_response(
                processing_result, 
                user_context,
                reasoning_steps,
                tool_results
            )
            
            # 7ë‹¨ê³„: ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
            self._update_memory(memory, query, final_response, processing_result, user_context)
            
            # 8ë‹¨ê³„: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            updated_context = self._update_user_context(user_context, processing_result, intent_result)
            
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ êµ¬ì„±
            result = {
                'response': final_response,
                'processing_time': processing_time,
                'confidence': processing_result.confidence,
                'intent_analysis': asdict(intent_result),
                'reasoning_steps': reasoning_steps,
                'tools_used': [r.get('tool') for r in tool_results if r.get('success')],
                'memory_updated': True,
                'user_context': asdict(updated_context),
                'service_metadata': {
                    'response_quality': processing_result.response_quality_score,
                    'user_satisfaction_prediction': processing_result.user_satisfaction_prediction,
                    'tokens_used': processing_result.tokens_used,
                    'cost_estimate': processing_result.cost_estimate
                }
            }
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_service_stats(result)
            
            logger.info(f"Next-gen conversation completed in {processing_time:.2f}s "
                       f"(confidence: {processing_result.confidence:.2f})")
            
            return result
            
        except Exception as e:
            logger.error(f"Next-gen conversation processing failed: {e}")
            return self._generate_error_response(str(e), time.time() - start_time)
    
    def _create_default_user_context(self) -> UserContext:
        """ê¸°ë³¸ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        return UserContext(
            user_id="anonymous",
            session_id=f"session_{int(time.time())}",
            conversation_mode=ConversationMode.STANDARD,
            response_style=ResponseStyle.DETAILED,
            expertise_level=3,
            preferred_language="korean",
            domain_interests=["general"],
            learning_goals=[],
            conversation_history=[],
            interaction_count=0,
            success_rate=0.8
        )
    
    def _get_or_create_memory(self, user_id: str) -> ConversationMemory:
        """ëŒ€í™” ë©”ëª¨ë¦¬ íšë“ ë˜ëŠ” ìƒì„±"""
        if user_id not in self.conversation_memories:
            self.conversation_memories[user_id] = ConversationMemory(
                short_term=deque(maxlen=10),
                semantic_memory={},
                episodic_memory=[],
                procedural_memory={},
                memory_strength={},
                access_frequency={},
                last_updated={}
            )
        
        return self.conversation_memories[user_id]
    
    def _enhance_query_with_memory(self, query: str, memory: ConversationMemory, 
                                  intent: IntentAnalysisResult) -> str:
        """ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•œ ì¿¼ë¦¬ í–¥ìƒ"""
        enhanced_parts = [query]
        
        # ìµœê·¼ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if memory.short_term:
            recent_topics = []
            for conversation in list(memory.short_term)[-3:]:  # ìµœê·¼ 3ê°œ
                if conversation.get('topic'):
                    recent_topics.append(conversation['topic'])
            
            if recent_topics:
                enhanced_parts.append(f"ìµœê·¼ ëŒ€í™” ì£¼ì œ: {', '.join(recent_topics)}")
        
        # ì˜ë¯¸ì  ë©”ëª¨ë¦¬ì—ì„œ ê´€ë ¨ ì •ë³´ ì¶”ê°€
        for topic, info in memory.semantic_memory.items():
            if any(keyword in query.lower() for keyword in topic.split()):
                enhanced_parts.append(f"ê´€ë ¨ ê¸°ì–µ: {info}")
                break
        
        return " | ".join(enhanced_parts)
    
    def _determine_reasoning_type(self, intent: IntentAnalysisResult) -> str:
        """ì¶”ë¡  ìœ í˜• ê²°ì •"""
        if intent.query_type == QueryType.PROBLEM_SOLVING:
            return 'problem_solving'
        elif intent.query_type == QueryType.COMPARISON:
            return 'comparison'
        elif intent.query_type == QueryType.EXPLANATION:
            return 'explanation'
        else:
            return 'analysis'
    
    async def _use_tools_parallel(self, selected_tools: List[str], query: str) -> List[Dict[str, Any]]:
        """ë„êµ¬ë“¤ì„ ë³‘ë ¬ë¡œ ì‚¬ìš©"""
        if not selected_tools:
            return []
        
        # ë³‘ë ¬ ë„êµ¬ ì‹¤í–‰
        tasks = []
        for tool in selected_tools[:3]:  # ìµœëŒ€ 3ê°œ ë„êµ¬
            task = self.tool_agent.use_tool(tool, query, {})
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ì„±ê³µí•œ ê²°ê³¼ë§Œ ë°˜í™˜
        successful_results = []
        for result in results:
            if isinstance(result, dict) and result.get('success'):
                successful_results.append(result)
                self.service_stats['tool_usage_count'] += 1
        
        return successful_results
    
    def _update_memory(self, memory: ConversationMemory, query: str, response: str,
                      processing_result: ProcessingResult, user_context: UserContext):
        """ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸"""
        current_time = time.time()
        
        # ë‹¨ê¸° ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
        conversation_entry = {
            'timestamp': current_time,
            'query': query,
            'response': response,
            'topic': self._extract_topic(query),
            'confidence': processing_result.confidence,
            'user_satisfaction': processing_result.user_satisfaction_prediction
        }
        memory.short_term.append(conversation_entry)
        
        # ì˜ë¯¸ì  ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
        topic = self._extract_topic(query)
        if topic:
            if topic in memory.semantic_memory:
                # ê¸°ì¡´ ì •ë³´ ê°•í™”
                memory.memory_strength[topic] = memory.memory_strength.get(topic, 0.5) + 0.1
            else:
                # ìƒˆ ì£¼ì œ ì¶”ê°€
                memory.semantic_memory[topic] = response[:200]  # ì²˜ìŒ 200ìë§Œ ì €ì¥
                memory.memory_strength[topic] = 0.7
            
            memory.access_frequency[topic] = memory.access_frequency.get(topic, 0) + 1
            memory.last_updated[topic] = current_time
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬ (ë„ˆë¬´ ë§ì•„ì§€ë©´)
        if len(memory.semantic_memory) > 50:
            self._cleanup_memory(memory)
    
    def _extract_topic(self, query: str) -> Optional[str]:
        """ì¿¼ë¦¬ì—ì„œ ì£¼ì œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì£¼ì œ ì¶”ì¶œ
        keywords = query.split()[:3]  # ì²˜ìŒ 3ê°œ ë‹¨ì–´
        return ' '.join(keywords) if keywords else None
    
    def _cleanup_memory(self, memory: ConversationMemory):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        current_time = time.time()
        
        # 1ì£¼ì¼ ì´ìƒ ì ‘ê·¼í•˜ì§€ ì•Šì€ ì•½í•œ ê¸°ì–µ ì œê±°
        topics_to_remove = []
        for topic, last_update in memory.last_updated.items():
            if (current_time - last_update > 604800 and  # 1ì£¼ì¼
                memory.memory_strength.get(topic, 0) < 0.3):
                topics_to_remove.append(topic)
        
        for topic in topics_to_remove:
            memory.semantic_memory.pop(topic, None)
            memory.memory_strength.pop(topic, None)
            memory.access_frequency.pop(topic, None)
            memory.last_updated.pop(topic, None)
    
    def _update_user_context(self, user_context: UserContext, 
                           processing_result: ProcessingResult,
                           intent_result: IntentAnalysisResult) -> UserContext:
        """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        # ìƒí˜¸ì‘ìš© ì¹´ìš´íŠ¸ ì¦ê°€
        user_context.interaction_count += 1
        
        # ì„±ê³µë¥  ì—…ë°ì´íŠ¸
        current_success = 1.0 if processing_result.confidence > 0.7 else 0.5
        user_context.success_rate = (
            (user_context.success_rate * (user_context.interaction_count - 1) + current_success) 
            / user_context.interaction_count
        )
        
        # ì „ë¬¸ì„± ìˆ˜ì¤€ ì¡°ì • (ë³µì¡í•œ ì§ˆë¬¸ì„ ê³„ì†í•˜ë©´ ë ˆë²¨ ìƒìŠ¹)
        if intent_result.complexity.value >= 4 and user_context.expertise_level < 5:
            user_context.expertise_level = min(5, user_context.expertise_level + 0.1)
        
        # ë„ë©”ì¸ ê´€ì‹¬ì‚¬ ì—…ë°ì´íŠ¸
        if intent_result.domain and intent_result.domain not in user_context.domain_interests:
            user_context.domain_interests.append(intent_result.domain)
            user_context.domain_interests = user_context.domain_interests[-5:]  # ìµœëŒ€ 5ê°œ
        
        return user_context
    
    def _update_service_stats(self, result: Dict[str, Any]):
        """ì„œë¹„ìŠ¤ í†µê³„ ì—…ë°ì´íŠ¸"""
        if result.get('confidence', 0) > 0.7:
            self.service_stats['successful_interactions'] += 1
        
        # í‰ê·  ë§Œì¡±ë„ ì—…ë°ì´íŠ¸
        satisfaction = result.get('service_metadata', {}).get('user_satisfaction_prediction', 0.5)
        total = self.service_stats['total_conversations']
        current_avg = self.service_stats['average_satisfaction']
        self.service_stats['average_satisfaction'] = (
            (current_avg * (total - 1) + satisfaction) / total
        )
    
    def _generate_error_response(self, error: str, processing_time: float) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        return {
            'response': f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error}",
            'processing_time': processing_time,
            'confidence': 0.0,
            'error': True,
            'service_metadata': {
                'response_quality': 0.0,
                'user_satisfaction_prediction': 0.2
            }
        }
    
    def get_service_statistics(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ í†µê³„ ë°˜í™˜"""
        return self.service_stats.copy()
    
    def get_user_analytics(self, user_id: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë¶„ì„ ì •ë³´ ë°˜í™˜"""
        memory = self.conversation_memories.get(user_id)
        if not memory:
            return {'error': 'User not found'}
        
        return {
            'conversation_count': len(memory.short_term),
            'topics_discussed': len(memory.semantic_memory),
            'most_frequent_topics': sorted(
                memory.access_frequency.items(), 
                key=lambda x: x[1], 
                reverse=True
            )[:5],
            'memory_strength_average': sum(memory.memory_strength.values()) / len(memory.memory_strength) if memory.memory_strength else 0
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
        components = {
            'multimodal_system': True,
            'intent_analyzer': True,
            'enhanced_rag': True,
            'reasoning_engine': True,
            'tool_agent': True,
            'response_generator': True
        }
        
        # ê° ì»´í¬ë„ŒíŠ¸ ìƒíƒœ í™•ì¸
        try:
            multimodal_health = self.multimodal_system.health_check()
            components['multimodal_system'] = multimodal_health['status'] == 'healthy'
        except:
            components['multimodal_system'] = False
        
        overall_health = all(components.values())
        
        return {
            'status': 'healthy' if overall_health else 'degraded',
            'components': components,
            'statistics': self.get_service_statistics(),
            'memory_usage': len(self.conversation_memories)
        }