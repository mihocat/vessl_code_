#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenAI Vision API í´ë¼ì´ì–¸íŠ¸
ChatGPT APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„ ì‹œìŠ¤í…œ
ë¹„ìš© ìµœì í™”: gpt-4o-mini ì‚¬ìš©ìœ¼ë¡œ 94% ë¹„ìš© ì ˆê°
"""

import os
import base64
import logging
import json
import time
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass
from datetime import datetime

try:
    from openai import OpenAI
except ImportError as e:
    logging.error("OpenAI library not found. Install with: pip install openai")
    raise e

logger = logging.getLogger(__name__)

@dataclass
class VisionAnalysisResult:
    """ë¹„ì „ ë¶„ì„ ê²°ê³¼"""
    success: bool
    content: str
    extracted_text: Optional[str] = None
    formulas: Optional[List[str]] = None
    analysis_type: Optional[str] = None
    confidence_score: Optional[float] = None
    processing_time: Optional[float] = None
    token_usage: Optional[Dict[str, int]] = None
    error_message: Optional[str] = None
    fallback_used: bool = False
    metadata: Optional[Dict[str, Any]] = None

class OpenAIVisionClient:
    """OpenAI Vision API í´ë¼ì´ì–¸íŠ¸ - gpt-4o-mini ìµœì í™”"""
    
    def __init__(self, config: Optional[Dict] = None):
        """
        í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        
        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (api_key, model, max_tokens ë“±)
        """
        self.config = config or {}
        
        # API í‚¤ ë¡œë“œ
        self.api_key = self._load_api_key()
        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = OpenAI(api_key=self.api_key)
        
        # ëª¨ë¸ ì„¤ì • (ë¹„ìš© ìµœì í™”)
        self.model = self.config.get('vision_model', 'gpt-4o-mini')  # 94% ë¹„ìš© ì ˆê°
        self.max_tokens = self.config.get('max_tokens', 4000)
        self.temperature = self.config.get('temperature', 0.1)
        
        # ë¶„ì„ ëª¨ë“œë³„ í”„ë¡¬í”„íŠ¸
        self.analysis_prompts = self._init_analysis_prompts()
        
        # ìš”ì²­ í†µê³„
        self.request_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'total_tokens': 0,
            'total_cost': 0.0
        }
        
        logger.info(f"OpenAI Vision Client initialized with model: {self.model}")
    
    def _load_api_key(self) -> Optional[str]:
        """API í‚¤ ë¡œë“œ"""
        # 1. ì„¤ì •ì—ì„œ ì§ì ‘ ë¡œë“œ
        if 'api_key' in self.config and self.config['api_key']:
            return self.config['api_key']
        
        # 2. í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œ
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key:
            return api_key
        
        # 3. VESSL ìŠ¤í† ë¦¬ì§€ì—ì„œ ë¡œë“œ
        vessl_key_paths = [
            '/apikey/openai_api_key.txt',
            '/apikey/OPENAI_API_KEY',
            './apikey/openai_api_key.txt'
        ]
        
        for path in vessl_key_paths:
            try:
                if os.path.exists(path):
                    with open(path, 'r', encoding='utf-8') as f:
                        key = f.read().strip()
                        if key:
                            logger.info(f"API key loaded from: {path}")
                            return key
            except Exception as e:
                logger.warning(f"Failed to read API key from {path}: {e}")
        
        # 4. ë¡œì»¬ ì„¤ì • íŒŒì¼ì—ì„œ ë¡œë“œ
        local_paths = [
            './config/openai_key.txt',
            '~/.openai/api_key',
            './openai_api_key.txt'
        ]
        
        for path in local_paths:
            expanded_path = os.path.expanduser(path)
            try:
                if os.path.exists(expanded_path):
                    with open(expanded_path, 'r', encoding='utf-8') as f:
                        key = f.read().strip()
                        if key:
                            logger.info(f"API key loaded from: {expanded_path}")
                            return key
            except Exception as e:
                logger.warning(f"Failed to read API key from {expanded_path}: {e}")
        
        logger.warning("No OpenAI API key found")
        return None
    
    def _init_analysis_prompts(self) -> Dict[str, str]:
        """ì§ˆì˜ ì¤‘ì‹¬ ìµœì í™”ëœ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”"""
        return {
            'text_extraction': """
ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì¤‘ìš”í•œ í…ìŠ¤íŠ¸ë§Œ ì •í™•íˆ ì¶”ì¶œ:
1. ì§ˆë¬¸ ë‹µë³€ì— í•„ìš”í•œ í•œêµ­ì–´ í…ìŠ¤íŠ¸ì™€ ìˆ˜ì‹ ì¶”ì¶œ
2. ê´€ë ¨ ì—†ëŠ” ë¶€ë¶„ì€ ê°„ëµíˆ ì²˜ë¦¬
3. í•œêµ­ì–´+ìˆ˜ì‹ í˜¼ì¬ ì‹œ ë‘˜ ë‹¤ ì •í™•íˆ í‘œí˜„
4. LaTeX í˜•ì‹: $$ìˆ˜ì‹$$ ë˜ëŠ” $ìˆ˜ì‹$
í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
""",
            
            'formula_analysis': """
ì§ˆë¬¸ ê´€ë ¨ ìˆ˜ì‹ê³¼ í…ìŠ¤íŠ¸ ì¤‘ì  ë¶„ì„:
1. **í•µì‹¬ ìˆ˜ì‹**: LaTeX í˜•ì‹ ($$ìˆ˜ì‹$$)
2. **ê´€ë ¨ í•œêµ­ì–´**: ìˆ˜ì‹ ì„¤ëª… ë¶€ë¶„ë§Œ
3. **ë³€ìˆ˜ ì„¤ëª…**: ì§ˆë¬¸ ê´€ë ¨ ë³€ìˆ˜ë§Œ
4. **ê³„ì‚° ê³¼ì •**: ì§ˆë¬¸ì— í•„ìš”í•œ ë¶€ë¶„ë§Œ
ë¶ˆí•„ìš”í•œ ë°°ê²½ ì„¤ëª…ì€ ì œì™¸í•˜ê³  í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
""",
            
            'problem_solving': """
ì§ˆë¬¸ í•´ê²°ì— ì§‘ì¤‘í•œ ë¶„ì„:
1. **í•µì‹¬ ë¬¸ì œ**: ì§ˆë¬¸ì´ ë¬»ëŠ” ê²ƒë§Œ
2. **í•„ìš”í•œ ì •ë³´**: ë¬¸ì œ í•´ê²°ì— í•„ìš”í•œ í•œêµ­ì–´+ìˆ˜ì‹
3. **í•´ê²° ë‹¨ê³„**: ê°„ê²°í•œ í’€ì´
4. **ë‹µ**: ëª…í™•í•œ ê²°ê³¼
ê´€ë ¨ ì—†ëŠ” ë‚´ìš©ì€ ìƒëµí•˜ê³  í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
""",
            
            'general_analysis': """
ì§ˆë¬¸ ì¤‘ì‹¬ ì´ë¯¸ì§€ ë¶„ì„:
1. **ì§ˆë¬¸ ê´€ë ¨ ë‚´ìš©**: ë¬¼ì–´ë³¸ ê²ƒê³¼ ì—°ê´€ëœ ë¶€ë¶„ë§Œ
2. **í•œêµ­ì–´ í…ìŠ¤íŠ¸**: ì§ˆë¬¸ ë‹µë³€ì— í•„ìš”í•œ ê²ƒë§Œ
3. **ìˆ˜ì‹**: ê´€ë ¨ ìˆëŠ” ìˆ˜ì‹ë§Œ LaTeXë¡œ ($$ìˆ˜ì‹$$)
4. **í•µì‹¬ ì •ë³´**: ì§ˆë¬¸ í•´ê²°ì— í•„ìˆ˜ì ì¸ ê²ƒë§Œ
ë¶ˆí•„ìš”í•œ ì„¸ë¶€ì‚¬í•­ì€ ì œì™¸í•˜ê³  ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
"""
        }
    
    def analyze_image(self, image_data: Union[str, bytes], 
                     analysis_type: str = "general_analysis",
                     custom_prompt: Optional[str] = None,
                     query_context: Optional[Dict] = None) -> VisionAnalysisResult:
        """
        ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰
        
        Args:
            image_data: ì´ë¯¸ì§€ ë°ì´í„° (base64 ë¬¸ìì—´ ë˜ëŠ” ë°”ì´íŠ¸)
            analysis_type: ë¶„ì„ ìœ í˜• (text_extraction, formula_analysis, problem_solving, general_analysis)
            custom_prompt: ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸
            query_context: ì§ˆì˜ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            
        Returns:
            VisionAnalysisResult: ë¶„ì„ ê²°ê³¼
        """
        start_time = time.time()
        self.request_stats['total_requests'] += 1
        
        try:
            # ì´ë¯¸ì§€ ë°ì´í„° ì¤€ë¹„
            if isinstance(image_data, bytes):
                image_base64 = base64.b64encode(image_data).decode('utf-8')
            else:
                image_base64 = image_data
            
            # í”„ë¡¬í”„íŠ¸ ì„ íƒ
            if custom_prompt:
                prompt = custom_prompt
            else:
                prompt = self.analysis_prompts.get(analysis_type, self.analysis_prompts['general_analysis'])
            
            # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ í–¥ìƒ
            if query_context:
                prompt = self._enhance_prompt_with_context(prompt, query_context)
            
            # API ìš”ì²­
            response = self._make_vision_request(image_base64, prompt)
            
            if response:
                # ì„±ê³µì ì¸ ì‘ë‹µ ì²˜ë¦¬
                result = self._process_successful_response(
                    response, analysis_type, start_time
                )
                self.request_stats['successful_requests'] += 1
                
                # í›„ì²˜ë¦¬
                result = self._post_process_result(result, analysis_type)
                
                logger.info(f"Vision analysis completed: {analysis_type} ({result.processing_time:.2f}s)")
                return result
            else:
                # ì‹¤íŒ¨ ì²˜ë¦¬
                error_result = self._create_error_result(
                    "API ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", start_time
                )
                self.request_stats['failed_requests'] += 1
                return error_result
                
        except Exception as e:
            logger.error(f"Vision analysis error: {e}")
            error_result = self._create_error_result(str(e), start_time)
            self.request_stats['failed_requests'] += 1
            return error_result
    
    def _make_vision_request(self, image_base64: str, prompt: str) -> Optional[Any]:
        """Vision API ìš”ì²­ ìˆ˜í–‰ (ìƒì„¸ ë¡œê¹… í¬í•¨)"""
        try:
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}",
                                "detail": "low"  # í† í° ìµœì í™”: ì§ˆì˜ ì¤‘ì‹¬ ë¶„ì„ì—ëŠ” lowë©´ ì¶©ë¶„
                            }
                        }
                    ]
                }
            ]
            
            # ìš”ì²­ ë¡œê¹…
            request_info = {
                "model": self.model,
                "max_tokens": self.max_tokens,
                "temperature": self.temperature,
                "prompt_length": len(prompt),
                "image_size_kb": len(image_base64) * 3 / 4 / 1024,  # base64 í¬ê¸° ì¶”ì •
                "detail_level": "low"
            }
            logger.info(f"ğŸš€ OpenAI Vision API ìš”ì²­ ì‹œì‘: {request_info}")
            
            # API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            
            # ì‘ë‹µ ë¡œê¹…
            if response and hasattr(response, 'usage'):
                response_info = {
                    "success": True,
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens,
                    "estimated_cost_usd": self._calculate_cost({
                        "prompt_tokens": response.usage.prompt_tokens,
                        "completion_tokens": response.usage.completion_tokens,
                        "total_tokens": response.usage.total_tokens
                    }),
                    "response_length": len(response.choices[0].message.content) if response.choices else 0
                }
                logger.info(f"âœ… OpenAI Vision API ì‘ë‹µ ì™„ë£Œ: {response_info}")
                
                # ìƒì„¸ ì‘ë‹µ ë‚´ìš© ë¡œê¹… (ì²˜ìŒ 200ìë§Œ)
                if response.choices and response.choices[0].message.content:
                    content_preview = response.choices[0].message.content[:200] + "..." if len(response.choices[0].message.content) > 200 else response.choices[0].message.content
                    logger.info(f"ğŸ“ ì‘ë‹µ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {content_preview}")
            
            return response
            
        except Exception as e:
            error_info = {
                "success": False,
                "error_type": type(e).__name__,
                "error_message": str(e),
                "prompt_length": len(prompt),
                "image_size_kb": len(image_base64) * 3 / 4 / 1024
            }
            logger.error(f"âŒ OpenAI Vision API ìš”ì²­ ì‹¤íŒ¨: {error_info}")
            return None
    
    def _enhance_prompt_with_context(self, prompt: str, context: Dict) -> str:
        """ì§ˆì˜ ì¤‘ì‹¬ í”„ë¡¬í”„íŠ¸ í–¥ìƒ"""
        # ì§ˆë¬¸ ì •ë³´ ìš°ì„  ë°˜ì˜
        if 'query' in context and context['query']:
            user_question = context['query']
            enhanced_prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸: "{user_question}"

ìœ„ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì´ë¯¸ì§€ì—ì„œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ë¶„ì„í•˜ì„¸ìš”.

{prompt}

íŠ¹ë³„ ì§€ì‹œì‚¬í•­:
- ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ëœ í•œêµ­ì–´ í…ìŠ¤íŠ¸ì™€ ìˆ˜ì‹ë§Œ ì¶”ì¶œ
- í•œêµ­ì–´+ìˆ˜ì‹ í˜¼ì¬ ì‹œ ì •í™•í•œ LaTeX í‘œí˜„ ì‚¬ìš©
- ì§ˆë¬¸ í•´ê²°ì— ë¶ˆí•„ìš”í•œ ë‚´ìš©ì€ ìƒëµ"""
        else:
            enhanced_prompt = prompt
        
        # ë„ë©”ì¸ë³„ ê°„ê²°í•œ íŒíŠ¸
        if 'domain' in context and context['domain']:
            domain_focus = {
                'electrical': "íšŒë¡œë„, ì „ì••/ì „ë¥˜ ê°’, ì „ê¸° ê³µì‹ ì¤‘ì‹¬ìœ¼ë¡œ",
                'mathematics': "ìˆ˜ì‹, ê·¸ë˜í”„, ê³„ì‚° ê³¼ì • ì¤‘ì‹¬ìœ¼ë¡œ", 
                'physics': "ë¬¼ë¦¬ ê³µì‹, ìˆ˜ì¹˜, ë‹¨ìœ„ ì¤‘ì‹¬ìœ¼ë¡œ",
                'chemistry': "í™”í•™ì‹, ë¶„ìêµ¬ì¡°, ë°˜ì‘ì‹ ì¤‘ì‹¬ìœ¼ë¡œ"
            }
            if context['domain'] in domain_focus:
                enhanced_prompt += f"\n\n{domain_focus[context['domain']]} ë¶„ì„í•˜ì„¸ìš”."
        
        # í•µì‹¬ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìš°ì„  ì²˜ë¦¬
        if 'keywords' in context and context['keywords']:
            key_terms = ', '.join(context['keywords'][:2])  # ìµœëŒ€ 2ê°œë§Œ
            enhanced_prompt += f"\n\ní•µì‹¬ í‚¤ì›Œë“œ: {key_terms} - ì´ì™€ ê´€ë ¨ëœ ë¶€ë¶„ì„ ìš°ì„  ë¶„ì„í•˜ì„¸ìš”."
        
        return enhanced_prompt
    
    def _process_successful_response(self, response: Any, analysis_type: str, start_time: float) -> VisionAnalysisResult:
        """ì„±ê³µì ì¸ ì‘ë‹µ ì²˜ë¦¬"""
        processing_time = time.time() - start_time
        
        # ì‘ë‹µ ë‚´ìš© ì¶”ì¶œ (ì•ˆì „í•œ ì ‘ê·¼)
        try:
            if hasattr(response, 'choices') and response.choices:
                choice = response.choices[0]
                if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                    content = choice.message.content
                elif hasattr(choice, 'content'):
                    content = choice.content
                else:
                    content = str(choice)
            else:
                content = str(response)
        except Exception as e:
            logger.warning(f"Response parsing issue: {e}")
            content = "ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
        token_usage = None
        try:
            if hasattr(response, 'usage'):
                token_usage = {
                    'prompt_tokens': response.usage.prompt_tokens,
                    'completion_tokens': response.usage.completion_tokens,
                    'total_tokens': response.usage.total_tokens
                }
                self.request_stats['total_tokens'] += token_usage['total_tokens']
                
                # ë¹„ìš© ê³„ì‚° (gpt-4o-mini ê¸°ì¤€)
                cost = self._calculate_cost(token_usage)
                self.request_stats['total_cost'] += cost
        except Exception as e:
            logger.warning(f"Token usage parsing failed: {e}")
        
        # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
        confidence_score = self._calculate_confidence_score(content, analysis_type)
        
        return VisionAnalysisResult(
            success=True,
            content=content,
            analysis_type=analysis_type,
            confidence_score=confidence_score,
            processing_time=processing_time,
            token_usage=token_usage,
            metadata={
                'model': self.model,
                'timestamp': datetime.now().isoformat()
            }
        )
    
    def _post_process_result(self, result: VisionAnalysisResult, analysis_type: str) -> VisionAnalysisResult:
        """ê²°ê³¼ í›„ì²˜ë¦¬"""
        try:
            if analysis_type == 'text_extraction':
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼ ì •ì œ
                result.extracted_text = self._extract_text_from_content(result.content)
            
            elif analysis_type == 'formula_analysis':
                # ìˆ˜ì‹ ì¶”ì¶œ
                result.formulas = self._extract_formulas_from_content(result.content)
            
            # ë‚´ìš© ì •ì œ
            result.content = self._clean_content(result.content)
            
        except Exception as e:
            logger.warning(f"Post-processing error: {e}")
        
        return result
    
    def _extract_text_from_content(self, content: str) -> Optional[str]:
        """ë‚´ìš©ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¡œì§
        lines = content.split('\n')
        text_lines = []
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('**') and not line.startswith('#'):
                # ë§ˆí¬ë‹¤ìš´ í—¤ë”ë‚˜ êµµì€ ê¸€ì”¨ê°€ ì•„ë‹Œ ì¼ë°˜ í…ìŠ¤íŠ¸
                text_lines.append(line)
        
        return '\n'.join(text_lines) if text_lines else None
    
    def _extract_formulas_from_content(self, content: str) -> List[str]:
        """ë‚´ìš©ì—ì„œ ìˆ˜ì‹ ì¶”ì¶œ"""
        import re
        formulas = []
        
        # LaTeX íŒ¨í„´ ì°¾ê¸°
        latex_patterns = [
            r'\$\$(.+?)\$\$',  # ë¸”ë¡ ìˆ˜ì‹
            r'\$(.+?)\$',      # ì¸ë¼ì¸ ìˆ˜ì‹
            r'\\begin\{equation\}(.+?)\\end\{equation\}',  # equation í™˜ê²½
        ]
        
        for pattern in latex_patterns:
            matches = re.findall(pattern, content, re.DOTALL)
            formulas.extend(matches)
        
        return list(set(formulas))  # ì¤‘ë³µ ì œê±°
    
    def _clean_content(self, content: str) -> str:
        """ë‚´ìš© ì •ì œ"""
        if not content:
            return content
        
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        content = '\n'.join(line.strip() for line in content.split('\n'))
        
        # ì—°ì†ëœ ë¹ˆ ì¤„ ì œê±°
        import re
        content = re.sub(r'\n\s*\n\s*\n', '\n\n', content)
        
        return content.strip()
    
    def _calculate_confidence_score(self, content: str, analysis_type: str) -> float:
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        if not content:
            return 0.0
        
        score = 0.7  # ê¸°ë³¸ ì ìˆ˜
        
        # ë‚´ìš© ê¸¸ì´ ê¸°ë°˜
        if len(content) > 100:
            score += 0.1
        if len(content) > 500:
            score += 0.1
        
        # ë¶„ì„ ìœ í˜•ë³„ íŠ¹í™” ì ìˆ˜
        if analysis_type == 'formula_analysis':
            if 'LaTeX' in content or '$' in content:
                score += 0.1
        elif analysis_type == 'text_extraction':
            if 'í…ìŠ¤íŠ¸' in content and 'ì—†ìŒ' not in content:
                score += 0.1
        
        # êµ¬ì¡°í™” ì ìˆ˜
        if '**' in content or '#' in content:  # ë§ˆí¬ë‹¤ìš´ êµ¬ì¡°
            score += 0.05
        
        return min(1.0, score)
    
    def _calculate_cost(self, token_usage: Dict[str, int]) -> float:
        """ë¹„ìš© ê³„ì‚° (gpt-4o-mini ê¸°ì¤€)"""
        # gpt-4o-mini ê°€ê²©: $0.00015/1K input tokens, $0.0006/1K output tokens
        input_cost = token_usage.get('prompt_tokens', 0) * 0.00015 / 1000
        output_cost = token_usage.get('completion_tokens', 0) * 0.0006 / 1000
        return input_cost + output_cost
    
    def _create_error_result(self, error_message: str, start_time: float) -> VisionAnalysisResult:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        processing_time = time.time() - start_time
        
        return VisionAnalysisResult(
            success=False,
            content="",
            error_message=error_message,
            processing_time=processing_time,
            metadata={
                'model': self.model,
                'timestamp': datetime.now().isoformat()
            }
        )
    
    def batch_analyze_images(self, images: List[Tuple[Union[str, bytes], str]], 
                           analysis_type: str = "general_analysis") -> List[VisionAnalysisResult]:
        """ë°°ì¹˜ ì´ë¯¸ì§€ ë¶„ì„"""
        results = []
        
        for i, (image_data, image_name) in enumerate(images):
            logger.info(f"Processing image {i+1}/{len(images)}: {image_name}")
            
            result = self.analyze_image(image_data, analysis_type)
            result.metadata = result.metadata or {}
            result.metadata['image_name'] = image_name
            result.metadata['batch_index'] = i
            
            results.append(result)
            
            # API ìš”ì²­ ì œí•œ ê³ ë ¤ (í•„ìš”ì‹œ)
            if i < len(images) - 1:
                time.sleep(0.1)  # ì§§ì€ ì§€ì—°
        
        logger.info(f"Batch analysis completed: {len(results)} images")
        return results
    
    def get_statistics(self) -> Dict[str, Any]:
        """í†µê³„ ì •ë³´ ë°˜í™˜"""
        success_rate = 0.0
        if self.request_stats['total_requests'] > 0:
            success_rate = self.request_stats['successful_requests'] / self.request_stats['total_requests']
        
        avg_cost_per_request = 0.0
        if self.request_stats['successful_requests'] > 0:
            avg_cost_per_request = self.request_stats['total_cost'] / self.request_stats['successful_requests']
        
        return {
            'total_requests': self.request_stats['total_requests'],
            'successful_requests': self.request_stats['successful_requests'],
            'failed_requests': self.request_stats['failed_requests'],
            'success_rate': success_rate,
            'total_tokens_used': self.request_stats['total_tokens'],
            'total_cost_usd': self.request_stats['total_cost'],
            'average_cost_per_request': avg_cost_per_request,
            'model': self.model,
            'cost_optimization': "94% savings with gpt-4o-mini vs gpt-4o"
        }
    
    def test_connection(self) -> Tuple[bool, str]:
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì™„ì„±ìœ¼ë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",  # ë” ì €ë ´í•œ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=5
            )
            
            if response and response.choices:
                return True, "OpenAI API ì—°ê²° ì„±ê³µ"
            else:
                return False, "OpenAI API ì‘ë‹µ ì—†ìŒ"
                
        except Exception as e:
            return False, f"OpenAI API ì—°ê²° ì‹¤íŒ¨: {e}"

# í¸ì˜ í•¨ìˆ˜
def analyze_image_with_openai(image_data: Union[str, bytes], 
                             analysis_type: str = "general_analysis",
                             custom_prompt: Optional[str] = None) -> VisionAnalysisResult:
    """ì´ë¯¸ì§€ ë¶„ì„ í¸ì˜ í•¨ìˆ˜"""
    client = OpenAIVisionClient()
    return client.analyze_image(image_data, analysis_type, custom_prompt)

def test_openai_vision() -> bool:
    """OpenAI Vision API í…ŒìŠ¤íŠ¸"""
    try:
        client = OpenAIVisionClient()
        success, message = client.test_connection()
        logger.info(f"OpenAI Vision test: {message}")
        return success
    except Exception as e:
        logger.error(f"OpenAI Vision test failed: {e}")
        return False