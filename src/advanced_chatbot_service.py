#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced Chatbot Service with Next-Generation Features
ì°¨ì„¸ëŒ€ ê¸°ëŠ¥ì„ íƒ‘ì¬í•œ ê³ ê¸‰ ì±—ë´‡ ì„œë¹„ìŠ¤
"""

import logging
import time
import asyncio
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import json
import hashlib
from datetime import datetime, timedelta

from PIL import Image

from config import Config
from intent_analyzer import IntentAnalyzer, IntentAnalysisResult
from enhanced_rag_system import EnhancedRAGSystem
from multi_agent_system import MultiAgentSystem, VisionAnalystAgent, RAGSpecialistAgent, ReasoningEngineAgent, SynthesizerAgent
from optimized_openai_vision_analyzer import OptimizedOpenAIVisionAnalyzer as OpenAIVisionAnalyzer

logger = logging.getLogger(__name__)


class ConversationMode(Enum):
    """ëŒ€í™” ëª¨ë“œ"""
    STANDARD = "standard"           # í‘œì¤€ ëª¨ë“œ
    EXPERT = "expert"              # ì „ë¬¸ê°€ ëª¨ë“œ
    TUTORIAL = "tutorial"          # íŠœí† ë¦¬ì–¼ ëª¨ë“œ
    RESEARCH = "research"          # ì—°êµ¬ ëª¨ë“œ
    COLLABORATIVE = "collaborative" # í˜‘ì—… ëª¨ë“œ


@dataclass
class ConversationContext:
    """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸"""
    session_id: str
    user_id: Optional[str]
    mode: ConversationMode
    domain_focus: Optional[str]
    difficulty_level: int  # 1-5
    preferences: Dict[str, Any]
    history: List[Dict[str, Any]]
    memory: Dict[str, Any]
    created_at: datetime
    last_active: datetime


@dataclass
class ResponseMetadata:
    """ì‘ë‹µ ë©”íƒ€ë°ì´í„°"""
    processing_time: float
    confidence: float
    source_count: int
    agent_count: int
    reasoning_depth: int
    token_usage: int
    cost_estimate: float
    quality_score: float


class MemorySystem:
    """ëŒ€í™” ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: Dict = None):
        self.config = config or {}
        self.short_term_memory = {}  # ì„¸ì…˜ë³„ ë‹¨ê¸° ë©”ëª¨ë¦¬
        self.long_term_memory = {}   # ì‚¬ìš©ìë³„ ì¥ê¸° ë©”ëª¨ë¦¬
        self.concept_graph = {}      # ê°œë… ê´€ê³„ ê·¸ë˜í”„
        
    def store_conversation(
        self, 
        session_id: str, 
        query: str, 
        response: str, 
        metadata: Dict
    ):
        """ëŒ€í™” ì €ì¥"""
        if session_id not in self.short_term_memory:
            self.short_term_memory[session_id] = []
        
        conversation_entry = {
            'timestamp': datetime.now(),
            'query': query,
            'response': response,
            'metadata': metadata
        }
        
        self.short_term_memory[session_id].append(conversation_entry)
        
        # ê°œë… ì¶”ì¶œ ë° ê·¸ë˜í”„ ì—…ë°ì´íŠ¸
        self._update_concept_graph(query, response, metadata)
    
    def get_relevant_context(
        self, 
        session_id: str, 
        current_query: str, 
        max_context: int = 5
    ) -> List[Dict]:
        """ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰"""
        if session_id not in self.short_term_memory:
            return []
        
        conversations = self.short_term_memory[session_id]
        
        # ìµœê·¼ ëŒ€í™” ìš°ì„ 
        recent_conversations = conversations[-max_context:]
        
        # ì˜ë¯¸ì  ìœ ì‚¬ì„± ê¸°ë°˜ í•„í„°ë§ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)
        relevant_conversations = []
        query_words = set(current_query.lower().split())
        
        for conv in recent_conversations:
            conv_words = set((conv['query'] + ' ' + conv['response']).lower().split())
            similarity = len(query_words.intersection(conv_words)) / len(query_words.union(conv_words))
            
            if similarity > 0.1:  # ì„ê³„ê°’
                relevant_conversations.append({
                    'conversation': conv,
                    'similarity': similarity
                })
        
        # ìœ ì‚¬ì„± ê¸°ì¤€ ì •ë ¬
        relevant_conversations.sort(key=lambda x: x['similarity'], reverse=True)
        
        return [rc['conversation'] for rc in relevant_conversations]
    
    def _update_concept_graph(self, query: str, response: str, metadata: Dict):
        """ê°œë… ê·¸ë˜í”„ ì—…ë°ì´íŠ¸"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ê°œë… ì¶”ì¶œ
        concepts = self._extract_concepts(query + ' ' + response)
        
        for concept in concepts:
            if concept not in self.concept_graph:
                self.concept_graph[concept] = {
                    'frequency': 0,
                    'related_concepts': set(),
                    'last_seen': datetime.now()
                }
            
            self.concept_graph[concept]['frequency'] += 1
            self.concept_graph[concept]['last_seen'] = datetime.now()
            
            # ê´€ë ¨ ê°œë… ì—°ê²°
            for other_concept in concepts:
                if other_concept != concept:
                    self.concept_graph[concept]['related_concepts'].add(other_concept)
    
    def _extract_concepts(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ê°œë… ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” NER, í‚¤ì›Œë“œ ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)
        import re
        words = re.findall(r'\b\w{3,}\b', text.lower())
        
        # ì¼ë°˜ì ì¸ ë¶ˆìš©ì–´ ì œê±°
        stopwords = {'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 'ë”°ë¼ì„œ', 'ë§Œì•½', 'ë•Œë¬¸ì—', 'í†µí•´ì„œ'}
        concepts = [word for word in words if word not in stopwords and len(word) > 2]
        
        return list(set(concepts))


class AdaptiveResponseGenerator:
    """ì ì‘í˜• ì‘ë‹µ ìƒì„±ê¸°"""
    
    def __init__(self, config: Dict = None):
        self.config = config or {}
        self.response_templates = self._initialize_templates()
        
    def generate_adaptive_response(
        self, 
        base_response: str,
        context: ConversationContext,
        metadata: ResponseMetadata
    ) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì ì‘í˜• ì‘ë‹µ ìƒì„±"""
        
        # ëª¨ë“œë³„ ì‘ë‹µ ì¡°ì •
        if context.mode == ConversationMode.EXPERT:
            response = self._enhance_for_expert_mode(base_response, metadata)
        elif context.mode == ConversationMode.TUTORIAL:
            response = self._enhance_for_tutorial_mode(base_response, metadata)
        elif context.mode == ConversationMode.RESEARCH:
            response = self._enhance_for_research_mode(base_response, metadata)
        else:
            response = base_response
        
        # ë‚œì´ë„ ì¡°ì •
        response = self._adjust_for_difficulty(response, context.difficulty_level)
        
        # ê°œì¸í™”
        response = self._personalize_response(response, context)
        
        # ë©”íƒ€ì •ë³´ ì¶”ê°€
        response = self._add_metadata_info(response, metadata)
        
        return response
    
    def _enhance_for_expert_mode(self, response: str, metadata: ResponseMetadata) -> str:
        """ì „ë¬¸ê°€ ëª¨ë“œìš© ì‘ë‹µ ê°•í™”"""
        enhancements = []
        
        # ì‹ ë¢°ë„ ì •ë³´ ì¶”ê°€
        enhancements.append(f"\n\n**ì‹ ë¢°ë„ ë¶„ì„**: {metadata.confidence:.1%}")
        
        # ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€
        if metadata.source_count > 0:
            enhancements.append(f"**ì°¸ì¡° ì†ŒìŠ¤**: {metadata.source_count}ê°œ ë¬¸ì„œ")
        
        # ì²˜ë¦¬ ê³¼ì • ì •ë³´
        if metadata.agent_count > 1:
            enhancements.append(f"**ë¶„ì„ ì—ì´ì „íŠ¸**: {metadata.agent_count}ê°œ ì „ë¬¸ ì‹œìŠ¤í…œ")
        
        # í’ˆì§ˆ ì ìˆ˜
        if metadata.quality_score > 0.8:
            enhancements.append("**í’ˆì§ˆ**: ë†’ìŒ âœ“")
        elif metadata.quality_score > 0.6:
            enhancements.append("**í’ˆì§ˆ**: ì¤‘ê°„ â—‹")
        else:
            enhancements.append("**í’ˆì§ˆ**: ë‚®ìŒ â–³")
        
        return response + "".join(enhancements)
    
    def _enhance_for_tutorial_mode(self, response: str, metadata: ResponseMetadata) -> str:
        """íŠœí† ë¦¬ì–¼ ëª¨ë“œìš© ì‘ë‹µ ê°•í™”"""
        # ë‹¨ê³„ë³„ ì„¤ëª… ì¶”ê°€
        tutorial_elements = [
            "\n\n**ğŸ“š í•™ìŠµ ë„ì›€ë§**:",
            "â€¢ ì´í•´í•˜ê¸° ì–´ë ¤ìš´ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ë” ìì„¸í•œ ì„¤ëª…ì„ ìš”ì²­í•˜ì„¸ìš”",
            "â€¢ ì˜ˆì‹œë¥¼ ë” ë³´ê³  ì‹¶ìœ¼ë©´ 'ì˜ˆì‹œ ë” ë³´ì—¬ì¤˜'ë¼ê³  ë§ì”€í•˜ì„¸ìš”",
            "â€¢ ì—°ê´€ëœ ê°œë…ì„ ì•Œê³  ì‹¶ìœ¼ë©´ 'ê´€ë ¨ ë‚´ìš©'ì„ ìš”ì²­í•˜ì„¸ìš”"
        ]
        
        if metadata.reasoning_depth > 2:
            tutorial_elements.append("â€¢ ë³µì¡í•œ ë‚´ìš©ì´ë¯€ë¡œ ë‹¨ê³„ë³„ë¡œ ì°¨ê·¼ì°¨ê·¼ ì½ì–´ë³´ì„¸ìš”")
        
        return response + "\n".join(tutorial_elements)
    
    def _enhance_for_research_mode(self, response: str, metadata: ResponseMetadata) -> str:
        """ì—°êµ¬ ëª¨ë“œìš© ì‘ë‹µ ê°•í™”"""
        research_elements = []
        
        # ì¶”ê°€ ì—°êµ¬ ë°©í–¥ ì œì‹œ
        research_elements.append("\n\n**ğŸ”¬ ì—°êµ¬ í™•ì¥ ì œì•ˆ**:")
        research_elements.append("â€¢ ì´ ì£¼ì œì™€ ê´€ë ¨ëœ ìµœì‹  ì—°êµ¬ ë™í–¥ì„ í™•ì¸í•´ë³´ì„¸ìš”")
        research_elements.append("â€¢ ë‹¤ë¥¸ ê´€ì ì—ì„œì˜ ì ‘ê·¼ ë°©ë²•ì„ íƒìƒ‰í•´ë³´ì„¸ìš”")
        
        # ì°¸ê³ ë¬¸í—Œ ìŠ¤íƒ€ì¼ ì •ë³´
        if metadata.source_count > 0:
            research_elements.append(f"â€¢ ì°¸ì¡°ëœ {metadata.source_count}ê°œ ì†ŒìŠ¤ì˜ ì›ë¬¸ì„ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤")
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ ì£¼ì˜ì‚¬í•­
        if metadata.confidence < 0.8:
            research_elements.append("âš ï¸ **ì£¼ì˜**: ì´ ë‹µë³€ì˜ ì‹ ë¢°ë„ê°€ ë†’ì§€ ì•Šìœ¼ë¯€ë¡œ ì¶”ê°€ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        return response + "\n".join(research_elements)
    
    def _adjust_for_difficulty(self, response: str, difficulty_level: int) -> str:
        """ë‚œì´ë„ë³„ ì‘ë‹µ ì¡°ì •"""
        if difficulty_level <= 2:  # ì´ˆê¸‰
            # ì‰¬ìš´ ìš©ì–´ë¡œ ëŒ€ì²´, ë” ë§ì€ ì„¤ëª… ì¶”ê°€
            response += "\n\n**ğŸ’¡ ì‰¬ìš´ ì„¤ëª…**: ë³µì¡í•œ ìš©ì–´ê°€ ìˆë‹¤ë©´ ë” ì‰½ê²Œ ì„¤ëª…í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        elif difficulty_level >= 4:  # ê³ ê¸‰
            # ì „ë¬¸ ìš©ì–´ ìœ ì§€, ì‹¬í™” ë‚´ìš© ì¶”ê°€
            response += "\n\n**ğŸ“ ì‹¬í™” í•™ìŠµ**: ë” ê¹Šì´ ìˆëŠ” ë‚´ìš©ì´ë‚˜ ìˆ˜í•™ì  ì ‘ê·¼ì´ í•„ìš”í•˜ë©´ ë§ì”€í•˜ì„¸ìš”."
        
        return response
    
    def _personalize_response(self, response: str, context: ConversationContext) -> str:
        """ê°œì¸í™” ì‘ë‹µ"""
        # ì‚¬ìš©ì ì„ í˜¸ë„ ë°˜ì˜
        preferences = context.preferences
        
        if preferences.get('include_examples', True):
            response += "\n\n**ğŸ“‹ ê´€ë ¨ ì˜ˆì‹œ**: êµ¬ì²´ì ì¸ ì˜ˆì‹œê°€ í•„ìš”í•˜ë©´ ìš”ì²­í•´ì£¼ì„¸ìš”."
        
        if preferences.get('show_formulas', True) and 'ìˆ˜ì‹' in response:
            response += "\n\n**ğŸ§® ìˆ˜ì‹ ì„¤ëª…**: ìˆ˜ì‹ì˜ ì˜ë¯¸ë‚˜ ìœ ë„ ê³¼ì •ì´ ê¶ê¸ˆí•˜ë©´ ì•Œë ¤ì£¼ì„¸ìš”."
        
        return response
    
    def _add_metadata_info(self, response: str, metadata: ResponseMetadata) -> str:
        """ë©”íƒ€ë°ì´í„° ì •ë³´ ì¶”ê°€"""
        footer_elements = []
        
        # ì²˜ë¦¬ ì‹œê°„ (ëŠë¦° ê²½ìš°ë§Œ)
        if metadata.processing_time > 10:
            footer_elements.append(f"â±ï¸ ì²˜ë¦¬ì‹œê°„: {metadata.processing_time:.1f}ì´ˆ")
        
        # ë¹„ìš© ì •ë³´ (ë†’ì€ ê²½ìš°ë§Œ)
        if metadata.cost_estimate > 0.01:
            footer_elements.append(f"ğŸ’° ì˜ˆìƒë¹„ìš©: ${metadata.cost_estimate:.3f}")
        
        if footer_elements:
            response += f"\n\n_{' | '.join(footer_elements)}_"
        
        return response
    
    def _initialize_templates(self) -> Dict[str, str]:
        """ì‘ë‹µ í…œí”Œë¦¿ ì´ˆê¸°í™”"""
        return {
            'greeting': "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
            'clarification': "ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì‹œê² ì–´ìš”?",
            'no_results': "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            'error': "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            'thinking': "ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."
        }


class AdvancedChatbotService:
    """ì°¨ì„¸ëŒ€ ê³ ê¸‰ ì±—ë´‡ ì„œë¹„ìŠ¤"""
    
    def __init__(self, config: Config):
        self.config = config
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.intent_analyzer = IntentAnalyzer()
        self.memory_system = MemorySystem()
        self.response_generator = AdaptiveResponseGenerator()
        
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        from rag_system import RAGSystem
        from llm_client_openai import LLMClient
        
        self.llm_client = LLMClient(config.llm)
        self.base_rag = RAGSystem(config.rag, config.dataset, self.llm_client)
        self.enhanced_rag = EnhancedRAGSystem(self.base_rag, config.rag)
        
        # ì´ë¯¸ì§€ ë¶„ì„ê¸° ì´ˆê¸°í™”
        self.vision_analyzer = OpenAIVisionAnalyzer(config)
        
        # ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.multi_agent_system = MultiAgentSystem()
        self._initialize_agents()
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì €ì¥ì†Œ
        self.conversation_contexts = {}
        
        # í†µê³„
        self.stats = {
            'total_queries': 0,
            'successful_responses': 0,
            'average_response_time': 0.0,
            'mode_usage': {mode.value: 0 for mode in ConversationMode},
            'feature_usage': {
                'vision_analysis': 0,
                'multi_agent': 0,
                'memory_recall': 0,
                'adaptive_response': 0
            }
        }
        
        logger.info("Advanced Chatbot Service initialized successfully")
    
    def _initialize_agents(self):
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        # ë¹„ì „ ë¶„ì„ ì—ì´ì „íŠ¸
        vision_agent = VisionAnalystAgent(self.vision_analyzer)
        self.multi_agent_system.register_agent(vision_agent)
        
        # RAG ì „ë¬¸ ì—ì´ì „íŠ¸
        rag_agent = RAGSpecialistAgent(self.enhanced_rag)
        self.multi_agent_system.register_agent(rag_agent)
        
        # ì¶”ë¡  ì—”ì§„
        reasoning_agent = ReasoningEngineAgent(self.llm_client)
        self.multi_agent_system.register_agent(reasoning_agent)
        
        # ì‘ë‹µ í•©ì„±ê¸°
        synthesizer = SynthesizerAgent(self.llm_client)
        self.multi_agent_system.register_agent(synthesizer)
        
        logger.info("Multi-agent system initialized with 4 specialized agents")
    
    def create_conversation_context(
        self, 
        session_id: str,
        user_id: Optional[str] = None,
        mode: ConversationMode = ConversationMode.STANDARD,
        preferences: Dict = None
    ) -> ConversationContext:
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        context = ConversationContext(
            session_id=session_id,
            user_id=user_id,
            mode=mode,
            domain_focus=None,
            difficulty_level=3,  # ê¸°ë³¸ ì¤‘ê°„ ë‚œì´ë„
            preferences=preferences or {},
            history=[],
            memory={},
            created_at=datetime.now(),
            last_active=datetime.now()
        )
        
        self.conversation_contexts[session_id] = context
        return context
    
    async def process_query_advanced(
        self,
        query: str,
        session_id: str,
        image: Optional[Image.Image] = None,
        mode: Optional[ConversationMode] = None,
        user_preferences: Dict = None
    ) -> Dict[str, Any]:
        """ê³ ê¸‰ ì¿¼ë¦¬ ì²˜ë¦¬"""
        start_time = time.time()
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
        if session_id not in self.conversation_contexts:
            self.create_conversation_context(session_id, preferences=user_preferences)
        
        context = self.conversation_contexts[session_id]
        context.last_active = datetime.now()
        
        # ëª¨ë“œ ì—…ë°ì´íŠ¸
        if mode:
            context.mode = mode
        
        try:
            # 1. ì˜ë„ ë¶„ì„
            intent = self.intent_analyzer.analyze_intent(
                query, 
                has_image=image is not None,
                context={'conversation_context': context}
            )
            
            # 2. ë©”ëª¨ë¦¬ì—ì„œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
            relevant_context = self.memory_system.get_relevant_context(
                session_id, query
            )
            
            # 3. ì²˜ë¦¬ ì „ëµ ê²°ì •
            use_multi_agent = self._should_use_multi_agent(intent, context)
            
            # 4. ì¿¼ë¦¬ ì²˜ë¦¬
            if use_multi_agent:
                logger.info("Using multi-agent processing")
                self.stats['feature_usage']['multi_agent'] += 1
                
                result = await self.multi_agent_system.process_query(
                    query, intent, 
                    has_image=image is not None, 
                    image=image,
                    context={'conversation_context': context, 'relevant_history': relevant_context}
                )
                
                base_response = result['answer']
                confidence = result['confidence']
                processing_metadata = result['metadata']
                
            else:
                logger.info("Using standard RAG processing")
                
                # í‘œì¤€ RAG ì²˜ë¦¬
                if hasattr(self.enhanced_rag, 'search_sync'):
                    search_results, max_score = self.enhanced_rag.search_sync(
                        query, k=10, has_image=image is not None
                    )
                else:
                    search_results, max_score = self.base_rag.search(query, k=10)
                
                # ê¸°ë³¸ ì‘ë‹µ ìƒì„±
                base_response = self._generate_basic_response(
                    query, search_results, max_score, image
                )
                confidence = max_score
                processing_metadata = {'agents_used': ['rag_only']}
            
            # 5. ì‘ë‹µ ë©”íƒ€ë°ì´í„° ìƒì„±
            response_metadata = ResponseMetadata(
                processing_time=time.time() - start_time,
                confidence=confidence,
                source_count=len(search_results if 'search_results' in locals() else []),
                agent_count=len(processing_metadata.get('agents_used', [])),
                reasoning_depth=intent.complexity_level,
                token_usage=intent.estimated_tokens,
                cost_estimate=self._estimate_cost(intent.estimated_tokens),
                quality_score=self._assess_quality(base_response, confidence)
            )
            
            # 6. ì ì‘í˜• ì‘ë‹µ ìƒì„±
            final_response = self.response_generator.generate_adaptive_response(
                base_response, context, response_metadata
            )
            
            # 7. ëŒ€í™” ë©”ëª¨ë¦¬ì— ì €ì¥
            self.memory_system.store_conversation(
                session_id, query, final_response, 
                {'intent': intent, 'metadata': response_metadata}
            )
            self.stats['feature_usage']['memory_recall'] += 1
            
            # 8. ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            context.history.append({
                'query': query,
                'response': final_response,
                'timestamp': datetime.now(),
                'intent': intent,
                'metadata': response_metadata
            })
            
            # 9. í†µê³„ ì—…ë°ì´íŠ¸
            self._update_stats(context.mode, True, response_metadata.processing_time)
            
            # 10. ê²°ê³¼ ë°˜í™˜
            return {
                'success': True,
                'response': final_response,
                'metadata': {
                    'confidence': confidence,
                    'processing_time': response_metadata.processing_time,
                    'mode': context.mode.value,
                    'intent_type': intent.query_type.value,
                    'complexity': intent.complexity_level,
                    'features_used': self._get_features_used(intent, use_multi_agent),
                    'quality_score': response_metadata.quality_score,
                    'cost_estimate': response_metadata.cost_estimate
                },
                'suggestions': self._generate_follow_up_suggestions(query, intent, context)
            }
            
        except Exception as e:
            logger.error(f"Advanced query processing failed: {e}")
            self._update_stats(context.mode if 'context' in locals() else ConversationMode.STANDARD, False, time.time() - start_time)
            
            return {
                'success': False,
                'response': "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                'error': str(e),
                'metadata': {
                    'processing_time': time.time() - start_time,
                    'mode': context.mode.value if 'context' in locals() else 'standard'
                }
            }
    
    def _should_use_multi_agent(self, intent: IntentAnalysisResult, context: ConversationContext) -> bool:
        """ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‚¬ìš© ì—¬ë¶€ ê²°ì •"""
        # ë³µì¡í•œ ì¿¼ë¦¬
        if intent.complexity_level >= 4:
            return True
        
        # ì´ë¯¸ì§€ ë¶„ì„ í•„ìš”
        if intent.requires_image:
            return True
        
        # ì¶”ë¡ ì´ í•„ìš”í•œ ê²½ìš°
        if intent.requires_reasoning:
            return True
        
        # ì „ë¬¸ê°€ ëª¨ë“œ
        if context.mode in [ConversationMode.EXPERT, ConversationMode.RESEARCH]:
            return True
        
        # ë‹¤ë‹¨ê³„ ì²˜ë¦¬ ëª¨ë“œ
        if intent.processing_mode.value in ['reasoning_chain', 'multi_agent', 'hybrid']:
            return True
        
        return False
    
    def _generate_basic_response(
        self, 
        query: str, 
        search_results: List, 
        max_score: float,
        image: Optional[Image.Image] = None
    ) -> str:
        """ê¸°ë³¸ ì‘ë‹µ ìƒì„±"""
        if not search_results:
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ì‹œ êµ¬ì„±í•´ì„œ ë¬¼ì–´ë³´ì‹œê±°ë‚˜ ë” êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ì œê³µí•´ì£¼ì„¸ìš”."
        
        best_result = search_results[0]
        
        response_parts = [f"ë‹µë³€: {best_result.answer}"]
        
        # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì¶”ê°€ (ë¹„ì „ ë¶„ì„ê¸° ì‚¬ìš©)
        if image and self.vision_analyzer.api_available:
            try:
                vision_result = self.vision_analyzer.analyze_image(image, query)
                if vision_result.get('success'):
                    response_parts.append(f"\n\nì´ë¯¸ì§€ ë¶„ì„: {vision_result['raw_response'][:300]}...")
            except Exception as e:
                logger.warning(f"Vision analysis failed: {e}")
        
        # ì‹ ë¢°ë„ ì •ë³´
        if max_score >= 0.8:
            confidence_text = "ë†’ìŒ"
        elif max_score >= 0.6:
            confidence_text = "ì¤‘ê°„"
        else:
            confidence_text = "ë‚®ìŒ"
        
        response_parts.append(f"\n\n[ì‹ ë¢°ë„: {confidence_text} ({max_score:.3f})]")
        
        return "".join(response_parts)
    
    def _estimate_cost(self, tokens: int) -> float:
        """ë¹„ìš© ì¶”ì •"""
        # OpenAI gpt-4o-mini ê¸°ì¤€ ($0.15 ì…ë ¥, $0.60 ì¶œë ¥ per 1M tokens)
        input_cost = tokens * 0.00000015
        output_cost = tokens * 0.5 * 0.0000006  # ì¶œë ¥ì€ ì…ë ¥ì˜ ì ˆë°˜ ê°€ì •
        return input_cost + output_cost
    
    def _assess_quality(self, response: str, confidence: float) -> float:
        """ì‘ë‹µ í’ˆì§ˆ í‰ê°€"""
        quality_score = confidence * 0.6  # ì‹ ë¢°ë„ ê¸°ë°˜
        
        # ê¸¸ì´ ê¸°ë°˜ ë³´ì •
        if len(response) > 100:
            quality_score += 0.1
        if len(response) > 500:
            quality_score += 0.1
        
        # êµ¬ì¡° ê¸°ë°˜ ë³´ì •
        if 'ë‹¨ê³„' in response or 'ë°©ë²•' in response:
            quality_score += 0.1
        
        # ì˜ˆì‹œ í¬í•¨ ì—¬ë¶€
        if 'ì˜ˆì‹œ' in response or 'ì˜ˆë¥¼ ë“¤ì–´' in response:
            quality_score += 0.1
        
        return min(quality_score, 1.0)
    
    def _get_features_used(self, intent: IntentAnalysisResult, use_multi_agent: bool) -> List[str]:
        """ì‚¬ìš©ëœ ê¸°ëŠ¥ ëª©ë¡"""
        features = []
        
        if intent.requires_image:
            features.append('vision_analysis')
        
        if use_multi_agent:
            features.append('multi_agent_system')
        
        if intent.requires_reasoning:
            features.append('chain_of_thought')
        
        if intent.requires_external_search:
            features.append('web_search')
        
        features.append('enhanced_rag')
        features.append('adaptive_response')
        
        return features
    
    def _generate_follow_up_suggestions(
        self, 
        query: str, 
        intent: IntentAnalysisResult, 
        context: ConversationContext
    ) -> List[str]:
        """í›„ì† ì§ˆë¬¸ ì œì•ˆ"""
        suggestions = []
        
        if intent.query_type.value == 'mathematical':
            suggestions.extend([
                "ì´ ìˆ˜ì‹ì˜ ìœ ë„ ê³¼ì •ì„ ë³´ì—¬ì£¼ì„¸ìš”",
                "ì‹¤ì œ ì ìš© ì˜ˆì‹œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
                "ê´€ë ¨ëœ ë‹¤ë¥¸ ê³µì‹ë“¤ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"
            ])
        
        elif intent.query_type.value == 'analytical':
            suggestions.extend([
                "ë” ìì„¸í•œ ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”",
                "ë‹¤ë¥¸ ê´€ì ì—ì„œ ì ‘ê·¼í•´ë³´ì„¸ìš”",
                "ì‹¤ë¬´ì—ì„œ ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”"
            ])
        
        elif intent.requires_image:
            suggestions.extend([
                "ì´ë¯¸ì§€ì˜ ë‹¤ë¥¸ ë¶€ë¶„ì„ ë¶„ì„í•´ì£¼ì„¸ìš”",
                "ìœ ì‚¬í•œ ì˜ˆì‹œë¥¼ ë” ë³´ì—¬ì£¼ì„¸ìš”",
                "ì´ë¡ ì  ë°°ê²½ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"
            ])
        
        # ëª¨ë“œë³„ ì œì•ˆ
        if context.mode == ConversationMode.TUTORIAL:
            suggestions.extend([
                "ë‹¨ê³„ë³„ë¡œ ë” ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                "ì—°ìŠµ ë¬¸ì œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”",
                "ê´€ë ¨ ê°œë…ì„ ë³µìŠµí•´ì£¼ì„¸ìš”"
            ])
        
        return suggestions[:3]  # ìµœëŒ€ 3ê°œ
    
    def _update_stats(self, mode: ConversationMode, success: bool, processing_time: float):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        self.stats['total_queries'] += 1
        self.stats['mode_usage'][mode.value] += 1
        
        if success:
            self.stats['successful_responses'] += 1
        
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
        n = self.stats['total_queries']
        prev_avg = self.stats['average_response_time']
        self.stats['average_response_time'] = (prev_avg * (n - 1) + processing_time) / n
    
    def get_stats(self) -> Dict:
        """í†µê³„ ë°˜í™˜"""
        return self.stats.copy()
    
    def get_conversation_summary(self, session_id: str) -> Dict:
        """ëŒ€í™” ìš”ì•½ ë°˜í™˜"""
        if session_id not in self.conversation_contexts:
            return {"error": "Session not found"}
        
        context = self.conversation_contexts[session_id]
        
        return {
            'session_id': session_id,
            'mode': context.mode.value,
            'conversation_count': len(context.history),
            'duration': (context.last_active - context.created_at).total_seconds(),
            'dominant_topics': self._extract_dominant_topics(context.history),
            'avg_complexity': sum(h.get('intent', type('obj', (object,), {'complexity_level': 3})).complexity_level 
                                for h in context.history) / max(len(context.history), 1),
            'last_active': context.last_active.isoformat()
        }
    
    def _extract_dominant_topics(self, history: List[Dict]) -> List[str]:
        """ì£¼ìš” ëŒ€í™” ì£¼ì œ ì¶”ì¶œ"""
        if not history:
            return []
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
        word_freq = {}
        for entry in history:
            words = entry['query'].lower().split()
            for word in words:
                if len(word) > 2:
                    word_freq[word] = word_freq.get(word, 0) + 1
        
        # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ
        top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]
        return [word for word, freq in top_words]


# ë™ê¸° ì¸í„°í˜ì´ìŠ¤
def create_advanced_chatbot_service(config: Config) -> AdvancedChatbotService:
    """ê³ ê¸‰ ì±—ë´‡ ì„œë¹„ìŠ¤ ìƒì„±"""
    return AdvancedChatbotService(config)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ
    from config import Config
    
    config = Config()
    service = create_advanced_chatbot_service(config)
    
    # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸
    async def test_advanced_service():
        result = await service.process_query_advanced(
            "ì „ë ¥ ê³„ì‚° ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            session_id="test_session_1",
            mode=ConversationMode.TUTORIAL
        )
        
        print(f"Success: {result['success']}")
        print(f"Response: {result['response'][:200]}...")
        print(f"Features: {result['metadata']['features_used']}")
        print(f"Quality: {result['metadata']['quality_score']:.2f}")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import asyncio
    asyncio.run(test_advanced_service())