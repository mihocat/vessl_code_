#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Gradio UI Application with Multimodal RAG System
ë©€í‹°ëª¨ë‹¬ RAG ì‹œìŠ¤í…œì„ ê°–ì¶˜ í–¥ìƒëœ Gradio UI ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import sys
import time
import logging
from typing import List, Tuple, Optional, Union, Dict, Any
from PIL import Image
import torch

import gradio as gr

from config import Config
from llm_client import LLMClient

# í–¥ìƒëœ ì‹œìŠ¤í…œ ì„í¬íŠ¸
from enhanced_rag_system import (
    EnhancedVectorDatabase, 
    EnhancedRAGSystem,
    RAGSystemAdapter
)
from enhanced_image_analyzer import ChatGPTStyleAnalyzer
from chatgpt_response_generator import ChatGPTResponseGenerator

# ê¸°ì¡´ ì„œë¹„ìŠ¤ (í˜¸í™˜ì„±)
from services import WebSearchService

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class EnhancedChatService:
    """í–¥ìƒëœ í†µí•© ì±—ë´‡ ì„œë¹„ìŠ¤"""
    
    def __init__(self, config: Config, llm_client: LLMClient):
        """
        í–¥ìƒëœ ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            config: ì „ì²´ ì„¤ì • ê°ì²´
            llm_client: LLM í´ë¼ì´ì–¸íŠ¸
        """
        self.config = config
        self.llm_client = llm_client
        
        # í–¥ìƒëœ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        logger.info("Initializing enhanced components...")
        
        # 1. í–¥ìƒëœ ë²¡í„° DB
        self.vector_db = EnhancedVectorDatabase(
            persist_directory=config.rag.persist_directory
        )
        
        # 2. í–¥ìƒëœ RAG ì‹œìŠ¤í…œ
        self.enhanced_rag = EnhancedRAGSystem(
            vector_db=self.vector_db,
            llm_client=llm_client
        )
        
        # 3. í˜¸í™˜ì„±ì„ ìœ„í•œ ì–´ëŒ‘í„°
        self.rag_system = RAGSystemAdapter(self.enhanced_rag)
        
        # 4. ì´ë¯¸ì§€ ë¶„ì„ê¸°
        self.image_analyzer = ChatGPTStyleAnalyzer(use_florence=True)
        
        # 5. ë©€í‹°ëª¨ë‹¬ OCR (ì¶”ê°€)
        try:
            from multimodal_ocr import MultimodalOCRPipeline
            self.ocr_pipeline = MultimodalOCRPipeline()
            logger.info("Multimodal OCR pipeline loaded successfully")
        except Exception as e:
            logger.warning(f"Failed to load multimodal OCR pipeline: {e}")
            self.ocr_pipeline = None
        
        # 6. ì‘ë‹µ ìƒì„±ê¸°
        self.response_generator = ChatGPTResponseGenerator()
        
        # 7. ì›¹ ê²€ìƒ‰ ì„œë¹„ìŠ¤
        self.web_search = WebSearchService(config.web_search)
        
        # ëŒ€í™” ì´ë ¥
        self.conversation_history = []
        
        logger.info("Enhanced chat service initialized successfully")
        
    def process_query(
        self, 
        question: str, 
        history: List[Tuple[str, str]],
        image: Optional[Image.Image] = None
    ) -> str:
        """
        ì‚¬ìš©ì ì§ˆì˜ ì²˜ë¦¬ (í–¥ìƒëœ ë²„ì „)
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            history: ëŒ€í™” ì´ë ¥
            image: ì„ íƒì  ì´ë¯¸ì§€ ì…ë ¥
            
        Returns:
            ìƒì„±ëœ ì‘ë‹µ
        """
        start_time = time.time()
        
        # ë¹ˆ ì§ˆë¬¸ ì²˜ë¦¬
        if not question or not question.strip():
            return "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
        
        try:
            # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬
            response_style = self._determine_response_style(question, image)
            
            # í–¥ìƒëœ RAG ì‹œìŠ¤í…œìœ¼ë¡œ ì²˜ë¦¬
            result = self.enhanced_rag.process_query(
                query=question,
                image=image,
                response_style=response_style
            )
            
            if result['success']:
                response = result['response']
                
                # ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€ (ì„ íƒì )
                if self.config.app.show_sources:
                    response += self._format_sources(result['search_results'])
                
                # ì‘ë‹µ ì‹œê°„ ì¶”ê°€
                elapsed_time = time.time() - start_time
                response += f"\n\n_ì‘ë‹µì‹œê°„: {elapsed_time:.2f}ì´ˆ_"
                
                # ëŒ€í™” ì´ë ¥ ì—…ë°ì´íŠ¸
                self.conversation_history.append((question, response))
                
                return response
            else:
                return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
        except Exception as e:
            logger.error(f"Query processing failed: {e}", exc_info=True)
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def _determine_response_style(self, question: str, image: Optional[Image.Image]) -> str:
        """ì‘ë‹µ ìŠ¤íƒ€ì¼ ê²°ì •"""
        question_lower = question.lower()
        
        # ë‹¨ê³„ë³„ ì„¤ëª… ìš”ì²­
        if any(keyword in question_lower for keyword in ['ë‹¨ê³„', 'ìˆœì„œ', 'ë°©ë²•', 'ì–´ë–»ê²Œ']):
            return 'step_by_step'
        
        # ê°œë… ì„¤ëª… ìš”ì²­
        if any(keyword in question_lower for keyword in ['ë¬´ì—‡', 'ì •ì˜', 'ê°œë…', 'ì˜ë¯¸']):
            return 'concept'
        
        # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° ì¢…í•©ì  ì‘ë‹µ
        if image:
            return 'comprehensive'
        
        # ê¸°ë³¸ê°’
        return 'comprehensive'
    
    def _format_sources(self, search_results: List[Dict[str, Any]]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ ì†ŒìŠ¤ í¬ë§·íŒ…"""
        if not search_results:
            return ""
        
        sources_text = "\n\nğŸ“š **ì°¸ê³  ìë£Œ:**"
        for i, result in enumerate(search_results[:3]):
            score = result.get('hybrid_score', 0)
            metadata = result.get('metadata', {})
            
            sources_text += f"\n{i+1}. "
            if metadata.get('title'):
                sources_text += f"{metadata['title']} "
            sources_text += f"(ì ìˆ˜: {score:.3f})"
        
        return sources_text
    
    def get_system_stats(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ"""
        stats = {
            'total_queries': len(self.conversation_history),
            'vector_db_size': self.vector_db.collection.count(),
            'model_status': 'active' if self.llm_client else 'inactive',
            'image_analyzer': 'active' if self.image_analyzer else 'inactive'
        }
        return stats


def create_enhanced_gradio_app(config: Optional[Config] = None) -> gr.Blocks:
    """
    í–¥ìƒëœ Gradio ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
    
    Args:
        config: ì„¤ì • ê°ì²´ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        
    Returns:
        Gradio Blocks ì¸ìŠ¤í„´ìŠ¤
    """
    # ì„¤ì • ì´ˆê¸°í™”
    if config is None:
        config = Config()
    
    # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    llm_client = LLMClient(config.llm)
    
    # ì„œë²„ ëŒ€ê¸°
    logger.info("Waiting for LLM server...")
    if not llm_client.wait_for_server():
        logger.error("Failed to connect to LLM server")
        raise RuntimeError("LLM server connection failed")
    
    # í–¥ìƒëœ ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    chat_service = EnhancedChatService(config, llm_client)
    
    # Gradio ì¸í„°í˜ì´ìŠ¤
    with gr.Blocks(
        title="AI ì „ê¸°ê³µí•™ íŠœí„° (í–¥ìƒëœ ë²„ì „)",
        theme=gr.themes.Soft(),
        css="""
        .message { font-size: 16px; }
        .latex-math { font-family: 'Computer Modern', serif; }
        pre { background-color: #f0f0f0; padding: 10px; border-radius: 5px; }
        """
    ) as app:
        gr.Markdown("""
        # ğŸ“ AI ì „ê¸°ê³µí•™ íŠœí„° (í–¥ìƒëœ ë²„ì „)
        
        ChatGPT ìŠ¤íƒ€ì¼ì˜ ì „ë¬¸ì ì¸ ì „ê¸°ê³µí•™ í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
        - âœ… **êµ¬ì¡°í™”ëœ ë‹µë³€**: í•µì‹¬ ì •ë¦¬, ë‹¨ê³„ë³„ ì„¤ëª…, ì‹œê°ì  ìš”ì†Œ
        - ğŸ“Š **ìˆ˜ì‹ ì§€ì›**: LaTeX ìˆ˜ì‹ ì¸ì‹ ë° í‘œí˜„
        - ğŸ–¼ï¸ **ì´ë¯¸ì§€ ë¶„ì„**: ë¬¸ì œ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ë©´ OCRë¡œ ë¶„ì„
        - ğŸ’¡ **ì „ë¬¸ê°€ ìˆ˜ì¤€**: ì „ê¸°ê³µí•™ íŠ¹í™” ì§€ì‹ ê¸°ë°˜
        """)
        
        # ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
        with gr.Row():
            with gr.Column(scale=7):
                # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
                chatbot = gr.Chatbot(
                    label="ëŒ€í™”",
                    height=600,
                    bubble_full_width=False,
                    show_label=True,
                    elem_classes=["message"]
                )
                
                # ì…ë ¥ ì˜ì—­
                with gr.Row():
                    with gr.Column(scale=4):
                        msg = gr.Textbox(
                            label="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
                            placeholder="ì „ê¸°ê³µí•™ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
                            lines=3,
                            max_lines=5
                        )
                    with gr.Column(scale=1):
                        submit = gr.Button("ì „ì†¡", variant="primary", size="lg")
                        clear = gr.Button("ëŒ€í™” ì´ˆê¸°í™”", size="sm")
                
                # ì´ë¯¸ì§€ ì—…ë¡œë“œ
                with gr.Row():
                    image_input = gr.Image(
                        label="ë¬¸ì œ ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì„ íƒì‚¬í•­)",
                        type="pil",
                        height=200
                    )
                    image_preview = gr.Markdown("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ OCRë¡œ í…ìŠ¤íŠ¸ì™€ ìˆ˜ì‹ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.")
            
            # ì‚¬ì´ë“œë°”
            with gr.Column(scale=3):
                # ì‘ë‹µ ìŠ¤íƒ€ì¼ ì„ íƒ
                with gr.Box():
                    gr.Markdown("### âš™ï¸ ì‘ë‹µ ìŠ¤íƒ€ì¼")
                    response_style = gr.Radio(
                        choices=[
                            ("ì¢…í•©ì  ì„¤ëª…", "comprehensive"),
                            ("ë‹¨ê³„ë³„ í’€ì´", "step_by_step"),
                            ("ê°œë… ì„¤ëª…", "concept")
                        ],
                        value="comprehensive",
                        label="ì›í•˜ëŠ” ì‘ë‹µ í˜•ì‹ì„ ì„ íƒí•˜ì„¸ìš”"
                    )
                
                # ì˜ˆì œ ì§ˆë¬¸
                gr.Markdown("### ğŸ’¡ ì˜ˆì œ ì§ˆë¬¸")
                with gr.Tab("ê¸°ë³¸ ê°œë…"):
                    gr.Examples(
                        examples=[
                            "3ìƒ ì „ë ¥ ì‹œìŠ¤í…œì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                            "ì—­ë¥ ì´ë€ ë¬´ì—‡ì´ê³  ì™œ ì¤‘ìš”í•œê°€ìš”?",
                            "ë³€ì••ê¸°ì˜ ë™ì‘ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                        ],
                        inputs=msg,
                        label="í´ë¦­í•˜ì—¬ ì‚¬ìš©"
                    )
                
                with gr.Tab("ë¬¸ì œ í’€ì´"):
                    gr.Examples(
                        examples=[
                            "3ìƒ ì „ë ¥ì—ì„œ ì„ ê°„ì „ì••ì´ 380Vì´ê³  ë¶€í•˜ì „ë¥˜ê°€ 10Aì¼ ë•Œ ì „ë ¥ì„ ê³„ì‚°í•˜ì„¸ìš”.",
                            "RLC ì§ë ¬íšŒë¡œì—ì„œ ê³µì§„ì£¼íŒŒìˆ˜ë¥¼ êµ¬í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                            "ìœ ë„ì „ë™ê¸°ì˜ ìŠ¬ë¦½ì´ 0.05ì¼ ë•Œ íšŒì „ì†ë„ë¥¼ êµ¬í•˜ì„¸ìš”."
                        ],
                        inputs=msg
                    )
                
                with gr.Tab("ì´ë¯¸ì§€ ì˜ˆì‹œ"):
                    gr.Markdown("""
                    ğŸ“· **ì´ë¯¸ì§€ ì—…ë¡œë“œ íŒ:**
                    - ë¬¸ì œ ì‚¬ì§„ì„ ì°ì–´ ì—…ë¡œë“œí•˜ì„¸ìš”
                    - íšŒë¡œë„ë‚˜ ê·¸ë˜í”„ë„ ë¶„ì„ ê°€ëŠ¥í•©ë‹ˆë‹¤
                    - ì†ê¸€ì”¨ë„ ì¸ì‹ë©ë‹ˆë‹¤ (ì •ìë¡œ ì“¸ìˆ˜ë¡ ì •í™•)
                    """)
        
        # í†µê³„ ë° ì •ë³´
        with gr.Accordion("ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´", open=False):
            with gr.Row():
                stats_display = gr.JSON(
                    label="ì‹œìŠ¤í…œ í†µê³„",
                    visible=True
                )
                refresh_stats = gr.Button("ìƒˆë¡œê³ ì¹¨", size="sm")
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        def respond(message: str, image, chat_history: List[Tuple[str, str]], style: str):
            """ë©”ì‹œì§€ ì‘ë‹µ ì²˜ë¦¬"""
            if not message.strip():
                return "", None, chat_history
            
            # ìŠ¤íƒ€ì¼ ì„¤ì • ì„ì‹œ ì €ì¥
            original_style = chat_service.enhanced_rag.response_generator
            
            response = chat_service.process_query(message, chat_history, image)
            
            # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° ëŒ€í™”ì— í‘œì‹œ
            if image:
                chat_history.append((f"{message}\nğŸ“ [ì´ë¯¸ì§€ ì²¨ë¶€ë¨]", response))
            else:
                chat_history.append((message, response))
            
            return "", None, chat_history
        
        def clear_chat():
            """ëŒ€í™” ì´ˆê¸°í™”"""
            chat_service.conversation_history.clear()
            return None, "", None
        
        def update_stats():
            """í†µê³„ ì—…ë°ì´íŠ¸"""
            return chat_service.get_system_stats()
        
        def analyze_image(image):
            """ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° ë¶„ì„"""
            if not image:
                return "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ OCRë¡œ í…ìŠ¤íŠ¸ì™€ ìˆ˜ì‹ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."
            
            try:
                # ê°„ë‹¨í•œ ë¶„ì„ ìˆ˜í–‰
                analysis = chat_service.image_analyzer.analyze_image(image)
                if analysis['success']:
                    preview = "ğŸ” **ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼:**\n"
                    if analysis.get('ocr_text'):
                        preview += f"- í…ìŠ¤íŠ¸: {analysis['ocr_text'][:100]}...\n"
                    if analysis.get('formulas'):
                        preview += f"- ìˆ˜ì‹: {len(analysis['formulas'])}ê°œ ê°ì§€\n"
                    return preview
                else:
                    return "ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            except:
                return "ì´ë¯¸ì§€ ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì´ë²¤íŠ¸ ë°”ì¸ë”©
        submit.click(
            respond, 
            [msg, image_input, chatbot, response_style], 
            [msg, image_input, chatbot]
        )
        msg.submit(
            respond, 
            [msg, image_input, chatbot, response_style], 
            [msg, image_input, chatbot]
        )
        clear.click(clear_chat, None, [chatbot, msg, image_input])
        refresh_stats.click(update_stats, None, stats_display)
        image_input.change(analyze_image, image_input, image_preview)
        
        # ì´ˆê¸° í†µê³„ í‘œì‹œ
        app.load(update_stats, None, stats_display)
    
    return app


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Enhanced RAG System Gradio UI")
    parser.add_argument(
        "--config", 
        type=str, 
        help="Path to config file (JSON format)"
    )
    parser.add_argument(
        "--server-port", 
        type=int, 
        default=7860,
        help="Server port (default: 7860)"
    )
    parser.add_argument(
        "--share", 
        action="store_true",
        help="Create public Gradio link"
    )
    
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    config = Config()
    config.app.show_sources = True  # ì†ŒìŠ¤ í‘œì‹œ í™œì„±í™”
    
    # ëª…ë ¹ì¤„ ì¸ìë¡œ ì˜¤ë²„ë¼ì´ë“œ
    if args.server_port:
        config.app.server_port = args.server_port
    if args.share:
        config.app.share = args.share
    
    # ì•± ìƒì„± ë° ì‹¤í–‰
    try:
        app = create_enhanced_gradio_app(config)
        app.launch(
            server_name=config.app.server_name,
            server_port=config.app.server_port,
            share=config.app.share
        )
    except Exception as e:
        logger.error(f"Failed to launch app: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()